## [2800] Counterfactual Graph Learning for Anomaly Detection with Feature Disentanglement and Generation (Student Abstract)

**Authors**: *Yutao Wei, Wenzheng Shu, Zhangtao Cheng, Wenxin Tai, Chunjing Xiao, Ting Zhong*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30524](https://doi.org/10.1609/aaai.v38i21.30524)

**Abstract**:

Graph anomaly detection has received remarkable research interests, and various techniques have been employed for enhancing detection performance. However, existing models tend to learn dataset-specific spurious correlations based on statistical associations. A well-trained model might suffer from performance degradation when applied to newly observed nodes with different environments. To handle this situation, we propose CounterFactual Graph Anomaly Detection model, CFGAD. In this model, we design a gradient-based separator to disentangle node features into class features and environment features. Then, we present a weight-varying diffusion model to combine class features and environment features from different nodes to generate counterfactual samples. These counterfactual samples will be adopted to enhance model robustness. Comprehensive experiments demonstrate the effectiveness of our CFGAD.

----

## [2801] Intersection of Artificial Intelligence and Medical Education (Student Abstract)

**Authors**: *Keefer P. Wu, Patricia C. Tsang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30525](https://doi.org/10.1609/aaai.v38i21.30525)

**Abstract**:

Can advanced AI-driven technologies transform the traditionally arduous educational process in medicine? This study takes a deep dive into how the publicly available OpenAI ChatGPT-3.5 performs in answering board-style questions designed for physicians training to become pathologists. Correctly answering 75% of 543 questions using an engaging and fast-paced format was an impressive performance. It underscores the potential as well as improvement opportunities of using interactive AI in future medical training.

----

## [2802] Bridging the Gap between Source Code and Requirements Using GPT (Student Abstract)

**Authors**: *Ruoyu Xu, Zhenyu Xu, Gaoxiang Li, Victor S. Sheng*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30526](https://doi.org/10.1609/aaai.v38i21.30526)

**Abstract**:

Reverse engineering involves analyzing the design, architecture, and functionality of systems, and is crucial for legacy systems. Legacy systems are outdated software systems that are still in use and often lack proper documentation, which makes their maintenance and evolution challenging. To address this, we introduce SC2Req, utilizing the Generative Pre-trained Transformer (GPT) for automated code analysis and requirement generation. This approach aims to convert source code into understandable requirements and bridge the gap between those two. Through experiments on diverse software projects, SC2Req shows the potential to enhance the accuracy and efficiency of the translation process. This approach not only facilitates faster software development and easier maintenance of legacy systems but also lays a strong foundation for future research, promoting better understanding and communication in software development.

----

## [2803] ChatGPT-Generated Code Assignment Detection Using Perplexity of Large Language Models (Student Abstract)

**Authors**: *Zhenyu Xu, Ruoyu Xu, Victor S. Sheng*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30527](https://doi.org/10.1609/aaai.v38i21.30527)

**Abstract**:

In the era of large language models like Chatgpt, maintaining academic integrity in programming education has become challenging due to potential misuse. There's a pressing need for reliable detectors to identify Chatgpt-generated code. While previous studies have tackled model-generated text detection, identifying such code remains uncharted territory. In this paper, we introduce a novel method to discern Chatgpt-generated code. We employ targeted masking perturbation, emphasizing code sections with high perplexity. Fine-tuned CodeBERT is utilized to replace these masked sections, generating subtly perturbed samples. Our scoring system amalgamates overall perplexity, variations in code line perplexity, and burstiness. In this scoring scheme, a higher rank for the original code suggests it's more likely to be chatgpt-generated. The underlying principle is that code generated by models typically exhibits consistent, low perplexity and reduced burstiness, with its ranking remaining relatively stable even after subtle modifications. In contrast, human-written code, when perturbed, is more likely to produce samples that the model prefers. Our approach significantly outperforms current detectors, especially against OpenAI's text-davinci-003 model, with the average AUC rising from 0.56 (GPTZero baseline) to 0.87.

----

## [2804] Pass-Efficient Algorithms for Graph Spectral Clustering (Student Abstract)

**Authors**: *Boshen Yan, Guihong Wan, Haim Schweitzer, Zoltan Maliga, Sara Khattab, Kun-Hsing Yu, Peter K. Sorger, Yevgeniy R. Semenov*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30528](https://doi.org/10.1609/aaai.v38i21.30528)

**Abstract**:

Graph spectral clustering is a fundamental technique in data analysis, which utilizes eigenpairs of the Laplacian matrix to partition graph vertices into clusters. However, classical spectral clustering algorithms require eigendecomposition of the Laplacian matrix, which has cubic time complexity. In
this work, we describe pass-efficient spectral clustering algorithms that leverage recent advances in randomized eigendecomposition and the structure of the graph vertex-edge matrix. Furthermore, we derive formulas for their efficient implementation. The resulting algorithms have a linear time complexity with respect to the number of vertices and edges and pass over the graph constant times, making them suitable for processing large graphs stored on slow memory. Experiments validate the accuracy and efficiency of the algorithms.

----

## [2805] Improving IP Geolocation With Target-Centric IP Graph (Student Abstract)

**Authors**: *Kai Yang, Jiayang Li, Wenxin Tai, Zhenhui Li, Ting Zhong, Guangqiang Yin, Yong Wang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30529](https://doi.org/10.1609/aaai.v38i21.30529)

**Abstract**:

Accurate IP geolocation is indispensable for location-aware applications. While recent advances based on router-centric IP graphs are considered cutting-edge, one challenge remain: the prevalence of sparse IP graphs (14.24% with fewer than 10 nodes, 9.73% isolated) limits graph learning. To mitigate this issue, we designate the target host as the central node and aggregate multiple last-hop routers to construct the target-centric IP graph, instead of relying solely on the router with the smallest last-hop latency as in previous works. Experiments on three real-world datasets show that our method significantly improves the geolocation accuracy compared to existing baselines.

----

## [2806] Decoupling User Relationships Guides Information Diffusion Prediction (Student Abstract)

**Authors**: *Wenxue Ye, Shichong Li, Zhangtao Cheng, Xovee Xu, Ting Zhong, Bei Hui, Fan Zhou*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30530](https://doi.org/10.1609/aaai.v38i21.30530)

**Abstract**:

Information diffusion prediction is a critical task for many social network applications. However, current methods are mainly limited by the following aspects: user relationships behind resharing behaviors are complex and entangled. To address these issues, we propose MHGFormer, a novel multi-channel hypergraph transformer framework, to better decouple complex user relations and obtain fine-grained user representations. First, we employ designed triangular motifs to decouple user relations into three different level hypergraphs. Second,  a position-aware hypergraph transformer is used to refine user relation and obtain high-quality user representations. Extensive experiments conducted on two social datasets demonstrate that MHGFormer outperforms state-of-the-art diffusion models across several settings.

----

## [2807] Amplifying Diversity and Quality in Commonsense Knowledge Graph Completion (Student Abstract)

**Authors**: *Liu Yu, Fenghui Tian, Ping Kuang, Fan Zhou*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30531](https://doi.org/10.1609/aaai.v38i21.30531)

**Abstract**:

Conventional commonsense knowledge graph completion (CKGC) methods provide inadequate sequence when fine-tuning or generating stages and incorporate full fine-tuning, which fail to align with the autoregressive model's pre-training patterns and have insufficient parameter efficiency. Moreover, decoding through beam or greedy search produces low diversity and high similarity in generated tail entities. Hence, we resort to prefix-tuning and propose a lightweight, effective pipeline to enhance the quality and diversity of extracted commonsense knowledge. Precisely, we measure head entity similarity to yield and then concatenate top-k tuples before each target tuple for prefix-tuning the source LM, thereby improving the efficiency and speed for pretrained models; then, we design a penalty-tailored diverse beam search (p-DBS) for decoding tail entities, producing a greater quantity and diversity of generated commonsense tuples; besides, a filter strategy is utilized to filter out invalid commonsense knowledge. Through extensive automatic evaluations, including ChatGPT scoring, our method can extract diverse, novel, and accurate commonsense knowledge (CK).

----

## [2808] Biases Mitigation and Expressiveness Preservation in Language Models: A Comprehensive Pipeline (Student Abstract)

**Authors**: *Liu Yu, Ludie Guo, Ping Kuang, Fan Zhou*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30532](https://doi.org/10.1609/aaai.v38i21.30532)

**Abstract**:

Pre-trained language models (PLMs) have greatly transformed various downstream tasks, yet frequently display social biases from training data, raising fairness concerns. Recent efforts to debias PLMs come with limitations: they either fine-tune the entire parameters in PLMs, which is time-consuming and disregards the expressiveness of PLMs, or ignore the reintroducing biases from downstream tasks when applying debiased models to them. Hence, we propose a two-stage pipeline to mitigate biases from both internal and downstream contexts while preserving expressiveness in language models. Specifically, for the debiasing procedure, we resort to continuous prefix-tuning, not fully fine-tuning the PLM, in which we design a debiasing term for optimization and an alignment term to keep words’ relative distances and ensure the model's expressiveness. For downstream tasks, we perform causal intervention across different demographic groups for invariant predictions. Results on three GLUE tasks show our method alleviates biases from internal and downstream contexts, while keeping PLM expressiveness intact.

----

## [2809] Leverage the Explainability of Transformer Models to Improve the DNA 5-Methylcytosine Identification (Student Abstract)

**Authors**: *Wenhuan Zeng, Daniel H. Huson*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30533](https://doi.org/10.1609/aaai.v38i21.30533)

**Abstract**:

DNA methylation is an epigenetic mechanism for regulating gene expression, and it plays an important role in many biological processes. While methylation sites can be identified using laboratory techniques, much work is being done on developing computational approaches using machine learning. Here, we present a deep-learning algorithm for determining the 5-methylcytosine status of a DNA sequence. We propose an ensemble framework that treats the self-attention score as an explicit feature that is added to the encoder layer generated by fine-tuned language models. We evaluate the performance of the model under different data distribution scenarios.

----

## [2810] THGFormer: Time-Aware Hypergraph Learning for Multimodal Social Media Popularity Prediction (Student Abstract)

**Authors**: *Jienan Zhang, Jie Liu, Zhangtao Cheng, Xovee Xu, Fang Liu, Ting Zhong, Kunpeng Zhang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30534](https://doi.org/10.1609/aaai.v38i21.30534)

**Abstract**:

Social media popularity prediction of multimodal user-generated content (UGC) is a crucial task for many real-world applications. However, existing efforts are often limited by missing inter-instance correlations and UGC temporal patterns. To address these issues, we propose a novel time-aware hypergraph Transformer framework, THGFormer. It fully represents inter-instance and intra-instance relations by hypergraphs, captures the temporal dependencies with a time encoder, and enhances UGC's representations via a neighborhood knowledge aggregation. Extensive experiments conducted on two real-world datasets demonstrate that THGFormer outperforms state-of-the-art popularity prediction models across several settings.

----

## [2811] Biomedical Knowledge Graph Embedding with Householder Projection (Student Abstract)

**Authors**: *Sensen Zhang, Xun Liang, Simin Niu, Xuan Zhang, Chen Feng, Yuefeng Ma*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30535](https://doi.org/10.1609/aaai.v38i21.30535)

**Abstract**:

Researchers have applied knowledge graph embedding (KGE) techniques with advanced neural network techniques, such as capsule networks, for predicting drug-drug interactions (DDIs) and achieved remarkable results. However, most ignore molecular structure and position features between drug pairs. They cannot model the biomedical field's significant relational mapping properties (RMPs,1-N, N-1, N-N) relation. To solve these problems,  we innovatively propose CDHse that consists of two crucial modules: 1) Entity embedding module, we obtain position feature obtained by PubMedBERT and Convolutional Neural Network (CNN),  obtain molecular structure feature with Graphic Nuaral Network (GNN), obtain entity embedding feature of drug pairs, and then incorporate these features into one synthetic feature. 2) Knowledge graph embedding module, the synthetic feature is Householder projections and then embedded in the complex vector space for training. In this paper, we have selected several advanced models for the DDIs task and performed experiments on three standard BioKG to validate the effectiveness of CDHse.

----

## [2812] MRMLREC: A Two-Stage Approach for Addressing Data Sparsity in MOOC Video Recommendation (Student Abstract)

**Authors**: *Ye Zhang, Yanqi Gao, Yupeng Zhou, Jianan Wang, Minghao Yin*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30536](https://doi.org/10.1609/aaai.v38i21.30536)

**Abstract**:

With the abundance of learning resources available on massive open online courses (MOOCs) platforms, the issue of interactive data sparsity has emerged as a significant challenge.This paper introduces MRMLREC, an efficient MOOC video recommendation which consists of two main stages: multi-relational representation and multi-level recommendation, aiming to solve the problem of data sparsity. In the multi-relational representation stage, MRMLREC adopts a tripartite approach, constructing relational graphs based on temporal sequences, courses-videos relation, and knowledge concepts-video relation. These graphs are processed by a Graph Convolution Network (GCN) and two variant Graph Attention Networks (GAT) to derive representations. A variant of the Long Short-Term Memory Network (LSTM) then integrates these multi-dimensional data to enhance the overall representation. The multi-level recommendation stage introduces three prediction tasks at varying levels—courses, knowledge concepts, and videos—to mitigate data sparsity and improve the interpretability of video recommendations. Beam search (BS) is employed to identify top-β items at each level, refining the subsequent level's search space and enhancing recommendation efficiency. Additionally, an optional layer offers both personalization and diversification modes, ensuring variety in recommended videos and maintaining learner engagement. Comprehensive experiments demonstrate the effectiveness of MRMLREC on two real-world instances from Xuetang X.

----

## [2813] Automated Natural Language Explanation of Deep Visual Neurons with Large Models (Student Abstract)

**Authors**: *Chenxu Zhao, Wei Qian, Yucheng Shi, Mengdi Huai, Ninghao Liu*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30537](https://doi.org/10.1609/aaai.v38i21.30537)

**Abstract**:

Interpreting deep neural networks through examining neurons offers distinct advantages when it comes to exploring the inner workings of Deep Neural Networks. Previous research has indicated that specific neurons within deep vision networks possess semantic meaning and play pivotal roles in model performance. Nonetheless, the current methods for generating neuron semantics heavily rely on human intervention, which hampers their scalability and applicability. To address this limitation, this paper proposes a novel post-hoc framework for generating semantic explanations of neurons with large foundation models, without requiring human intervention or prior knowledge. Experiments are conducted with both qualitative and quantitative analysis to verify the effectiveness of our proposed approach.

----

## [2814] Power-Aware Inverse-Search Machine Learning for Low Resource Multi-Objective Unmanned Underwater Vehicle Control (Student Abstract)

**Authors**: *Brian Zhou, Jason Geder, Kamal Viswanath, Alisha Sharma, Julian Lee*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30538](https://doi.org/10.1609/aaai.v38i21.30538)

**Abstract**:

Flapping-fin unmanned underwater vehicle (UUV) propulsion systems enable high maneuverability for tasks ranging from station-keeping to surveillance but are often constrained by their limited computational power and battery capacity. Previous research has demonstrated that time-series neural network models can accurately predict the thrust and power of certain fin kinematics based on the specified gait coupled with the fin configuration, but can not fit an inverse neural network that takes a thrust request and tunes the kinematics by weighting thrust generation, smooth movement transitions, and power attributes. We study various combinations of the three weights and fin materials to create different ‘modes’ of movement for a multi-objective UUV, based on controller intent using an inverse neural network. Finally, we implement and validate an enhanced power-aware inverse model by benchmarking on the Raspberry Pi Model 4B system and testing through generated simulated movements.

----

## [2815] Multi-Expert Distillation for Few-Shot Coordination (Student Abstract)

**Authors**: *Yujian Zhu, Hao Ding, Zongzhang Zhang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30539](https://doi.org/10.1609/aaai.v38i21.30539)

**Abstract**:

Ad hoc teamwork is a crucial challenge that aims to design an agent capable of effective collaboration with teammates employing diverse strategies without prior coordination. However, current Population-Based Training (PBT) approaches train the ad hoc agent through interaction with diverse teammates from scratch, which suffer from low efficiency. We introduce Multi-Expert Distillation (MED), a novel approach that directly distills diverse strategies through modeling across-episodic sequences. Experiments show that our algorithm achieves more efficient and stable training and has the ability to improve its behavior using historical contexts. Our code is available at https://github.com/LAMDA-RL/MED.

----

## [2816] LLM-Powered Synthetic Environments for Self-Driving Scenarios

**Authors**: *Oluwanifemi Adebayo Moses Adekanye*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30540](https://doi.org/10.1609/aaai.v38i21.30540)

**Abstract**:

This paper outlines a proposal exploring the potential use of Large Language Models (LLMs), particularly GPT-4, in crafting realistic synthetic environments for self-driving scenarios. The envisioned approach involves dynamic scene generation within game engines, leveraging LLMs to introduce challenging elements for autonomous vehicles. The proposed evaluation process outlines assessments such as realistic testing, safety metrics, and user interaction, aiming to set the stage for potential improvements in self-driving system performance.
The paper aims to contribute to the AI field by discussing how LLMs could be utilized to create valuable testing grounds for autonomous vehicles, potentially fostering the development of more robust self-driving technology. The envisioned impact is the eventual enhancement of road safety and the possible acceleration of the adoption of autonomous vehicles, paving the way for a future with safer and more efficient transportation.

----

## [2817] Integrating Neural Pathways for Learning in Deep Reinforcement Learning Models

**Authors**: *Varun Ananth*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30541](https://doi.org/10.1609/aaai.v38i21.30541)

**Abstract**:

Considering that the human brain is the most powerful, generalizable, and energy-efficient computer we know of, it makes the most sense to look to neuroscience for ideas regarding deep learning model improvements. I propose one such idea, augmenting a traditional Advantage-Actor-Critic (A2C) model with additional learning signals akin to those in the brain. Pursuing this direction of research should hopefully result in a new reinforcement learning (RL) control paradigm that can learn from fewer examples, train with greater stability, and possibly consume less energy.

----

## [2818] Evaluating AI Red Teaming's Readiness to Address Environmental Harms: A Thematic Analysis of LLM Discourse

**Authors**: *Amy Au*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30542](https://doi.org/10.1609/aaai.v38i21.30542)

**Abstract**:

This research explores the discourse surrounding red teaming and aims to identify any themes in the online discussion of potential environmental harms stemming from Large Language Models (LLMs). Focusing on the AI Red Teaming event at DEFCON 31, this study employs reflexive thematic analysis on diverse social networking site sources to extract insights into public discussion of LLM red teaming and its environmental implications. The findings intend to inform future research, highlighting the need for responsible AI development that addresses environmental concerns.

----

## [2819] Enhancing Healthcare Predictions with Deep Learning Models

**Authors**: *Adam Baji*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30543](https://doi.org/10.1609/aaai.v38i21.30543)

**Abstract**:

This study leverages Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to enhance diagnostics and predictions in healthcare. By training on extensive healthcare datasets, this project aims to improve early disease detection and health risk assessments. Evaluation emphasizes accuracy, reliability, and ethical considerations, including bias mitigation. This research promises to bridge AI advancements and clinical applications, offering significant improvements in diagnostic capabilities and healthcare accessibility.

----

## [2820] Securing Billion Bluetooth Devices Leveraging Learning-Based Techniques

**Authors**: *Hanlin Cai*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30544](https://doi.org/10.1609/aaai.v38i21.30544)

**Abstract**:

As the most popular low-power communication protocol, cybersecurity research on Bluetooth Low Energy (BLE) has garnered significant attention. Due to BLE’s inherent security limitations and firmware vulnerabilities, spoofing attacks can easily compromise BLE devices and tamper with privacy data. In this paper, we proposed BLEGuard, a hybrid detection mechanism combined cyber-physical features with learning-based techniques. We established a physical network testbed to conduct attack simulations and capture advertising packets. Four different network features were utilized to implement detection and classification algorithms. Preliminary results have verified the feasibility of our proposed methods.

----

## [2821] Flow-Event Autoencoder: Event Stream Object Recognition Dataset Generation with Arbitrary High Temporal Resolution

**Authors**: *Minghai Chen*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30545](https://doi.org/10.1609/aaai.v38i21.30545)

**Abstract**:

Event camera has unique advantages in high temporal resolution and dynamic range and has shown potentials in several computer vision tasks. However, due to the novelty of this hardware, there’s a lack of large benchmark DVS event-stream datasets, including datasets for object recognition. In this work, we proposed an encoder-decoder method to augment event stream dataset from image and optical flow with arbitrary temporal resolution for object recognition task. We believe this proposed method can be generalized well in augmenting event stream vision data for object recognition and will help advance the development of event vision paradigm.

----

## [2822] Revolutionizing Education through AI-Powered Inclusive Learning Systems

**Authors**: *Chahana Dahal*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30546](https://doi.org/10.1609/aaai.v38i21.30546)

**Abstract**:

This proposal introduces an innovative AI-powered learning system designed to address educational disparities worldwide. Focused on developing countries, the system seamlessly translates educational content between English and native languages, breaking down language barriers. Leveraging advanced natural language processing and machine learning techniques, including transformer models like BERT and GPT-3, the system ensures inclusivity, effectiveness, and engagement.

Built on prior research demonstrating AI's efficacy in language translation and personalized learning, the proposed system draws inspiration from successful projects like Duolingo Language Incubator. By providing inclusive and accessible learning experiences, it empowers individuals to overcome language barriers, fostering global participation.

The potential impact is significant, with the system poised to accelerate learning, enhance literacy rates, and create a more skilled workforce in developing countries. This research reflects a commitment to revolutionize education through technology, aiming for lasting and transformative contributions to global society. Through AI-driven education, a brighter, more inclusive future is envisioned.

----

## [2823] Enhancing Robotics with Cognitive Capabilities

**Authors**: *Joseph Fatoye*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30547](https://doi.org/10.1609/aaai.v38i21.30547)

**Abstract**:

In the pursuit of creating more effective and adaptable robots, the flourishing field of cognitive robotics has arisen to infuse machines with human-like cognitive functions. This paper delves into the significance of cognitive robotics and charts a course for empowering robots with advanced cognitive capabilities. Drawing inspiration from current research in cognitive architectures, the paper underscores the importance of refined perception, language processing, complex decision-making, emotional intelligence, and cognitive synergy. By integrating these cognitive functions into robotic systems, the goal is to equip robots to operate intelligently in dynamic environments, collaborate seamlessly with humans, and adeptly handle diverse tasks. The proposed enhancements mark crucial strides towards the development of more versatile and capable intelligent robots.

----

## [2824] Using Reinforcement Learning to Iteratively Construct Road Networks from Satellite Images and GPS Data

**Authors**: *Isaiah Gallardo*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30548](https://doi.org/10.1609/aaai.v38i21.30548)

**Abstract**:

Constructing road networks manually is a time consuming and labor-intensive process. This paper proposes a new method to iteratively construct road networks using reinforcement learning from a combined tensor-based representation of satellite image and GPS trajectory data.

----

## [2825] Statistically Principled Deep Learning for SAR Image Segmentation

**Authors**: *Cassandra Goldberg*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30549](https://doi.org/10.1609/aaai.v38i21.30549)

**Abstract**:

This paper proposes a novel approach for Synthetic Aperture Radar (SAR) image segmentation by incorporating known statistical properties of SAR into deep learning models. We generate synthetic data using the Generalized Gamma distribution, modify the U-Net architecture to encompass statistical moments, and employ stochastic distance losses for improved segmentation performance. Evaluation against traditional methods will reveal the potential of this approach to advance SAR image analysis, with broader applications in environmental monitoring and general image segmentation tasks.

----

## [2826] A Novel Approach for Longitudinal Modeling of Aging Health and Predicting Mortality Rates

**Authors**: *Hannah Guan*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30550](https://doi.org/10.1609/aaai.v38i21.30550)

**Abstract**:

Aging is a complex stochastic process that affects healthy functioning through various pathways. In contrast to the more commonly used cross-sectional methods, our research focuses on longitudinal modeling of aging, a less explored but crucial area. We have developed a Stochastic Differential Equation (SDE) model, at the forefront of aging research, designed to accurately forecast the health trajectories and survival rates of individuals. This model adeptly delineates the connections between different health indicators and provides clear, interpretable results. Our approach utilizes the SDE framework to encapsulate the inherent uncertainty in the aging process. Moreover, it incorporates a Recurrent Neural Network (RNN) to integrate past health data into future health projections. We plan to train and test our model using a comprehensive dataset tailored for aging studies. This model is not only computationally cost-effective but also highly relevant in assessing health risks in older populations, particularly for those at high risk. It can serve as an essential tool in anticipating and preparing for challenges like infectious disease outbreaks. Overall, our research aims to improve health equity and global health security significantly, offering substantial benefits to public health and deepening our understanding of the aging process.

----

## [2827] Multimodal Ensembling for Zero-Shot Image Classification

**Authors**: *Javon Hickmon*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30551](https://doi.org/10.1609/aaai.v38i21.30551)

**Abstract**:

Artificial intelligence has made significant progress in image classification, an essential task for machine perception to achieve human-level image understanding. Despite recent advances in vision-language fields, multimodal image classification is still challenging, particularly for the following two reasons. First, models with low capacity often suffer from underfitting and thus underperform on fine-grained image classification. Second, it is important to ensure high-quality data with rich cross-modal representations of each class, which is often difficult to generate. Here, we utilize ensemble learning to reduce the impact of these issues on pre-trained models. We aim to create a meta-model that combines the predictions of multiple open-vocabulary multimodal models trained on different data to create more robust and accurate predictions. By utilizing ensemble learning and multimodal machine learning, we will achieve higher prediction accuracies without any additional training or fine-tuning, meaning that this method is completely zero-shot.

----

## [2828] Vision-Language Models for Robot Success Detection

**Authors**: *Fiona Luo*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30552](https://doi.org/10.1609/aaai.v38i21.30552)

**Abstract**:

In this work, we use Vision-Language Models (VLMs) as a binary success detector given a robot observation and task description, formulated as a Visual Question Answering (VQA) problem. We fine-tune the open-source MiniGPT-4 VLM to detect success on robot trajectories from the Berkeley Bridge and Berkeley AUTOLab UR5 datasets. We find that while a handful of test distribution trajectories can train an accurate detector, transferring learning between different environments is challenging due to distribution shift. In addition, while our VLM is robust to language variations, it is less robust to visual variations. In the future, more powerful VLMs such as Gemini and GPT-4 have the potential to be more accurate and robust success detectors, and success detectors can provide a sparse binary reward to improve existing policies.

----

## [2829] Transforming Healthcare: A Comprehensive Approach to Mitigating Bias and Fostering Empathy through AI-Driven Augmented Reality

**Authors**: *Erica Okeh*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30553](https://doi.org/10.1609/aaai.v38i21.30553)

**Abstract**:

The integration of Artificial Intelligence (AI) into Augmented Reality (AR) for medical applications is propelled by the aim to address evident healthcare disparities. Certain communities have encountered disparities in medical diagnoses, exemplified by Black individuals exhibiting a 2.4 times higher likelihood of schizophrenia diagnosis compared to their white counterparts (Faber et al., 2023). These disparities often arise from structured interview assessments overlooking cultural nuances, resulting in increased misdiagnosis rates. This study leverages AI and AR to develop unbiased diagnostic tools and enhance empathy in healthcare professionals' training. Uniquely prioritizing the reduction of biased language and the fostering of empathy through AI-driven Natural Language Processing (NLP) and AI-driven virtual patients, the research aims to enhance diagnostic accuracy while promoting cultural sensitivity among healthcare professionals. Aligned with broader goals of achieving equitable healthcare and reducing disparities, the evaluation involves pre- and post-training assessments to measure language improvements and empathy enhancements. Successful implementation could lead to a more equitable healthcare landscape, fostering trust in AI-driven systems and ensuring fairer medical care for diverse communities.

----

## [2830] Defog Artificial Intelligence Glasses: Neural Networks for the Imperfect Real World

**Authors**: *Nilton Rojas*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30554](https://doi.org/10.1609/aaai.v38i21.30554)

**Abstract**:

This research investigates the generalization capabilities of neural networks in deep learning when applied to real-world scenarios where data often contains imperfections, focusing on their adaptability to both noisy and non-noisy scenarios for image retrieval tasks. Our study explores approaches to preserve all available data, regardless of quality, for diverse tasks. The evaluation of results varies per task, due to the ultimate goal of developing a technique to extract relevant information while disregarding noise in the final network design for each specific task. The aim is to enhance accessibility and efficiency of AI across diverse tasks, particularly for individuals or countries with limited resources, lacking access to high-quality data. The dedication is directed towards fostering inclusivity and unlocking the potential of AI for wide-spread societal benefit.

----

## [2831] Multi-world Model in Continual Reinforcement Learning

**Authors**: *Kevin Shen*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30555](https://doi.org/10.1609/aaai.v38i21.30555)

**Abstract**:

World Models are made of generative networks that can predict future states of a single environment which it was trained on. This research proposes a Multi-world Model, a foundational model built from World Models for the field of continual reinforcement learning that is trained on many different environments, enabling it to generalize state sequence predictions even for unseen settings.

----

## [2832] AI-Enhanced Art Appreciation: Generating Text from Artwork to Promote Inclusivity

**Authors**: *Tanisha Shende*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30556](https://doi.org/10.1609/aaai.v38i21.30556)

**Abstract**:

Visual art facilitates expression, communication, and connection, yet it remains inaccessible to those who are visually-impaired and those who lack the resources to understand the techniques and history of art. In this work, I propose the development of a generative AI model that generates a description and interpretation of a given artwork. Such research can make art more accessible, support art education, and improve the ability of AI to understand and translate between creative media. Development will begin with a formative study to assess the needs and preferences of blind and low vision people and art experts. Following the formative study, the basic approach is to train the model on a database of artworks and their accompanying descriptions, predict sentiments from extracted visual data, and generate a paragraph closely resembling training textual data and incorporating sentiment analysis. The model will then be evaluated quantitatively through metrics like METEOR and qualitatively through Turing tests in an iterative process.

----

## [2833] Adapted Weighted Aggregation in Federated Learning

**Authors**: *Yitong Tang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30557](https://doi.org/10.1609/aaai.v38i21.30557)

**Abstract**:

This study introduces FedAW, a novel federated learning algorithm that uses a weighted aggregation mechanism sensitive to the quality of client datasets, leading to better model
performance and faster convergence on diverse datasets, validated using Colored MNIST.

----

## [2834] Deep Learning for Style Transfer and Experimentation with Audio Effects and Music Creation

**Authors**: *Ada Tur*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30558](https://doi.org/10.1609/aaai.v38i21.30558)

**Abstract**:

Recent advancements in deep learning have the potential to transform the process of writing and creating music. Models that have the potential to capture and analyze higher-level representations of music and audio can serve to change the field of digital signal processing. In this statement, I propose a set of Music+AI methods that serves to assist with the writing of and melodies, modelling and transferring of timbres, applying a wide variety of audio effects, including research into experimental audio effects, and production of audio samples using style transfers. Writing and producing music is a tedious task that is notably difficult to become proficient in, as many tools to create music both cost sums money and require long-term commitments to study. An all-encompassing framework for music processing would make the process much more accessible and simple and would allow for human art to work alongside technology to advance.

----

## [2835] Validation, Robustness, and Accuracy of Perturbation-Based Sensitivity Analysis Methods for Time-Series Deep Learning Models

**Authors**: *Zhengguang Wang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30559](https://doi.org/10.1609/aaai.v38i21.30559)

**Abstract**:

This work undertakes studies to evaluate Interpretability Methods for Time Series Deep Learning. Sensitivity analysis assesses how input changes affect the output, constituting a key component of interpretation. Among the post-hoc interpretation methods such as back-propagation, perturbation, and approximation, my work will investigate perturbation-based sensitivity Analysis methods on modern Transformer models to benchmark their performances. Specifically, my work intends to answer three research questions: 1) Do different sensitivity analysis methods yield comparable outputs and attribute importance rankings? 2) Using the same sensitivity analysis method, do different Deep Learning models impact the output of the sensitivity analysis? 3) How well do the results from sensitivity analysis methods align with the ground truth?

----

## [2836] SemLa: A Visual Analysis System for Fine-Grained Text Classification

**Authors**: *Munkhtulga Battogtokh, Cosmin Davidescu, Michael Luck, Rita Borgo*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30560](https://doi.org/10.1609/aaai.v38i21.30560)

**Abstract**:

Fine-grained text classification requires models to distinguish between many fine-grained classes that are hard to tell apart. However, despite the increased risk of models relying on confounding features and predictions being especially difficult to interpret in this context, existing work on the interpretability of fine-grained text classification is severely limited. Therefore, we introduce our visual analysis system, SemLa, which incorporates novel visualization techniques that are tailored to this challenge. Our evaluation based on case studies and expert feedback shows that SemLa can be a powerful tool for identifying model weaknesses, making decisions about data annotation, and understanding the root cause of errors.

----

## [2837] Interactive Plan Selection Using Linear Temporal Logic, Disjunctive Action Landmarks, and Natural Language Instruction

**Authors**: *Tathagata Chakraborti, Jungkoo Kang, Francesco Fuggitti, Michael Katz, Shirin Sohrabi*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30561](https://doi.org/10.1609/aaai.v38i21.30561)

**Abstract**:

We present Lemming – a visualization tool for the interactive selection of plans for a given problem, allowing the user to efficiently whittle down the set of plans and select their plan(s) of choice. We demonstrate four different user experiences for this process, three of them based on the principle of using disjunctive action landmarks as guidance to cut down the set of choice points for the user, and one on the use of linear temporal logic (LTL) to impart additional constraints into the plan set using natural language (NL) instruction.

----

## [2838] SOCIALGYM 20: Simulator for Multi-Robot Learning and Navigation in Shared Human Spaces

**Authors**: *Rohan Chandra, Zayne Sprague, Joydeep Biswas*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30562](https://doi.org/10.1609/aaai.v38i21.30562)

**Abstract**:

We present Social Gym 2.0, a simulator for multi-agent navigation research. Our simulator enables navigation for multiple autonomous agents, replicating real-world dynamics in complex indoor environments, including doorways, hallways, intersections, and roundabouts. Unlike current simulators that concentrate on single robots in open spaces, Social Gym 2.0 employs multi-agent reinforcement learning (MARL) to develop optimal navigation policies for multiple robots with diverse, dynamic constraints in complex environments. Social Gym 2.0 also departs from the accepted software design standards by employing a configuration-over-convention paradigm providing the capability to benchmark different MARL algorithms, as well as customize observation and reward functions. Users can additionally create their own environments and evaluate various algorithms, based on both deep reinforcement learning as well as classical navigation, using a broad range of social navigation metrics.

----

## [2839] Enhancing Machine Translation Experiences with Multilingual Knowledge Graphs

**Authors**: *Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Yunyao Li*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30563](https://doi.org/10.1609/aaai.v38i21.30563)

**Abstract**:

Translating entity names, especially when a literal translation is not correct, poses a significant challenge. Although Machine Translation (MT) systems have achieved impressive results, they still struggle to translate cultural nuances and language-specific context. In this work, we show that the integration of multilingual knowledge graphs into MT systems can address this problem and bring two significant benefits: i) improving the translation of utterances that contain entities by leveraging their human-curated aliases from a multilingual knowledge graph, and, ii) increasing the interpretability of the translation process by providing the user with information from the knowledge graph.

----

## [2840] From Static to Dynamic: Knowledge Metabolism for Large Language Models

**Authors**: *Mingzhe Du, Anh Tuan Luu, Bin Ji, See-Kiong Ng*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30564](https://doi.org/10.1609/aaai.v38i21.30564)

**Abstract**:

The immense parameter space of Large Language Models (LLMs) endows them with superior knowledge retention capabilities, allowing them to excel in a variety of natural language processing tasks. However, it also instigates difficulties in consistently tuning LMs to incorporate the most recent knowledge, which may further lead LMs to produce inaccurate and fabricated content. 
To alleviate this issue, we propose a knowledge metabolism framework for LLMs. This framework proactively sustains the credibility of knowledge through an auxiliary external memory component and directly delivers pertinent knowledge for LM inference, thereby suppressing hallucinations caused by obsolete internal knowledge during the LM inference process.
Benchmark experiments demonstrate DynaMind's effectiveness in overcoming this challenge. The code and demo of DynaMind are available at: https://github.com/Elfsong/DynaMind.

----

## [2841] MANDREL: Modular Reinforcement Learning Pipelines for Material Discovery

**Authors**: *Clyde Fare, George K. Holt, Lamogha Chiazor, Michail Smyrnakis, Robert Tracey, Lan Hoang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30565](https://doi.org/10.1609/aaai.v38i21.30565)

**Abstract**:

AI-driven materials discovery is evolving rapidly with new approaches and pipelines for experimentation and design. However, the pipelines are often designed in isolation. We introduce a modular reinforcement learning framework for inter-operable experimentation and design of tailored, novel molecular species. The framework unifies reinforcement learning (RL) pipelines and allows the mixing and matching of choices for the underlying chemical action space, molecular representation, desired molecular properties, and RL algorithm. Our demo showcases the framework's capabilities applied to benchmark problems like quantitative estimate of drug-likeness and PLogP, as well as the design of novel small molecule solvents for carbon capture.

----

## [2842] LLMGuard: Guarding against Unsafe LLM Behavior

**Authors**: *Shubh Goyal, Medha Hira, Shubham Mishra, Sukriti Goyal, Arnav Goel, Niharika Dadu, Kirushikesh D. B., Sameep Mehta, Nishtha Madaan*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30566](https://doi.org/10.1609/aaai.v38i21.30566)

**Abstract**:

Although the rise of Large Language Models (LLMs) in enterprise settings brings new opportunities and capabilities, it also brings challenges, such as the risk of generating inappropriate, biased, or misleading content that violates regulations and can have legal concerns.
To alleviate this, we present "LLMGuard", a tool that monitors user interactions with an LLM application and flags content against specific behaviours or conversation topics. To do this robustly, LLMGuard employs an ensemble of detectors.

----

## [2843] Interactive Visual Task Learning for Robots

**Authors**: *Weiwei Gu, Anant Sah, Nakul Gopalan*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30567](https://doi.org/10.1609/aaai.v38i21.30567)

**Abstract**:

We present a demonstrable framework for robots to learn novel visual concepts and visual tasks via in-situ linguistic interactions with human users. Previous approaches in computer vision have either used large pre-trained visual models to infer novel objects zero-shot, or added novel concepts along with their attributes and representations to a concept hierarchy. We extend the approaches that focus on learning visual concept hierarchies and take this ability one step further to demonstrate novel task solving on robots along with the learned visual concepts. 
To enable a visual concept learner to solve robotics tasks one-shot, we developed two distinct techniques.
Firstly, we propose a novel approach, Hi-Viscont(HIerarchical VISual CONcept learner for Task), which augments information of a novel concept, that is being taught, to its parent nodes within a concept hierarchy. 
This information propagation allows all concepts in a hierarchy to update as novel concepts are taught in a continual learning setting. 
Secondly, we represent a visual task as a scene graph with language annotations, allowing us to create novel permutations of a demonstrated task zero-shot in-situ. 
Combining the two techniques, we present a demonstration on a real robot that learns visual task and concepts in one-shot from in-situ interactions with human users, and generalize to perform a novel visual task of the same type in zero-shot.
As shown by the studies in the main conference paper, our system achieves a success rate of 50% on solving the whole task correctly with generalization where the baseline performs at 14% without any ability to generalize to novel tasks and concepts. 
We will demonstrate our working interactive learning pipeline at AAAI 2024 in person with our robot and other required hardware.

----

## [2844] Fast & Fair: A Collaborative Platform for Fair Division Applications

**Authors**: *Jiatong Han, Warut Suksompong*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30568](https://doi.org/10.1609/aaai.v38i21.30568)

**Abstract**:

Fair division, the study of how to fairly allocate resources among agents, has received substantial interest in the areas of artificial intelligence and multiagent systems. While there is an extensive theoretical literature on fair division by now, the developed algorithms are still mostly confined to research papers and inaccessible to the public. We attempt to bridge this gap by developing Fast & Fair, an open-source web application that hosts a number of fair allocation algorithms with user-friendly interfaces and explainable outcomes. In contrast to existing implementations, Fast & Fair is a collaborative platform that is open to community contributions and thereby facilitates the deployment of additional algorithms.

----

## [2845] Tools Identification By On-Board Adaptation of Vision-and-Language Models

**Authors**: *Jun Hu, Phil Miller, Michael Lomnitz, Saurabh Farkya, Emre Yilmaz, Aswin Raghavan, David C. Zhang, Michael R. Piacentino*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30569](https://doi.org/10.1609/aaai.v38i21.30569)

**Abstract**:

A robotic workshop assistant has been a long-standing grand challenge for robotics, speech, computer vision, and artificial intelligence (AI) research. We revisit the goal of visual identification of tools from human queries in the current era of Large Vision-and-Language models (like GPT-4). We find that current off-the-shelf models (that are trained on internet images) are unable to overcome the domain shift and unable to identify small, obscure tools in cluttered  environments. Furthermore, these models are unable to match tools to their intended purpose or affordances. We present a novel system for online domain adaptation that can be run directly on a small on-board processor. The system uses Hyperdimensional Computing (HD), a fast and efficient neuromorphic method. We adapted CLIP to work with explicit ("I need the hammer") and implicit purpose-driven queries ("Drive these nails"), and even with  depth images as input. This demo allows the user to try out various real tools and interact via free-form audio.

----

## [2846] AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head

**Authors**: *Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jiawei Huang, Jinglin Liu, Yi Ren, Yuexian Zou, Zhou Zhao, Shinji Watanabe*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30570](https://doi.org/10.1609/aaai.v38i21.30570)

**Abstract**:

Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving 16 AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Code can be found in https://github.com/AIGC-Audio/AudioGPT

----

## [2847] Knowledge-Powered Recommendation for an Improved Diet Water Footprint

**Authors**: *Saurav Joshi, Filip Ilievski, Jay Pujara*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30571](https://doi.org/10.1609/aaai.v38i21.30571)

**Abstract**:

According to WWF, 1.1 billion people lack access to water, and 2.7 billion experience water scarcity at least one month a year. By 2025, two-thirds of the world's population may be facing water shortages. This highlights the urgency of managing water usage efficiently, especially in water-intensive sectors like food. This paper proposes a recommendation engine, powered by knowledge graphs, aiming to facilitate sustainable and healthy food consumption. The engine recommends ingredient substitutes in user recipes that improve nutritional value and reduce environmental impact, particularly water footprint. The system architecture includes source identification, information extraction, schema alignment, knowledge graph construction, and user interface development. The research offers a promising tool for promoting healthier eating habits and contributing to water conservation efforts.

----

## [2848] Reading between the Lines: Image-Based Order Detection in OCR for Chinese Historical Documents

**Authors**: *Hsing-Yuan Ma, Hen-Hsen Huang, Chao-Lin Liu*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30572](https://doi.org/10.1609/aaai.v38i21.30572)

**Abstract**:

Chinese historical documents, with their unique layouts and reading patterns, pose significant challenges for traditional Optical Character Recognition (OCR) systems. This paper introduces a tailored OCR system designed to address these complexities, particularly emphasizing the crucial aspect of Reading Order Detection(ROD). Our system operates through a threefold process: text detection using the Differential Binarization++ model, text recognition with the SVTR Net, and a novel ROD approach harnessing raw image features. This innovative method for ROD, inspired by human perception, utilizes visual cues present in raw images to deduce the inherent sequence of ancient texts. Preliminary results show promising reductions in page error rates. By preserving both content and context, our system contributes meaningfully to the accurate and contextual digitization of Chinese historical manuscripts.

----

## [2849] MIDDAG: Where Does Our News Go? Investigating Information Diffusion via Community-Level Information Pathways

**Authors**: *Mingyu Derek Ma, Alexander K. Taylor, Nuan Wen, Yanchen Liu, Po-Nien Kung, Wenna Qin, Shicheng Wen, Azure Zhou, Diyi Yang, Xuezhe Ma, Nanyun Peng, Wei Wang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30573](https://doi.org/10.1609/aaai.v38i21.30573)

**Abstract**:

We present MIDDAG, an intuitive, interactive system that visualizes the information propagation paths on social media triggered by COVID-19-related news articles accompanied by comprehensive insights including user/community susceptibility level, as well as events and popular opinions raised by the crowd while propagating the information. Besides discovering information flow patterns among users, we construct communities among users and develop the propagation forecasting capability, enabling tracing and understanding of how information is disseminated at a higher level. A demo video and more are available at https://info-pathways.github.io.

----

## [2850] ESG Accountability Made Easy: DocQA at Your Service

**Authors**: *Lokesh Mishra, Cesar Berrospi, Kasper Dinkla, Diego Antognini, Francesco Fusco, Benedikt Bothur, Maksym Lysak, Nikolaos Livathinos, Ahmed S. Nassar, Panagiotis Vagenas, Lucas Morin, Christoph Auer, Michele Dolfi, Peter W. J. Staar*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30574](https://doi.org/10.1609/aaai.v38i21.30574)

**Abstract**:

We present Deep Search DocQA. This application enables information extraction from documents via a question-answering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.

----

## [2851] CHICOT: A Developer-Assistance Toolkit for Code Search with High-Level Contextual Information

**Authors**: *Terufumi Morishita, Yuta Koreeda, Atsuki Yamaguchi, Gaku Morio, Osamu Imaichi, Yasuhiro Sogawa*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30575](https://doi.org/10.1609/aaai.v38i21.30575)

**Abstract**:

We propose a source code search system named CHICOT (Code search with HIgh level COnText) to assist developers in reusing existing code.
While previous studies have examined code search on the basis of code-level, fine-grained specifications such as functionality, logic, or implementation, CHICOT addresses a unique mission: code search with high-level contextual information, such as the purpose or domain of a developer's project.
It achieves this feature by first extracting the context information from codebases and then considering this context during the search.
It provides a VSCode plugin for daily coding assistance, and the built-in crawler ensures up-to-date code suggestions.
The case study attests to the utility of CHICOT in real-world scenarios.

----

## [2852] Expressive and Flexible Simulation of Information Spread Strategies in Social Networks Using Planning

**Authors**: *Bharath Muppasani, Vignesh Narayanan, Biplav Srivastava, Michael N. Huhns*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30576](https://doi.org/10.1609/aaai.v38i21.30576)

**Abstract**:

In the digital age, understanding the dynamics of information spread and opinion formation within networks is paramount. This research introduces an innovative framework that combines the principles of opinion dynamics with the strategic capabilities of Automated Planning. We have developed, to the best of our knowledge, the first-ever numeric PDDL tailored for opinion dynamics. Our tool empowers users to visualize intricate networks, simulate the evolution of opinions, and strategically influence that evolution to achieve specific outcomes. By harnessing Automated Planning techniques, our framework offers a nuanced approach to devise sequences of actions tailored to transition a network from its current opinion landscape to a desired state. This holistic approach provides insights into the intricate interplay of individual nodes within a network and paves the way for targeted interventions. Furthermore, the tool facilitates human-AI collaboration, enabling users to not only understand information spread but also devise practical strategies to mitigate potential harmful outcomes arising from it. Demo Video link - https://tinyurl.com/3k7bp99h

----

## [2853] GEAR-Up: Generative AI and External Knowledge-Based Retrieval: Upgrading Scholarly Article Searches for Systematic Reviews

**Authors**: *Kaushik Roy, Vedant Khandelwal, Valerie Vera, Harshul Surana, Heather Heckman, Amit P. Sheth*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30577](https://doi.org/10.1609/aaai.v38i21.30577)

**Abstract**:

This paper addresses the time-intensive nature of systematic reviews (SRs) and proposes a solution leveraging advancements in Generative AI (e.g., ChatGPT) and external knowledge augmentation (e.g., Retrieval-Augmented Generation). The proposed system, GEAR-Up, automates query development and translation in SRs, enhancing efficiency by enriching user queries with context from language models and knowledge graphs. Collaborating with librarians, qualitative evaluations demonstrate improved reproducibility and search strategy quality. Access the demo at https://youtu.be/zMdP56GJ9mU.

----

## [2854] SciSpace Copilot: Empowering Researchers through Intelligent Reading Assistance

**Authors**: *Trinita Roy, Asheesh Kumar, Daksh Raghuvanshi, Siddhant Jain, Goutham Vignesh, Kartik Shinde, Rohan Tondulkar*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30578](https://doi.org/10.1609/aaai.v38i21.30578)

**Abstract**:

We introduce SciSpace Copilot, an AI research assistant that helps in understanding and reading research papers faster by providing a plethora of features. Answering questions from a document has recently become popular using the Retrieval Augmented Generation (RAG) approach. Our tool uses an advanced question-answering pipeline to get accurate answers and also provide exact citations for the same. We provide many more valuable features on scientific text, including generating explanations, generating summaries, adding notes and highlights, and finding related papers from our 200 million corpus. Our tool supports 100+ languages, making research more accessible across language barriers. Thousands of users use SciSpace Copilot on a daily basis by uploading their articles to understand research faster and better. Our tool can be accessed at this link: https://typeset.io.

----

## [2855] Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning

**Authors**: *Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Avisek Naug, Sahand Ghorbanpour*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30579](https://doi.org/10.1609/aaai.v38i21.30579)

**Abstract**:

We present a generic Reinforcement Learning (RL) framework optimized for crafting adversarial attacks on different model types spanning from ECG signal analysis (1D), image classification (2D), and video classification (3D). The framework focuses on identifying sensitive regions and inducing misclassifications with minimal distortions and various distortion types. The novel RL method outperforms state-of-the-art methods for all three applications, proving its efficiency. Our RL approach produces superior localization masks, enhancing interpretability for image classification and ECG analysis models. For applications such as ECG analysis, our platform highlights critical ECG segments for clinicians while ensuring resilience against prevalent distortions. This comprehensive tool aims to bolster both resilience with adversarial training and transparency across varied applications and data types.

----

## [2856] Sustainability of Data Center Digital Twins with Reinforcement Learning

**Authors**: *Soumyendu Sarkar, Avisek Naug, Antonio Guillen, Ricardo Luna Gutierrez, Vineet Gundecha, Ashwin Ramesh Babu, Sajad Mousavi*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30580](https://doi.org/10.1609/aaai.v38i21.30580)

**Abstract**:

The rapid growth of machine learning (ML) has led to an increased demand for computational power, resulting in larger data centers (DCs) and higher energy consumption. To address this issue and reduce carbon emissions, intelligent design and control of DC components such as IT servers, cabinets, HVAC cooling, flexible load shifting, and battery energy storage are essential. However, the complexity of designing and controlling them in tandem presents a significant challenge. While some individual components like CFD-based design and Reinforcement Learning (RL) based HVAC control have been researched, there's a gap in the holistic design and optimization covering all elements simultaneously. To tackle this, we've developed DCRL-Green, a multi-agent RL environment that empowers the ML community to design data centers and research, develop, and refine RL controllers for carbon footprint reduction in DCs. It is a flexible, modular, scalable, and configurable platform that can handle large High Performance Computing (HPC) clusters. Furthermore, in its default setup, DCRL-Green provides a benchmark for evaluating single as well as multi-agent RL algorithms. It easily allows users to subclass the default implementations and design their own control approaches, encouraging community development for sustainable data centers. Open Source Link: https://github.com/HewlettPackard/dc-rl

----

## [2857] EmFORE: Learning Email Folder Classification Rules by Demonstration

**Authors**: *Mukul Singh, Gust Verbruggen, José Cambronero, Vu Le, Sumit Gulwani*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30581](https://doi.org/10.1609/aaai.v38i21.30581)

**Abstract**:

Tools that help with email folder management are limited, as users have to manually write rules to assign emails to folders. We present EMFORE, an iterative learning system that automatically learns and updates such rules from observations. EMFORE is fast enough to suggest and update rules in real time and suppresses mails with low confidence to reduce the number of false positives. EMFORE can use different rule grammars, and thus be adapted to different clients, without changing the user experience. Previous methods do not learn rules, require complete retraining or multiple new examples after making a mistake, and do not distinguish between inbox and other folders. EMFORE learns rules incrementally and can make the neutral decision of leaving emails in the inbox, making it an ideal candidate for integration in email clients.

----

## [2858] Interactive Human-Centric Bias Mitigation

**Authors**: *Inge Vejsbjerg, Elizabeth M. Daly, Rahul Nair, Svetoslav Nizhnichenkov*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30582](https://doi.org/10.1609/aaai.v38i21.30582)

**Abstract**:

Bias mitigation algorithms differ in their definition of bias and how they go about achieving that objective. Bias mitigation algorithms impact different cohorts differently and allowing end users and data scientists to understand the impact of these differences in order to make informed choices is a relatively unexplored domain. This demonstration presents an interactive bias mitigation pipeline that allows users to understand the cohorts impacted by their algorithm choice and provide feedback in order to provide a bias mitigated pipeline that most aligns with their goals.

----

## [2859] Visual Language - Let the Product Say What You Want

**Authors**: *Jiaying Wang, Shuailing Hao, Jing Shan, Xiaoxu Song*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30583](https://doi.org/10.1609/aaai.v38i21.30583)

**Abstract**:

Visual Language is a multitasking on-line system focusing on e-commerce, which involves in generating accurate product descriptions for sellers and providing convenient product retrieval service for customers. To achieve this goal, the system adopts image description technology and multi-modal retrieval technology. 
By utilizing cross-modal generation technique, we could help sellers on rapid uploading products and customers on rapid retrieval, which could improve the experience of both sellers and customers.

----

## [2860] The CoachAI Badminton Environment: Bridging the Gap between a Reinforcement Learning Environment and Real-World Badminton Games

**Authors**: *Kuang-Da Wang, Yu-Tse Chen, Yu-Heng Lin, Wei-Yao Wang, Wen-Chih Peng*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30584](https://doi.org/10.1609/aaai.v38i21.30584)

**Abstract**:

We present the CoachAI Badminton Environment, a reinforcement learning (RL) environment tailored for AI-driven sports analytics. In contrast to traditional environments using rule-based opponents or simplistic physics-based randomness, our environment integrates authentic opponent AIs and realistic randomness derived from real-world matches data to bridge the performance gap encountered in real-game deployments. This novel feature enables RL agents to seamlessly adapt to genuine scenarios. The CoachAI Badminton Environment empowers researchers to validate strategies in intricate real-world settings, offering: i) Realistic opponent simulation for RL training; ii) Visualizations for evaluation; and iii) Performance benchmarks for assessing agent capabilities. By bridging the RL environment with actual badminton games, our environment is able to advance the discovery of winning strategies for players. Our code is available at https://github.com/wywyWang/CoachAI-Projects/tree/main/Strategic%20Environment.

----

## [2861] Virtual Try-On: Real-Time Interactive Hybrid Network with High-Fidelity

**Authors**: *Umer Waqas, Yunwan Jeon, Donghun Lee*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30585](https://doi.org/10.1609/aaai.v38i21.30585)

**Abstract**:

A significant upsurge in the fashion e-commerce industry in recent years has brought considerable attention to image-based virtual fitting. This image-based technology allows users to try on clothes virtually without physically touching them. However, the current techniques have notable limitations in terms of real-world scenarios, noisy results, partial clothing categories and computational cost, thus limiting the real-world applications. To address these critical limitations, we propose a hybrid interactive network that allows actual users to interact with the system to try on clothes virtually. The network is composed of state of art keypoint extraction, appearance flow alteration and wrapping modules. The pro-posed network facilitates real-time application with high-quality noise-free results, a variety of clothing categories and efficient computational cost.

----

## [2862] Generation of Visual Representations for Multi-Modal Mathematical Knowledge

**Authors**: *Lianlong Wu, Seewon Choi, Daniel Raggi, Aaron Stockdill, Grecia Garcia Garcia, Fiorenzo Colarusso, Peter C.-H. Cheng, Mateja Jamnik*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30586](https://doi.org/10.1609/aaai.v38i21.30586)

**Abstract**:

In this paper we introduce MaRE, a tool designed to generate representations in multiple modalities for a given mathematical problem while ensuring the correctness and interpretability of the transformations between different representations. The theoretical foundation for this tool is Representational Systems Theory (RST), a mathematical framework for studying the structure and transformations of representations. In MaRE’s web front-end user interface, a set of probability equations in Bayesian Notation can be rigorously transformed into Area Diagrams, Contingency Tables, and Probability Trees with just one click, utilising a back-end engine based on RST. A table of cognitive costs, based on the cognitive Representational Interpretive Structure Theory (RIST), that a representation places on a particular profile of user is produced at the same time. MaRE is general and domain independent, applicable to other representations encoded in RST. It may enhance mathematical education and research, facilitating multi-modal knowledge representation and discovery.

----

## [2863] EasyTS: The Express Lane to Long Time Series Forecasting

**Authors**: *Tiancheng Zhang, Shaoyuan Huang, Cheng Zhang, Xiaofei Wang, Wenyu Wang*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30587](https://doi.org/10.1609/aaai.v38i21.30587)

**Abstract**:

Responding to the escalating interest in long-term forecasting within the industry, we introduce EasyTS, a comprehensive toolkit engineered to streamline data collection, analysis, and model creation procedures. EasyTS acts as a unified solution, driving progress in long-term time series forecasting. The platform provides effortless access to various time series datasets, including a newly open-sourced multi-scenario dataset in the electricity domain. Integrated visualization and analysis tools help unveil inherent data features and relationships. EasyTS facilitates a user-friendly model validation approach with versatile evaluation criteria. This toolkit allows researchers to compare their models proficiently against renowned benchmarks. With our ongoing commitment to expanding our dataset collection and enhancing toolkit functionalities, we aspire to contribute significantly to the time series forecasting domain. Code is available at this repository: https://github.com/EdgeBigBang/EasyTS.git.

----

## [2864] RecWizard: A Toolkit for Conversational Recommendation with Modular, Portable Models and Interactive User Interface

**Authors**: *Zeyuan Zhang, Tanmay Laud, Zihang He, Xiaojie Chen, Xinshuang Liu, Zhouhang Xie, Julian J. McAuley, Zhankui He*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30588](https://doi.org/10.1609/aaai.v38i21.30588)

**Abstract**:

We present a new Python toolkit called RecWizard for Conversational Recommender Systems (CRS). RecWizard offers support for development of models and interactive user interface, drawing from the best practices of the Huggingface ecosystems. CRS with RecWizard are modular, portable, interactive and Large Language Models (LLMs)-friendly, to streamline the learning process and reduce the additional effort for CRS research. For more comprehensive information about RecWizard, please check our GitHub https://github.com/McAuley-Lab/RecWizard.

----

## [2865] NarrativePlay: An Automated System for Crafting Visual Worlds in Novels for Role-Playing

**Authors**: *Runcong Zhao, Wenjia Zhang, Jiazheng Li, Lixing Zhu, Yanran Li, Yulan He, Lin Gui*

**Conference**: *aaai 2024*

**URL**: [https://doi.org/10.1609/aaai.v38i21.30589](https://doi.org/10.1609/aaai.v38i21.30589)

**Abstract**:

In this demo, we present NarrativePlay -- an innovative system enabling users to role-play a fictional character and interact with dynamically generated narrative environments. Unlike existing predefined sandbox approaches, NarrativePlay centres around the main storyline events extracted from the narrative, allowing users to experience the story from the perspective of a character they chose. To design versatile AI agents for diverse scenarios, we employ a framework built on a Large Language Models (LLMs) to extract detailed character traits from text. We also incorporate automatically generated visual displays of narrative settings, character portraits, and character speech, greatly enhancing the overall user experience.

----



[Go to the previous page](AAAI-2024-list14.md)

[Go to the catalog section](README.md)