## [0] Distance Polymatrix Coordination Games

**Authors**: *Alessandro Aloisio, Michele Flammini, Bojana Kodric, Cosimo Vinci*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/1](https://doi.org/10.24963/ijcai.2021/1)

**Abstract**:

In polymatrix coordination games, each player x is a node of a graph and must select an action in her strategy set. Nodes are playing separate bimatrix games with their neighbors in the graph. Namely, the utility of x is given by the preference she has for her action plus, for each neighbor y, a payoff which strictly depends on the mutual actions played by x and y.

We propose the new class of distance polymatrix coordination games, properly generalizing polymatrix coordination games, in which the overall utility of player x further depends on the payoffs arising by mutual actions of players v,z that are the endpoints of edges at any distance h

Keywords:Agent-based and Multi-agent Systems: Algorithmic Game Theory  Agent-based and Multi-agent Systems: Computational Social Choice  Agent-based and Multi-agent Systems: Noncooperative Games

----

## [1] Diversity in Kemeny Rank Aggregation: A Parameterized Approach

**Authors**: *Emmanuel Arrighi, Henning Fernau, Daniel Lokshtanov, Mateus de Oliveira Oliveira, Petra Wolf*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/2](https://doi.org/10.24963/ijcai.2021/2)

**Abstract**:

In its most traditional setting, the main concern of optimization theory is the search for optimal solutions for instances of a given computational problem. A recent trend of research in artificial intelligence, called solution diversity, has focused on the development of notions of optimality that may be more appropriate in settings where subjectivity is essential. The idea is that instead of aiming at the development of algorithms that output a single optimal solution, the goal is to investigate algorithms that output a small set of sufficiently good solutions that are sufficiently diverse from one another. In this way, the user has the opportunity to choose the solution that is most appropriate to the context at hand. It also displays the richness of the solution space. 

When combined with techniques from parameterized complexity theory, the paradigm of diversity of solutions offers a powerful algorithmic framework to address problems of practical relevance. In this work, we investigate the impact of this combination in the field of Kemeny Rank Aggregation, a well-studied class of problems lying in the intersection of order theory and social choice theory and also in the field of order theory itself. In particular, we show that KRA is fixed-parameter tractable with respect to natural parameters providing natural formalizations of the notions of diversity and of the notion of a sufficiently good solution. Our main results work both when considering the traditional setting of aggregation over linearly ordered votes, and in the more general setting where votes are partially ordered.

----

## [2] School Choice with Flexible Diversity Goals and Specialized Seats

**Authors**: *Haris Aziz, Zhaohong Sun*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/3](https://doi.org/10.24963/ijcai.2021/3)

**Abstract**:

We present a new and rich model of school choice with flexible diversity goals and specialized seats. The model also applies to other settings such as public housing allocation with diversity objectives. Our method of expressing flexible diversity goals is also applicable to other settings in moral multi-agent decision making where competing policies need to be balanced when allocating scarce resources. For our matching model, we present a polynomial-time algorithm that satisfies desirable properties, including strategyproofness and stability under several natural subdomains of our problem. We complement the results by providing a clear understanding about what results do not extend when considering the general model.

----

## [3] PROPm Allocations of Indivisible Goods to Multiple Agents

**Authors**: *Artem Baklanov, Pranav Garimidi, Vasilis Gkatzelis, Daniel Schoepflin*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/4](https://doi.org/10.24963/ijcai.2021/4)

**Abstract**:

We study the classic problem of fairly allocating a set of indivisible goods among a group of agents, and focus on the notion of approximate proportionality known as PROPm. Prior work showed that there exists an allocation that satisfies this notion of fairness for instances involving up to five agents, but fell short of proving that this is true in general. We extend this result to show that a PROPm allocation is guaranteed to exist for all instances, independent of the number of agents or goods. Our proof is constructive, providing an algorithm that computes such an allocation and, unlike prior work, the running time of this algorithm is polynomial in both the number of agents and the number of goods.

----

## [4] Learning Within an Instance for Designing High-Revenue Combinatorial Auctions

**Authors**: *Maria-Florina Balcan, Siddharth Prasad, Tuomas Sandholm*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/5](https://doi.org/10.24963/ijcai.2021/5)

**Abstract**:

We develop a new framework for designing truthful, high-revenue (combinatorial) auctions for limited supply. Our mechanism learns within an instance. It generalizes and improves over previously-studied random-sampling mechanisms. It first samples a participatory group of bidders, then samples several learning groups of bidders from the remaining pool of bidders, learns a high-revenue auction from the learning groups, and finally runs that auction on the participatory group. Previous work on random-sampling mechanisms focused primarily on unlimited supply. Limited supply poses additional significant technical challenges, since allocations of items to bidders must be feasible. We prove guarantees on the performance of our mechanism based on a market-shrinkage term and a new complexity measure we coin partition discrepancy. Partition discrepancy simultaneously measures the intrinsic complexity of the mechanism class and the uniformity of the set of bidders. We then introduce new auction classes that can be parameterized in a way that does not depend on the number of bidders participating, and prove strong guarantees for these classes. We show how our mechanism can be implemented efficiently by leveraging practically-efficient routines for solving winner determination. Finally, we show how to use structural revenue maximization to decide what auction class to use with our framework when there is a constraint on the number of learning groups.

----

## [5] Combining Fairness and Optimality when Selecting and Allocating Projects

**Authors**: *Khaled Belahcène, Vincent Mousseau, Anaëlle Wilczynski*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/6](https://doi.org/10.24963/ijcai.2021/6)

**Abstract**:

We consider the problem of the conjoint selection and allocation of projects to a population of agents, e.g. students are assigned papers and shall present them to their peers. The selection can be constrained either by quotas over subcategories of projects, or by the preferences of the agents themselves. We explore fairness and optimality issues and refine the analysis of the rank-maximality and popularity optimality concepts. We show that they are compatible with reasonable fairness requirements related to rank-based envy-freeness and can be adapted to select globally good projects according to the preferences of the agents.

----

## [6] Two Influence Maximization Games on Graphs Made Temporal

**Authors**: *Niclas Boehmer, Vincent Froese, Julia Henkel, Yvonne Lasars, Rolf Niedermeier, Malte Renken*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/7](https://doi.org/10.24963/ijcai.2021/7)

**Abstract**:

To address the dynamic nature of real-world networks, we generalize competitive diffusion games and Voronoi games from static to temporal graphs, where edges may appear or disappear over time. This establishes a new direction of studies in the area of graph games, motivated by applications such as influence spreading. As a first step, we investigate the existence of Nash equilibria in competitive diffusion and Voronoi games on different temporal graph classes. Even when restricting our studies to temporal paths and cycles, this turns out to be a challenging undertaking, revealing significant differences between the two games in the temporal setting. Notably, both games are equivalent on static paths and cycles. Our two main technical results are (algorithmic) proofs for the existence of Nash equilibria in temporal competitive diffusion and temporal Voronoi games when the edges are restricted not to disappear over time.

----

## [7] Winner Robustness via Swap- and Shift-Bribery: Parameterized Counting Complexity and Experiments

**Authors**: *Niclas Boehmer, Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/8](https://doi.org/10.24963/ijcai.2021/8)

**Abstract**:

We study the parameterized complexity of counting variants of Swap- and Shift-Bribery, focusing on the parameterizations by the number of swaps and the number of voters. Facing several computational hardness results, using sampling we show experimentally that Swap-Bribery offers a new approach to the robustness analysis of elections.

----

## [8] Putting a Compass on the Map of Elections

**Authors**: *Niclas Boehmer, Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier, Stanislaw Szufa*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/9](https://doi.org/10.24963/ijcai.2021/9)

**Abstract**:

In their AAMAS 2020 paper, Szufa et al. presented a "map of elections" that visualizes a set of 800 elections generated from various statistical cultures. While similar elections are grouped together on this map, there is no obvious interpretation of the elections' positions. We provide such an interpretation by introducing four canonical “extreme” elections, acting as a compass on the map. We use them to analyze both a dataset provided by Szufa et al. and a number of real-life elections. In effect, we find a new parameterization of the Mallows model, based on measuring the expected swap distance from the central preference order, and show that it is useful for capturing real-life scenarios.

----

## [9] Loyalty in Cardinal Hedonic Games

**Authors**: *Martin Bullinger, Stefan Kober*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/10](https://doi.org/10.24963/ijcai.2021/10)

**Abstract**:

A common theme of decision making in multi-agent systems is to assign utilities to alternatives, which individuals seek to maximize. This rationale is questionable in coalition formation where agents are affected by other members of their coalition. Based on the assumption that agents are benevolent towards other agents they like to form coalitions with, we propose loyalty in hedonic games, a binary relation dependent on agents' utilities. Given a hedonic game, we define a loyal variant where agents' utilities are defined by taking the minimum of their utility and the utilities of agents towards which they are loyal. This process can be iterated to obtain various degrees of loyalty, terminating in a locally egalitarian variant of the original game.
We investigate axioms of group stability and efficiency for different degrees of loyalty. Specifically, we consider the problem of finding coalition structures in the core and of computing best coalitions, obtaining both positive and intractability results. In particular, the limit game possesses Pareto optimal coalition structures in the core.

----

## [10] Approximating the Shapley Value Using Stratified Empirical Bernstein Sampling

**Authors**: *Mark Alexander Burgess, Archie C. Chapman*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/11](https://doi.org/10.24963/ijcai.2021/11)

**Abstract**:

The Shapley value is a well recognised method for dividing the value of joint effort in cooperative games. However, computing the Shapley value is known to be computationally hard, so stratified sample-based estimation is sometimes used. For this task, we provide two contributions to the state of the art. First, we derive a novel concentration inequality that is tailored to stratified Shapley value estimation using sample variance information. Second, by sequentially choosing samples to minimize our inequality, we develop a new and more efficient method of sampling to estimate the Shapley value. We evaluate our sampling method on a suite of test cooperative games, and our results demonstrate that it outperforms or is competitive with existing stratified sample-based estimation approaches to computing the Shapley value.

----

## [11] Picking Sequences and Monotonicity in Weighted Fair Division

**Authors**: *Mithun Chakraborty, Ulrike Schmidt-Kraepelin, Warut Suksompong*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/12](https://doi.org/10.24963/ijcai.2021/12)

**Abstract**:

We study the problem of fairly allocating indivisible items to agents with different entitlements, which captures, for example, the distribution of ministries among political parties in a coalition government. Our focus is on picking sequences derived from common apportionment methods, including five traditional divisor methods and the quota method. We paint a complete picture of these methods in relation to known envy-freeness and proportionality relaxations for indivisible items as well as monotonicity properties with respect to the resource, population, and weights. In addition, we provide characterizations of picking sequences satisfying each of the fairness notions, and show that the well-studied maximum Nash welfare solution fails resource- and population-monotonicity even in the unweighted setting. Our results serve as an argument in favor of using picking sequences in weighted fair division problems.

----

## [12] Fractional Matchings under Preferences: Stability and Optimality

**Authors**: *Jiehua Chen, Sanjukta Roy, Manuel Sorge*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/13](https://doi.org/10.24963/ijcai.2021/13)

**Abstract**:

We study generalizations of stable matching in which agents may be matched fractionally; this models time-sharing assignments. We focus on the so-called ordinal stability and cardinal stability, and investigate the computational complexity of finding an ordinally stable or cardinally stable fractional matching which either maximizes the social welfare (i.e., the overall utilities of the agents) or the number of fully matched agents (i.e., agents whose matching values sum up to one). We complete the complexity classification of both optimization problems for both ordinal stability and cardinal stability, distinguishing between the marriage (bipartite) and roommates (non-bipartite) cases and the presence or absence of ties in the preferences. In particular, we prove a surprising result that finding a cardinally stable fractional matching with maximum social welfare is NP-hard even for the marriage case without ties. This answers an open question and exemplifies a rare variant of stable marriage that remains hard for preferences without ties. We also complete the picture of the relations of the stability notions and derive structural properties.

----

## [13] Temporal Induced Self-Play for Stochastic Bayesian Games

**Authors**: *Weizhe Chen, Zihan Zhou, Yi Wu, Fei Fang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/14](https://doi.org/10.24963/ijcai.2021/14)

**Abstract**:

One practical requirement in solving dynamic games is to ensure that the players play well from any decision point onward. To satisfy this requirement, existing efforts focus on equilibrium refinement, but the scalability and applicability of existing techniques are limited. In this paper, we propose Temporal-Induced Self-Play (TISP), a novel reinforcement learning-based framework to find strategies with decent performances from any decision point onward. TISP uses belief-space representation, backward induction, policy learning, and non-parametric approximation. Building upon TISP, we design a policy-gradient-based algorithm TISP-PG. We prove that TISP-based algorithms can find approximate Perfect Bayesian Equilibrium in zero-sum one-sided stochastic Bayesian games with finite horizon. We test TISP-based algorithms in various games, including finitely repeated security games and a grid-world game. The results show that TISP-PG is more scalable than existing mathematical programming-based methods and significantly outperforms other learning-based methods.

----

## [14] Cooperation in Threshold Public Projects with Binary Actions

**Authors**: *Yiling Chen, Biaoshuai Tao, Fang-Yi Yu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/15](https://doi.org/10.24963/ijcai.2021/15)

**Abstract**:

When can cooperation arise from self-interested decisions in public goods games? And how can we help agents to act cooperatively? We examine these classical questions in a pivotal participation game, a variant of public good games, where heterogeneous agents make binary participation decisions on contributing their endowments, and the public project succeeds when it has enough contributions. 

We prove it is NP-complete to decide the existence of a cooperative Nash equilibrium such that the project succeeds. We demonstrate that the decision problem becomes easy if agents are homogeneous enough.  
We then propose two algorithms to help cooperation in the game.  Our first algorithm adds an external investment to the public project, and our second algorithm uses matching funds.  We show the cost to induce a cooperative Nash equilibrium is near-optimal for both algorithms.  Finally, the cost of matching funds can always be smaller than the cost of adding an external investment. Intuitively, matching funds provide a greater incentive for cooperation than adding an external investment does.

----

## [15] Learning in Markets: Greed Leads to Chaos but Following the Price is Right

**Authors**: *Yun Kuen Cheung, Stefanos Leonardos, Georgios Piliouras*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/16](https://doi.org/10.24963/ijcai.2021/16)

**Abstract**:

We study learning dynamics in distributed production economies such as blockchain mining, peer-to-peer file sharing and crowdsourcing. These economies can be modelled as multi-product Cournot competitions or all-pay auctions (Tullock contests) when individual firms have market power, or as Fisher markets with quasi-linear utilities when every firm has negligible influence on market outcomes. In the former case, we provide a formal proof that Gradient Ascent (GA) can be Li-Yorke chaotic for a step size as small as Î˜(1/n), where n is the number of firms. In stark contrast, for the Fisher market case, we derive a Proportional Response (PR) protocol that converges to market equilibrium. The positive results on the convergence of the PR dynamics are obtained in full generality, in the sense that they hold for Fisher markets with any quasi-linear utility functions. Conversely, the chaos results for the GA dynamics are established even in the simplest possible setting of two firms and one good, and they hold for a wide range of price functions with different demand elasticities. Our findings suggest that by considering multi-agent interactions from a market rather than a game-theoretic perspective, we can formally derive natural learning protocols which are stable and converge to effective outcomes rather than being chaotic.

----

## [16] Identifying Norms from Observation Using MCMC Sampling

**Authors**: *Stephen Cranefield, Ashish Dhiman*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/17](https://doi.org/10.24963/ijcai.2021/17)

**Abstract**:

To promote efficient interactions in dynamic and multi-agent systems, there is much interest in techniques that allow agents to represent and reason about social norms that govern agent interactions. Much of this work assumes that norms are provided to agents, but some work has investigated how agents can identify the norms present in a society through observation and experience. However, the norm-identification techniques proposed in the literature often depend on a very specific and domain-specific representation of norms, or require that the possible norms can be enumerated in advance. This paper investigates the problem of identifying norm candidates from a normative language expressed as a probabilistic context-free grammar, using Markov Chain Monte Carlo (MCMC) search. We apply our technique to a simulated robot manipulator task and show that it allows effective identification of norms from observation.

----

## [17] Improving Multi-agent Coordination by Learning to Estimate Contention

**Authors**: *Panayiotis Danassis, Florian Wiedemair, Boi Faltings*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/18](https://doi.org/10.24963/ijcai.2021/18)

**Abstract**:

We present a multi-agent learning algorithm, ALMA-Learning, for efficient and fair allocations in large-scale systems. We circumvent the traditional pitfalls of multi-agent learning (e.g., the moving target problem, the curse of dimensionality, or the need for mutually consistent actions) by relying on the ALMA heuristic as a coordination mechanism for each stage game. ALMA-Learning is decentralized, observes only own action/reward pairs, requires no inter-agent communication, and achieves near-optimal (<5% loss) and fair coordination in a variety of synthetic scenarios and a real-world meeting scheduling problem. The lightweight nature and fast learning constitute ALMA-Learning ideal for on-device deployment.

----

## [18] Multi-Agent Intention Progression with Black-Box Agents

**Authors**: *Michael Dann, Yuan Yao, Brian Logan, John Thangarajah*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/19](https://doi.org/10.24963/ijcai.2021/19)

**Abstract**:

We propose a new approach to intention progression in multi-agent settings where other agents are effectively black boxes. That is, while their goals are known, the precise programs used to achieve these goals are not known. In our approach, agents use an abstraction of their own program called a partially-ordered goal-plan tree (pGPT) to schedule their intentions and predict the actions of other agents. We show how a pGPT can be derived from the program of a BDI agent, and present an approach based on Monte Carlo Tree Search (MCTS) for scheduling an agent's intentions using pGPTs. We evaluate our pGPT-based approach in cooperative, selfish and adversarial multi-agent settings, and show that it out-performs MCTS-based scheduling where agents assume that other agents have the same program as themselves.

----

## [19] The Parameterized Complexity of Connected Fair Division

**Authors**: *Argyrios Deligkas, Eduard Eiben, Robert Ganian, Thekla Hamm, Sebastian Ordyniak*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/20](https://doi.org/10.24963/ijcai.2021/20)

**Abstract**:

We study the Connected Fair Division problem (CFD), which generalizes the fundamental problem of fairly allocating resources to agents by requiring that the items allocated to each agent form a connected subgraph in a provided item graph G. We expand on previous results by providing a comprehensive complexity-theoretic understanding of CFD based on several new algorithms and lower bounds while taking into account several well-established notions of fairness: proportionality, envy-freeness, EF1 and EFX. In particular, we show that to achieve tractability, one needs to restrict both the agents and the item graph in a meaningful way. We design (XP)-algorithms for the problem parameterized by (1) clique-width of G plus the number of agents and (2) treewidth of G plus the number of agent types, along with corresponding lower bounds. Finally, we show that to achieve fixed-parameter tractability, one needs to not only use a more restrictive parameterization of G, but also include the maximum item valuation as an additional parameter.

----

## [20] Neural Regret-Matching for Distributed Constraint Optimization Problems

**Authors**: *Yanchen Deng, Runsheng Yu, Xinrun Wang, Bo An*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/21](https://doi.org/10.24963/ijcai.2021/21)

**Abstract**:

Distributed constraint optimization problems (DCOPs) are a powerful model for multi-agent coordination and optimization, where information and controls are distributed among multiple agents by nature. Sampling-based algorithms are important incomplete techniques for solving medium-scale DCOPs. However, they use tables to exactly store all the information (e.g., costs, confidence bounds) to facilitate sampling, which limits their scalability. This paper tackles the limitation by incorporating deep neural networks in solving DCOPs for the first time and presents a neural-based sampling scheme built upon regret-matching. In the algorithm, each agent trains a neural network to approximate the regret related to its local problem and performs sampling according to the estimated regret. Furthermore, to ensure exploration we propose a regret rounding scheme that rounds small regret values to positive numbers. We theoretically show the regret bound of our algorithm and extensive evaluations indicate that our algorithm can scale up to large-scale DCOPs and significantly outperform the state-of-the-art methods.

----

## [21] Online Selection of Diverse Committees

**Authors**: *Virginie Do, Jamal Atif, Jérôme Lang, Nicolas Usunier*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/22](https://doi.org/10.24963/ijcai.2021/22)

**Abstract**:

Citizens' assemblies need to represent subpopulations according to their proportions in the general population. These large committees are often constructed in an online fashion by contacting people, asking for the demographic features of the volunteers, and deciding to include them or not. This raises a trade-off between the number of people contacted (and the incurring cost) and the representativeness of the committee. We study three methods, theoretically and experimentally: a greedy algorithm that includes volunteers as long as proportionality is not violated; a non-adaptive method that includes a volunteer with a probability depending only on their features, assuming that the joint feature distribution in the volunteer pool is known; and a reinforcement learning based approach when this distribution is not known a priori but learnt online.

----

## [22] Graphical Cake Cutting via Maximin Share

**Authors**: *Edith Elkind, Erel Segal-Halevi, Warut Suksompong*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/23](https://doi.org/10.24963/ijcai.2021/23)

**Abstract**:

We study the recently introduced cake-cutting setting in which the cake is represented by an undirected graph. This generalizes the canonical interval cake and allows for modeling the division of road networks. We show that when the graph is a forest, an allocation satisfying the well-known criterion of maximin share fairness always exists. Our result holds even when separation constraints are imposed; however, in the latter case no multiplicative approximation of proportionality can be guaranteed. Furthermore, while maximin share fairness is not always achievable for general graphs, we prove that ordinal relaxations can be attained.

----

## [23] Keep Your Distance: Land Division With Separation

**Authors**: *Edith Elkind, Erel Segal-Halevi, Warut Suksompong*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/24](https://doi.org/10.24963/ijcai.2021/24)

**Abstract**:

This paper is part of an ongoing endeavor to bring the theory of fair division closer to practice by handling requirements from real-life applications. We focus on two requirements originating from the division of land estates: (1) each agent should receive a plot of a usable geometric shape, and (2) plots of different agents must be physically separated. With these requirements, the classic fairness notion of proportionality is impractical, since it may be impossible to attain any multiplicative approximation of it. In contrast, the ordinal maximin share approximation, introduced by Budish in 2011, provides meaningful fairness guarantees. We prove upper and lower bounds on achievable maximin share guarantees when the usable shapes are squares, fat rectangles, or arbitrary axes-aligned rectangles, and explore the algorithmic and query complexity of finding fair partitions in this setting.

----

## [24] On a Competitive Secretary Problem with Deferred Selections

**Authors**: *Tomer Ezra, Michal Feldman, Ron Kupfer*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/25](https://doi.org/10.24963/ijcai.2021/25)

**Abstract**:

We study the secretary problem in multi-agent environments.  In the standard secretary problem, a sequence of arbitrary awards arrive online, in a random order, and a single decision maker makes an immediate and irrevocable decision whether to accept each award upon its arrival.  The requirement to make immediate decisions arises in many cases due to an implicit assumption regarding competition. Namely, if the decision maker does not take the offered award immediately, it will be taken by someone else. We introduce a novel multi-agent secretary model, in which the competition is explicit.
In our model, multiple agents compete over the arriving awards, but the decisions need not be immediate; instead, agents may select previous awards as long as they are available (i.e., not taken by another agent). If an award is selected by multiple agents, ties are broken either randomly or according to a global ranking.
This induces a multi-agent game in which the time of selection is not enforced by the rules of the games, rather it is an important component of the agent's strategy.
We study the structure and performance of equilibria in this game. 
For random tie breaking, we characterize the equilibria of the  game, and show that the expected social welfare in equilibrium is nearly optimal, despite competition among the agents.
For ranked tie breaking, we give a full characterization of equilibria in the 3-agent game, and show that as the number of agents grows, the winning probability of every agent under non-immediate selections approaches her winning probability under immediate selections.

----

## [25] Relaxed Core Stability in Fractional Hedonic Games

**Authors**: *Angelo Fanelli, Gianpiero Monaco, Luca Moscardelli*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/26](https://doi.org/10.24963/ijcai.2021/26)

**Abstract**:

The core is a well-known and fundamental notion of stability in games intended to model coalition formation such as hedonic games. The fact that the number of deviating agents (that have to coordinate themselves) can be arbitrarily high, and the fact that agents may benefit only by a tiny amount from their deviation (while they could incur in a cost for deviating), suggest that the core is not able to suitably model many practical scenarios in large and highly distributed multi-agent systems. For this reason, we consider relaxed core stable outcomes where the notion of permissible deviations is modified along two orthogonal directions: the former takes into account the size of the deviating coalition, and the latter the amount of utility gain for each member of the deviating coalition. These changes result in two different notions of stability, namely, the q-size core and k-improvement core. We investigate these concepts of stability in fractional hedonic games, that is a well-known subclass of hedonic games for which core stable outcomes are not guaranteed to exist and it is computationally hard to decide nonemptiness of the core. Interestingly, the considered relaxed notions of core also possess the appealing property of recovering, in some notable cases, the convergence, the existence and the possibility of computing stable solutions in polynomial time.

----

## [26] Reasoning over Argument-Incomplete AAFs in the Presence of Correlations

**Authors**: *Bettina Fazzinga, Sergio Flesca, Filippo Furfaro*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/27](https://doi.org/10.24963/ijcai.2021/27)

**Abstract**:

We introduce  "argument-incomplete Abstract Argumentation Frameworks with dependencies", 
that extend the traditional 
abstract argumentation reasoning to the case where some arguments are uncertain 
and correlated through logical dependencies
(such as mutual exclusion, implication, etc.).
We characterize the complexities of the problems DSAT of deciding the satisfiability 
of the
dependencies and  PDVER of verifying extensions,
and show how they depend on the forms of dependencies and, for PDVER, also on the 
semantics of the extensions.

----

## [27] Kemeny Consensus Complexity

**Authors**: *Zack Fitzsimmons, Edith Hemaspaandra*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/28](https://doi.org/10.24963/ijcai.2021/28)

**Abstract**:

The computational study of election problems generally focuses on questions related to the winner or set of winners of an election. But social preference functions such as Kemeny rule output a full ranking of the candidates (a consensus). We study the complexity of consensus-related questions, with a particular focus on Kemeny and its qualitative version Slater. The simplest of these questions is the problem of determining whether a ranking is a consensus, and we show that this problem is coNP-complete. We also study the natural question of the complexity of manipulative actions that have a specific consensus as a goal. Though determining whether a ranking is a Kemeny consensus is hard, the optimal action for manipulators is to simply vote their desired consensus. We provide evidence that this simplicity is caused by the combination of election system (Kemeny), manipulative action (manipulation), and manipulative goal (consensus). In the process we provide the first completeness results at the second level of the polynomial hierarchy for electoral manipulation and for optimal solution recognition.

----

## [28] Two-Sided Matching Meets Fair Division

**Authors**: *Rupert Freeman, Evi Micha, Nisarg Shah*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/29](https://doi.org/10.24963/ijcai.2021/29)

**Abstract**:

We introduce a new model for two-sided matching which allows us to borrow popular fairness notions from the fair division literature such as envy-freeness up to one good and maximin share guarantee. In our model, each agent is matched to multiple agents on the other side over whom she has additive preferences. We demand fairness for each side separately, giving rise to notions such as double envy-freeness up to one match (DEF1) and double maximin share guarantee (DMMS). We show that (a slight strengthening of) DEF1 cannot always be achieved, but in the special case where both sides have identical preferences, the round-robin algorithm with a carefully designed agent ordering achieves it. In contrast, DMMS cannot be achieved even when both sides have identical preferences.

----

## [29] Worst-case Bounds on Power vs Proportion in Weighted Voting Games with Application to False-name Manipulation

**Authors**: *Yotam Gafni, Ron Lavi, Moshe Tennenholtz*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/30](https://doi.org/10.24963/ijcai.2021/30)

**Abstract**:

Weighted voting games are applicable to a wide variety of multi-agent settings. They
enable the formalization of power indices which quantify the coalitional power of players. We take a novel approach to the study of the power of big vs.~small players in these games. We model small (big) players as having single (multiple) votes. The aggregate relative power of big players is measured w.r.t.~their votes proportion. 
For this ratio, we show small constant worst-case bounds for the Shapley-Shubik and the Deegan-Packel indices. In sharp contrast, this ratio is unbounded for the Banzhaf index. As an application, we define a false-name strategic normal form game where each big player may split its votes between false identities, and study its various properties. Together our results provide foundations for the implications of players' size, modeled as their ability to split, on their relative power.

----

## [30] Even More Effort Towards Improved Bounds and Fixed-Parameter Tractability for Multiwinner Rules

**Authors**: *Sushmita Gupta, Pallavi Jain, Saket Saurabh, Nimrod Talmon*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/31](https://doi.org/10.24963/ijcai.2021/31)

**Abstract**:

Multiwinner elections have proven to be a fruitful research topic with many real world applications. We contribute to this line of research by improving the state of the art regarding the computational complexity of computing good committees. More formally, given a set of candidates C, a set of voters V, each ranking the candidates according to their preferences, and an integer k; a multiwinner voting rule identifies a committee of size k, based on these given voter preferences. In this paper we consider several utilitarian and egailitarian OWA (ordered weighted average) scoring rules, which are an extensively researched family of rules (and a subfamily of the family of committee scoring rules). First, we improve the result of Betzler et al. [JAIR, 2013], which gave a O(n^n) algorithm for computing winner under the Chamberlin Courant rule (CC), where n is the number of voters; to a running time of O(2^n), which is optimal. Furthermore, we study the parameterized complexity of the Pessimist voting rule and describe a few tractable and intractable cases. Apart from such utilitarian voting rules, we extend our study and consider egalitarian median and egalitarian mean (both committee scoring rules), showing some tractable and intractable results, based on nontrivial structural observations.

----

## [31] Fair and Efficient Resource Allocation with Partial Information

**Authors**: *Daniel Halpern, Nisarg Shah*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/32](https://doi.org/10.24963/ijcai.2021/32)

**Abstract**:

We study the fundamental problem of allocating indivisible goods to agents with additive preferences. We consider eliciting from each agent only a ranking of her k most preferred goods instead of her full cardinal valuations. We characterize the amount of preference information that must be elicited in order to satisfy envy-freeness up to one good and approximate maximin share guarantee, two widely studied fairness notions. We also analyze the multiplicative loss in social welfare incurred due to the lack of full information with and without fairness requirements.

----

## [32] Accomplice Manipulation of the Deferred Acceptance Algorithm

**Authors**: *Hadi Hosseini, Fatima Umar, Rohit Vaish*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/33](https://doi.org/10.24963/ijcai.2021/33)

**Abstract**:

The deferred acceptance algorithm is an elegant solution to the stable matching problem that guarantees optimality and truthfulness for one side of the market. Despite these desirable guarantees, it is susceptible to strategic misreporting of preferences by the agents on the other side. We study a novel model of strategic behavior under the deferred acceptance algorithm: manipulation through an accomplice. Here, an agent on the proposed-to side (say, a woman) partners with an agent on the proposing side---an accomplice---to manipulate on her behalf (possibly at the expense of worsening his match). We show that the optimal manipulation strategy for an accomplice comprises of promoting exactly one woman in his true list (i.e., an inconspicuous manipulation). This structural result immediately gives a polynomial-time algorithm for computing an optimal accomplice manipulation. We also study the conditions under which the manipulated matching is stable with respect to the true preferences. Our experimental results show that accomplice manipulation outperforms self manipulation both in terms of the frequency of occurrence as well as the quality of matched partners.

----

## [33] Guaranteeing Maximin Shares: Some Agents Left Behind

**Authors**: *Hadi Hosseini, Andrew Searns*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/34](https://doi.org/10.24963/ijcai.2021/34)

**Abstract**:

The maximin share (MMS) guarantee is a desirable fairness notion for allocating indivisible goods. While MMS allocations do not always exist, several approximation techniques have been developed to ensure that all agents receive a fraction of their maximin share. We focus on an alternative approximation notion, based on the population of agents, that seeks to guarantee MMS for a fraction of agents. We show that no optimal approximation algorithm can satisfy more than a constant number of agents, and discuss the existence and computation of MMS for all but one agent and its relation to approximate MMS guarantees. We then prove the existence of allocations that guarantee MMS for 2/3 of agents, and devise a polynomial time algorithm that achieves this bound for up to nine agents.  A key implication of our result is the existence of allocations that guarantee the value that an agent receives by partitioning the goods into 3n/2 bundles, improving the best known guarantee when goods are partitioned into 2n-2 bundles. Finally, we provide empirical experiments using synthetic data.

----

## [34] Surprisingly Popular Voting Recovers Rankings, Surprisingly!

**Authors**: *Hadi Hosseini, Debmalya Mandal, Nisarg Shah, Kevin Shi*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/35](https://doi.org/10.24963/ijcai.2021/35)

**Abstract**:

The wisdom of the crowd has long become the de facto approach for eliciting information from individuals or experts in order to predict the ground truth. However, classical democratic approaches for aggregating individual \emph{votes} only work when the opinion of the majority of the crowd is relatively accurate. A clever recent approach, \emph{surprisingly popular voting}, elicits additional information from the individuals, namely their \emph{prediction} of other individuals' votes, and provably recovers the ground truth even when experts are in minority. This approach works well when the goal is to pick the correct option from a small list, but when the goal is to recover a true ranking of the alternatives, a direct application of the approach requires eliciting too much information. We explore practical techniques for extending the surprisingly popular algorithm to ranked voting by partial votes and predictions and designing robust aggregation rules. We experimentally demonstrate that even a little prediction information helps surprisingly popular voting outperform classical approaches.

----

## [35] SURPRISE! and When to Schedule It

**Authors**: *Zhihuan Huang, Shengwei Xu, You Shan, Yuxuan Lu, Yuqing Kong, Tracy Xiao Liu, Grant Schoenebeck*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/36](https://doi.org/10.24963/ijcai.2021/36)

**Abstract**:

Information flow measures, over the duration of a game, the audience’s belief of who will win, and thus can reflect the amount of surprise in a game. To quantify the relationship between information flow and audiences' perceived quality, we conduct a case study where subjects watch one of the world’s biggest esports events, LOL S10.  In addition to eliciting information flow, we also ask subjects to report their rating for each game. We find that the amount of surprise in the end of the game plays a dominant role in predicting the rating. This suggests the importance of incorporating when the surprise occurs, in addition to the amount of surprise, in perceived quality models. For content providers, it implies that everything else being equal, it is better for twists to be more likely to happen toward the end of a show rather than uniformly throughout.

----

## [36] Dynamic Proportional Rankings

**Authors**: *Jonas Israel, Markus Brill*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/37](https://doi.org/10.24963/ijcai.2021/37)

**Abstract**:

Proportional ranking rules aggregate approval-style preferences of agents into a collective ranking such that groups of agents with similar preferences are adequately represented. Motivated by the application of live Q&A platforms, where submitted questions need to be ranked based on the interests of the audience, we study a dynamic extension of the proportional rankings setting. In our setting, the goal is to maintain the proportionality of a ranking when alternatives (i.e., questions)---not necessarily from the top of the ranking---get selected sequentially. We propose generalizations of well-known aggregation rules to this setting and study their monotonicity and proportionality properties. We also evaluate the performance of these rules experimentally, using realistic probabilistic assumptions on the selection procedure.

----

## [37] A Polynomial-time, Truthful, Individually Rational and Budget Balanced Ridesharing Mechanism

**Authors**: *Tatsuya Iwase, Sebastian Stein, Enrico H. Gerding*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/38](https://doi.org/10.24963/ijcai.2021/38)

**Abstract**:

Ridesharing has great potential to improve transportation efficiency while reducing congestion and pollution. To realize this potential, mechanisms are needed that allocate vehicles optimally and provide the right incentives to riders. However, many existing approaches consider restricted settings (e.g., 
only one rider per vehicle
or a common origin for all riders). Moreover, 
naive applications of standard approaches, such as the Vickrey-Clarke-Groves or greedy mechanisms, cannot achieve a polynomial-time, truthful, individually rational and budget balanced mechanism. To address this, we formulate a general ridesharing problem and apply mechanism design to develop a novel mechanism which satisfies all four properties and whose social cost is within 8.6% of the optimal on average.

----

## [38] Participatory Budgeting with Project Groups

**Authors**: *Pallavi Jain, Krzysztof Sornat, Nimrod Talmon, Meirav Zehavi*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/39](https://doi.org/10.24963/ijcai.2021/39)

**Abstract**:

We study a generalization of the standard approval-based model of participatory budgeting (PB), in which voters are providing approval ballots over a set of predefined projects and---in addition to a global budget limit---there are several groupings of the projects, each group with its own budget limit. We study the computational complexity of identifying project bundles that maximize voter satisfaction while respecting all budget limits. We show that the problem is generally intractable and describe efficient exact algorithms for several special cases, including instances with only few groups and instances where the group structure is close to being hierarchical, as well as efficient approximation algorithms. Our results could allow, e.g., municipalities to hold richer PB processes that are thematically and geographically inclusive.

----

## [39] Interaction Considerations in Learning from Humans

**Authors**: *Pallavi Koppol, Henny Admoni, Reid G. Simmons*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/40](https://doi.org/10.24963/ijcai.2021/40)

**Abstract**:

The ability to learn from large quantities of complex data has led to the development of intelligent agents such as self-driving cars and assistive devices. This data often comes from people via interactions such as labeling, providing rewards and punishments, and giving demonstrations or critiques. However, people's ability to provide high-quality data can be affected by human factors of an interaction, such as induced cognitive load and perceived usability. We show that these human factors differ significantly between interaction types. We first formalize interactions as a Markov Decision Process, and construct a taxonomy of these interactions to identify four archetypes: Showing, Categorizing, Sorting, and Evaluating. We then run a user study across two task domains. Our findings show that Evaluating interactions are more cognitively loading and less usable than the others, and Categorizing and Showing interactions are the least cognitively loading and most usable.

----

## [40] Two-Stage Facility Location Games with Strategic Clients and Facilities

**Authors**: *Simon Krogmann, Pascal Lenzner, Louise Molitor, Alexander Skopalik*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/41](https://doi.org/10.24963/ijcai.2021/41)

**Abstract**:

We consider non-cooperative facility location games where both facilities and clients act strategically and heavily influence each other. This contrasts established game-theoretic facility location models with non-strategic clients that simply select the closest opened facility. In our model, every facility location has a set of attracted clients and each client has a set of shopping locations and a weight that corresponds to its spending capacity. Facility agents selfishly select a location for opening their facility to maximize the attracted total spending capacity, whereas clients strategically decide how to distribute their spending capacity among the opened facilities in their shopping range. We focus on a natural client behavior similar to classical load balancing: our selfish clients aim for a distribution that minimizes their maximum waiting time for getting serviced, where a facility’s waiting time corresponds to its total attracted client weight.

We show that subgame perfect equilibria exist and we give almost tight constant bounds on the Price of Anarchy and the Price of Stability, which even hold for a broader class of games with arbitrary client behavior. Since facilities and clients influence each other, it is crucial for the facilities to anticipate the selfish clients’ behavior when selecting their location. For this, we provide an efficient algorithm that also implies an efficient check for equilibrium. Finally, we show that computing a socially optimal facility placement is NP-hard and that this result holds for all feasible client weight distributions.

----

## [41] Fairness in Long-Term Participatory Budgeting

**Authors**: *Martin Lackner, Jan Maly, Simon Rey*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/42](https://doi.org/10.24963/ijcai.2021/42)

**Abstract**:

Participatory Budgeting (PB) processes are usually designed to span several years, with referenda for new budget allocations taking place regularly. This paper presents a first formal framework for long-term PB, based on a sequence of budgeting problems as main input. We introduce a theory of fairness for this setting, focusing on three main concepts that apply to types (groups) of voters:
(i) achieving equal welfare for all types, (ii) minimizing inequality of welfare (as measured by the Gini coefficient), and (iii) achieving equal welfare in the long run.
We investigate under which conditions these criteria can be  satisfied, and analyze the computational complexity of verifying whether they hold.

----

## [42] Strategyproof Randomized Social Choice for Restricted Sets of Utility Functions

**Authors**: *Patrick Lederer*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/43](https://doi.org/10.24963/ijcai.2021/43)

**Abstract**:

When aggregating preferences of multiple agents, strategyproofness is a fundamental requirement. For randomized voting rules, so-called social decision schemes (SDSs), strategyproofness is usually formalized with the help of utility functions. A classic result shown by Gibbard in 1977 characterizes the set of SDSs that are strategyproof with respect to all utility functions and shows that these SDSs are either indecisive or unfair. For finding more insights into the trade-off between strategyproofness and decisiveness, we propose the notion of U-strategyproofness which requires that only voters with a utility function in the set U cannot manipulate. In particular, we show that if the utility functions in U value the best alternative much more than other alternatives, there are U-strategyproof SDSs that choose an alternative with probability 1 whenever all but k voters rank it first. We also prove for rank-based SDSs that this large gap in the utilities is required to be strategyproof and that the gap must increase in k. On the negative side, we show that U-strategyproofness is incompatible with Condorcet-consistency if U satisfies minimal symmetry conditions and there are at least four alternatives. For three alternatives, the Condorcet rule can be characterized based on U-strategyproofness for the set U containing all equi-distant utility functions.

----

## [43] Budget-feasible Mechanisms for Representing Groups of Agents Proportionally

**Authors**: *Xiang Liu, Hau Chan, Minming Li, Weiwei Wu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/44](https://doi.org/10.24963/ijcai.2021/44)

**Abstract**:

In this paper, we consider the problem of designing budget-feasible mechanisms 
for selecting agents with private costs from various groups to ensure proportional representation, where the minimum proportion of the selected agents from each group is maximized. Depending on agents' membership in the groups, we consider two main models: single group setting where each agent belongs to only one group, and multiple group setting where each agent may belong to multiple groups. We propose novel budget-feasible proportion-representative mechanisms for these models, which can select representative agents from different groups.  The proposed mechanisms guarantee theoretical properties of individual rationality, budget-feasibility, truthfulness, and approximation performance on proportional representation.

----

## [44] Improving Welfare in One-Sided Matchings using Simple Threshold Queries

**Authors**: *Thomas Ma, Vijay Menon, Kate Larson*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/45](https://doi.org/10.24963/ijcai.2021/45)

**Abstract**:

We study one-sided matching problems where each agent must be assigned at most one object. In this classic problem it is often assumed that agents specify only ordinal preferences over objects and the goal is to return a matching that satisfies some desirable property such as Pareto optimality or rank-maximality. However, agents may have cardinal utilities describing their preference intensities and ignoring this can result in welfare loss. We investigate how to elicit additional cardinal information from agents using simple threshold queries and use it in turn to design algorithms that return a matching satisfying a desirable matching property, while also achieving a good approximation to the optimal welfare among all matchings satisfying that property.  Overall, our results show how one can improve welfare by even non-adaptively asking  agents for just one bit of extra information per object.

----

## [45] Generalized Kings and Single-Elimination Winners in Random Tournaments

**Authors**: *Pasin Manurangsi, Warut Suksompong*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/46](https://doi.org/10.24963/ijcai.2021/46)

**Abstract**:

Tournaments can be used to model a variety of practical scenarios including sports competitions and elections. A natural notion of strength of alternatives in a tournament is a generalized king: an alternative is said to be a k-king if it can reach every other alternative in the tournament via a directed path of length at most k. In this paper, we provide an almost complete characterization of the probability threshold such that all, a large number, or a small number of alternatives are k-kings with high probability in two random models. We show that, perhaps surprisingly, all changes in the threshold occur in the regime of constant k, with the biggest change being between k = 2 and k = 3. In addition, we establish an asymptotically tight bound on the probability threshold for which all alternatives are likely able to win a single-elimination tournament under some bracket.

----

## [46] Almost Envy-Freeness for Groups: Improved Bounds via Discrepancy Theory

**Authors**: *Pasin Manurangsi, Warut Suksompong*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/47](https://doi.org/10.24963/ijcai.2021/47)

**Abstract**:

We study the allocation of indivisible goods among groups of agents using well-known fairness notions such as envy-freeness and proportionality. While these notions cannot always be satisfied, we provide several bounds on the optimal relaxations that can be guaranteed. For instance, our bounds imply that when the number of groups is constant and the $n$ agents are divided into groups arbitrarily, there exists an allocation that is envy-free up to $\Theta(\sqrt{n})$ goods, and this bound is tight. Moreover, we show that while such an allocation can be found efficiently, it is NP-hard to compute an allocation that is envy-free up to $o(\sqrt{n})$ goods even when a fully envy-free allocation exists. Our proofs make extensive use of tools from discrepancy theory.

----

## [47] Winner Determination and Strategic Control in Conditional Approval Voting

**Authors**: *Evangelos Markakis, Georgios Papasotiropoulos*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/48](https://doi.org/10.24963/ijcai.2021/48)

**Abstract**:

Our work focuses on a generalization of the classic Minisum approval voting rule, introduced by Barrot and Lang (2016), and referred to as Conditional Minisum (CMS), for multi-issue elections. 
Although the CMS rule provides much higher levels of expressiveness, this comes at the expense of increased computational complexity. In this work, we study further the issue of efficient algorithms for CMS, and we
identify the condition of bounded treewidth (of an appropriate graph that emerges from the provided ballots), as the necessary and sufficient condition for polynomial algorithms, under common complexity assumptions. Additionally we investigate the complexity of problems related to the strategic control of such elections by the possibility of adding or deleting either voters or alternatives. We exhibit that in most variants of these problems, CMS is resistant against control.

----

## [48] Majority Vote in Social Networks: Make Random Friends or Be Stubborn to Overpower Elites

**Authors**: *Charlotte Out, Ahad N. Zehmakan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/49](https://doi.org/10.24963/ijcai.2021/49)

**Abstract**:

Consider a graph G, representing a social network. Assume that initially each node is colored either black or white, which corresponds to a positive or negative opinion regarding a consumer product or a technological innovation. In the majority model, in each round all nodes simultaneously update their color to the most frequent color among their connections.

Experiments on the graph data from the real world social networks (SNs) suggest that if all nodes in an extremely small set of high-degree nodes, often referred to as the elites, agree on a color, that color becomes the dominant color at the end of the process. We propose two countermeasures that can be adopted by individual nodes relatively easily and guarantee that the elites will not have this disproportionate power to engineer the dominant output color. The first countermeasure essentially requires each node to make some new connections at random while the second one demands the nodes to be more reluctant towards changing their color (opinion). We verify their effectiveness and correctness both theoretically and experimentally.

We also investigate the majority model and a variant of it when the initial coloring is random on the real world SNs and several random graph models. In particular, our results on the Erdős-Rényi, and regular random graphs confirm or support several theoretical findings or conjectures by the prior work regarding the threshold behavior of the process.

Finally, we provide theoretical and experimental evidence for the existence of a poly-logarithmic bound on the expected stabilization time of the majority model.

----

## [49] Mean Field Games Flock! The Reinforcement Learning Way

**Authors**: *Sarah Perrin, Mathieu Laurière, Julien Pérolat, Matthieu Geist, Romuald Élie, Olivier Pietquin*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/50](https://doi.org/10.24963/ijcai.2021/50)

**Abstract**:

We present a method enabling a large number of agents to learn how to flock. This problem has drawn a lot of interest but requires many structural assumptions and is tractable only in small dimensions. We phrase this problem as a Mean Field Game (MFG),  where each individual chooses its own acceleration depending on the population behavior. Combining Deep Reinforcement Learning (RL) and Normalizing Flows (NF), we obtain a tractable solution requiring only very weak assumptions. Our algorithm finds a Nash Equilibrium and the agents adapt their velocity to match the neighboring flock’s average one. We use Fictitious Play and alternate: (1) computing an approximate best response with Deep RL, and (2) estimating the next population distribution with NF. We show numerically that our algorithm can learn multi-group or high-dimensional flocking with obstacles.

----

## [50] Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling

**Authors**: *Naveen Raman, Sanket Shah, John P. Dickerson*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/51](https://doi.org/10.24963/ijcai.2021/51)

**Abstract**:

Rideshare and ride-pooling platforms use artificial intelligence-based matching algorithms to pair riders and drivers. However, these platforms can induce unfairness either through an unequal income distribution or disparate treatment of riders. We investigate two methods to reduce forms of inequality in ride-pooling platforms: by incorporating fairness constraints into the objective function and redistributing income to drivers who deserve more. To test these out, we use New York City taxi data to evaluate their performance on both the rider and driver side. For the first method, we find that optimizing for driver fairness out-performs state-of-the-art models in terms of the number of riders serviced, showing that optimizing for fairness can assist profitability in certain circumstances. For the second method, we explore income redistribution as a method to combat income inequality by having drivers keep an $r$ fraction of their income, and contribute the rest to a redistribution pool. For certain values of $r$, most drivers earn near their Shapley value, while still incentivizing drivers to maximize income, thereby avoiding the free-rider problem and reducing income variability. While the first method is useful because it improves both rider and driver-side fairness, the second method is useful because it improves fairness without affecting profitability, and both methods can be combined to improve rider and driver-side fairness.

----

## [51] Shortlisting Rules and Incentives in an End-to-End Model for Participatory Budgeting

**Authors**: *Simon Rey, Ulle Endriss, Ronald de Haan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/52](https://doi.org/10.24963/ijcai.2021/52)

**Abstract**:

We introduce an end-to-end model for participatory
budgeting grounded in social choice theory. Our
model accounts for the interplay between the two
stages commonly encountered in real-life partici-
patory budgeting. In the first stage participants pro-
pose projects to be shortlisted, while in the second
stage they vote on which of the shortlisted projects
should be funded. Prior work of a formal nature has
focused on analysing the second stage only. We in-
troduce several shortlisting rules for the first stage
and analyse them in both normative and algorith-
mic terms. Our main focus is on the incentives of
participants to engage in strategic behaviour during
the first stage, in which they need to reason about
how their proposals will impact the range of strate-
gies available to everyone in the second stage.

----

## [52] Matchings with Group Fairness Constraints: Online and Offline Algorithms

**Authors**: *Govind S. Sankar, Anand Louis, Meghana Nasre, Prajakta Nimbhorkar*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/53](https://doi.org/10.24963/ijcai.2021/53)

**Abstract**:

We consider the problem of assigning items to platforms in the presence of group fairness constraints. In the input, each item belongs to certain categories, called classes in this paper. Each platform specifies the group fairness constraints through an upper bound on the number of items it can serve from each class. Additionally, each platform also has an upper bound on the total number of items it can serve. The goal is to assign items to platforms so as to maximize the number of items assigned while satisfying the upper bounds of each class. This problem models several important real-world problems like ad-auctions, scheduling, resource allocations, school choice etc. We show that if the classes are arbitrary, then the problem is NP-hard and has a strong inapproximability. We consider the problem in both online and offline settings under natural restrictions on the classes. Under these restrictions, the problem continues to remain NP-hard but admits approximation algorithms with small approximation factors. We also implement some of the algorithms. Our experiments show that the algorithms work well in practice both in terms of efficiency and the number of items that get assigned to some platform.

----

## [53] Stochastic Market Games

**Authors**: *Kyrill Schmid, Lenz Belzner, Robert Müller, Johannes Tochtermann, Claudia Linnhoff-Popien*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/54](https://doi.org/10.24963/ijcai.2021/54)

**Abstract**:

Some of the most relevant future applications of multi-agent systems like autonomous driving or factories as a service display mixed-motive scenarios, where agents might have conflicting goals. In these settings agents are likely to learn undesirable outcomes in terms of cooperation under independent learning, such as overly greedy behavior. Motivated from real world societies, in this work we propose to utilize market forces to provide incentives for agents to become cooperative. As demonstrated in an iterated version of the Prisoner's Dilemma, the proposed market formulation can change the dynamics of the game to consistently learn cooperative policies. Further we evaluate our approach in spatially and temporally extended settings for varying numbers of agents. We empirically find that the presence of markets can improve both the overall result and agent individual returns via their trading activities.

----

## [54] Tango: Declarative Semantics for Multiagent Communication Protocols

**Authors**: *Munindar P. Singh, Samuel H. Christie V.*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/55](https://doi.org/10.24963/ijcai.2021/55)

**Abstract**:

A flexible communication protocol is necessary to build a decentralized multiagent system whose member agents are not coupled to each other's decision making.
Information-based protocol languages capture a protocol in terms of causality and integrity constraints based on the information exchanged by the agents. Thus, they enable highly flexible enactments in which the agents proceed asynchronously and messages may be arbitrarily reordered. However, the existing semantics for such languages can produce a large number of protocol enactments, which makes verification of a protocol property intractable.

This paper formulates a protocol semantics declaratively via inference rules that determine when a message emission or reception becomes enabled during an enactment, and its effect on the local state of an agent.
The semantics enables heuristics for determining when alternative extensions of a current enactment would be equivalent, thereby helping produce parsimonious models and yielding improved protocol verification methods.

----

## [55] Vitality Indices are Equivalent to Induced Game-Theoretic Centralities

**Authors**: *Oskar Skibski*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/56](https://doi.org/10.24963/ijcai.2021/56)

**Abstract**:

Vitality indices form a class of centrality measures that assess the importance of a node based on the impact its removal has on the network. To date, theoretical analysis of this class is lacking. In this paper, we show that vitality indices can be characterized using the axiom of Balanced Contributions proposed by Myerson in the coalitional game theory literature. We explore the link between both fields and show an equivalence between vitality indices and induced game theoretic centralities based on the Shapley value. Our characterization allows us to easily determine which known centrality measures are vitality indices.

----

## [56] Game-theoretic Analysis of Effort Allocation of Contributors to Public Projects

**Authors**: *Jared Soundy, Chenhao Wang, Clay Stevens, Hau Chan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/57](https://doi.org/10.24963/ijcai.2021/57)

**Abstract**:

Public projects can succeed or fail for many reasons such as the feasibility of the original goal and coordination among contributors. One major reason for failure is that insufficient work leaves the project partially completed. For certain types of projects anything short of full completion is a failure (e.g., feature request on software projects in GitHub). Therefore, project success relies heavily on individuals allocating sufficient effort. When there are multiple public projects, each contributor needs to make decisions to best allocate his/her limited effort (e.g., time) to projects while considering the effort allocation decisions of other strategic contributors and his/her parameterized utilities based on values and costs for the projects. In this paper, we introduce a game-theoretic effort allocation model of contributors to public projects for modeling effort allocation of strategic contributors. We study the related Nash equilibrium (NE) computational problems and provide NP-hardness results for the existence of NE and polynomial-time algorithms for finding NE in restricted settings. Finally, we investigate the inefficiency of NE measured by the price of anarchy and price of stability.

----

## [57] New Algorithms for Japanese Residency Matching

**Authors**: *Zhaohong Sun, Taiki Todo, Makoto Yokoo*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/58](https://doi.org/10.24963/ijcai.2021/58)

**Abstract**:

We study the Japanese Residency Matching Program (JRMP) in which hospitals are partitioned into disjoint regions and both hospitals and regions are subject to quotas. To achieve a balanced distribution of doctors across regions, hard bounds are imposed by the government to limit the number of
doctors who can be placed in each region. However, such hard bounds lead to inefficiency in terms of wasted vacant positions. In this paper, we propose
two suitable algorithms to reduce waste with minimal modification to the current system and show that they are superior to the algorithm currently
deployed in JRMP by comparing them theoretically and empirically.

----

## [58] Fair Pairwise Exchange among Groups

**Authors**: *Zhaohong Sun, Taiki Todo, Toby Walsh*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/59](https://doi.org/10.24963/ijcai.2021/59)

**Abstract**:

We study the pairwise organ exchange problem among groups motivated by real-world applications and consider two types of group formulations. Each
group represents either a certain type of patient-donor pairs who are compatible with the same set of organs, or a set of patient-donor pairs who reside
in the same region. We address a natural research question, which asks how to match a maximum number of pairwise compatible patient-donor
pairs in a fair and individually rational way. We first propose a natural fairness concept that is applicable to both types of group formulations and design
a polynomial-time algorithm that checks whether a matching exists that satisfies optimality, individual rationality, and fairness. We also present several
running time upper bounds for computing such matchings for different graph structures.

----

## [59] Reducing Bus Bunching with Asynchronous Multi-Agent Reinforcement Learning

**Authors**: *Jiawei Wang, Lijun Sun*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/60](https://doi.org/10.24963/ijcai.2021/60)

**Abstract**:

The bus system is a critical component of sustainable urban transportation. However, due to the significant uncertainties in passenger demand and traffic conditions, bus operation is unstable in nature and bus bunching has become a common phenomenon that undermines the reliability and efficiency of bus services. Despite recent advances in multi-agent reinforcement learning (MARL) on traffic control, little research has focused on bus fleet control due to the tricky asynchronous characteristic---control actions only happen when a bus arrives at a bus stop and thus agents do not act simultaneously. In this study, we formulate route-level bus fleet control as an asynchronous multi-agent reinforcement learning (ASMR) problem and extend the classical actor-critic architecture to handle the asynchronous issue. Specifically, we design a novel critic network to effectively approximate the marginal contribution for other agents, in which graph attention neural network is used to conduct inductive learning for policy evaluation. The critic structure also helps the ego agent optimize its policy more efficiently. We evaluate the proposed framework on real-world bus services and actual passenger demand derived from smart card data. Our results show that the proposed model outperforms both traditional headway-based control methods and existing MARL methods.

----

## [60] Emergent Prosociality in Multi-Agent Games Through Gifting

**Authors**: *Woodrow Z. Wang, Mark Beliaev, Erdem Biyik, Daniel A. Lazar, Ramtin Pedarsani, Dorsa Sadigh*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/61](https://doi.org/10.24963/ijcai.2021/61)

**Abstract**:

Coordination is often critical to forming prosocial behaviors -- behaviors that increase the overall sum of rewards received by all agents in a multi-agent game. However, state of the art reinforcement learning algorithms often suffer from converging to socially less desirable equilibria when multiple equilibria exist. Previous works address this challenge with explicit reward shaping, which requires the strong assumption that agents can be forced to be prosocial. We propose using a less restrictive peer-rewarding mechanism, gifting, that guides the agents toward more socially desirable equilibria while allowing agents to remain selfish and decentralized. Gifting allows each agent to give some of their reward to other agents. We employ a theoretical framework that captures the benefit of gifting in converging to the prosocial equilibrium by characterizing the equilibria's basins of attraction in a dynamical system. With gifting, we demonstrate increased convergence of high risk, general-sum coordination games to the prosocial equilibrium both via numerical analysis and experiments.

----

## [61] An Axiom System for Feedback Centralities

**Authors**: *Tomasz Was, Oskar Skibski*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/62](https://doi.org/10.24963/ijcai.2021/62)

**Abstract**:

In recent years, the axiomatic approach to centrality measures has attracted attention in the literature. However, most papers propose a collection of axioms dedicated to one or two considered centrality measures. In result, it is hard to capture the differences and similarities between various measures. In this paper, we propose an axiom system for four classic feedback centralities: Eigenvector centrality, Katz centrality, Katz prestige and PageRank. We prove that each of these four centrality measures can be uniquely characterized with a subset of our axioms. Our system is the first one in the literature that considers all four feedback centralities.

----

## [62] Manipulation of k-Coalitional Games on Social Networks

**Authors**: *Naftali Waxman, Sarit Kraus, Noam Hazon*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/63](https://doi.org/10.24963/ijcai.2021/63)

**Abstract**:

In many coalition formation games the utility of the agents depends on a social network. In such scenarios there might be a manipulative agent that would like to manipulate his connections in the social network in order to increase his utility. We study a model of coalition formation in which a central organizer, who needs to form k coalitions, obtains information about the social network from the agents.
The central organizer has her own objective: she might want to maximize the utilitarian social welfare, maximize the egalitarian social welfare, or only guarantee that every agent will have at least one connection within her coalition. 
In this paper we study the susceptibility for manipulation of these objectives, given the abilities and information that the manipulator has. Specifically, we show that if the manipulator has very limited information, namely he is only familiar with his immediate neighbours in the network, then a manipulation is almost always impossible. Moreover, if the manipulator is only able to add connections to the social network, then a manipulation is still impossible for some objectives, even if the manipulator has full information on the structure of the network. On the other hand,  if the manipulator is able to hide some of his connections, then all objectives are susceptible to manipulation, even if the manipulator has limited information, i.e., when he is familiar with his immediate neighbours and with their neighbours.

----

## [63] State-Aware Value Function Approximation with Attention Mechanism for Restless Multi-armed Bandits

**Authors**: *Shuang Wu, Jingyu Zhao, Guangjian Tian, Jun Wang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/64](https://doi.org/10.24963/ijcai.2021/64)

**Abstract**:

The restless multi-armed bandit (RMAB) problem is a generalization of the multi-armed bandit with non-stationary rewards. Its optimal solution is intractable due to exponentially large state and action spaces with respect to the number of arms. Existing approximation approaches, e.g., Whittle's index policy, have difficulty in capturing either temporal or spatial factors such as impacts from other arms. We propose considering both factors using the attention mechanism, which has achieved great success in deep learning. Our state-aware value function approximation solution comprises an attention-based value function approximator and a Bellman equation solver. The attention-based coordination module capture both spatial and temporal factors for arm coordination. The Bellman equation solver utilizes the decoupling structure of RMABs to acquire solutions with significantly reduced computation overheads. In particular, the time complexity of our approximation is linear in the number of arms. Finally, we illustrate the effectiveness and investigate the properties of our proposed method with numerical experiments.

----

## [64] Budget-feasible Maximum Nash Social Welfare is Almost Envy-free

**Authors**: *Xiaowei Wu, Bo Li, Jiarui Gan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/65](https://doi.org/10.24963/ijcai.2021/65)

**Abstract**:

The Nash social welfare (NSW) is a well-known social welfare measurement that balances individual utilities and the overall efficiency. In the context of fair allocation of indivisible goods, it has been shown by Caragiannis et al. (EC 2016 and TEAC 2019) that an allocation maximizing the NSW is envy-free up to one good (EF1). In this paper, we are interested in the fairness of the NSW in a budget-feasible allocation problem, in which each item has a cost that will be incurred to the agent it is allocated to, and each agent has a budget constraint on the total cost of items she receives. We show that a budget-feasible allocation that maximizes the NSW achieves a 1/4-approximation of EF1 and the approximation ratio is tight. The approximation ratio improves gracefully when the items have small costs compared with the agents' budgets; it converges to 1/2 when the budget-cost ratio approaches infinity.

----

## [65] Learning with Generated Teammates to Achieve Type-Free Ad-Hoc Teamwork

**Authors**: *Dong Xing, Qianhui Liu, Qian Zheng, Gang Pan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/66](https://doi.org/10.24963/ijcai.2021/66)

**Abstract**:

In ad-hoc teamwork, an agent is required to cooperate with unknown teammates without prior coordination. To swiftly adapt to an unknown teammate, most works adopt a type-based approach, which pre-trains the agent with a set of pre-prepared teammate types, then associates the unknown teammate with a particular type. Typically, these types are collected manually. This hampers previous works by both the availability and diversity of types they manage to obtain. To eliminate these limitations, this work addresses to achieve ad-hoc teamwork in a type-free approach. Specifically, we propose the model of Entropy-regularized Deep Recurrent Q-Network (EDRQN) to generate teammates automatically, meanwhile utilize them to pre-train our agent. These teammates are obtained from scratch and are designed to perform the task with various behaviors, therefore their availability and diversity are both ensured. We evaluate our model on several benchmark domains of ad-hoc teamwork. The result shows that even if our model has no access to any pre-prepared teammate types, it still achieves significant performance.

----

## [66] H-FL: A Hierarchical Communication-Efficient and Privacy-Protected Architecture for Federated Learning

**Authors**: *He Yang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/67](https://doi.org/10.24963/ijcai.2021/67)

**Abstract**:

The longstanding goals of federated learning (FL) require rigorous privacy guarantees and low communication overhead while holding a relatively high model accuracy. However, simultaneously achieving all the goals is extremely challenging. In this paper, we propose a novel framework called hierarchical federated learning (H-FL) to tackle this challenge. Considering the degradation of the model performance due to the statistic heterogeneity of the training data, we devise a runtime distribution reconstruction strategy, which reallocates the clients appropriately and utilizes mediators to rearrange the local training of the clients. In addition, we design a compression-correction mechanism incorporated into H-FL to reduce the communication overhead while not sacrificing the model performance. To further provide privacy guarantees, we introduce differential privacy while performing local training, which injects moderate amount of noise into only part of the complete model. Experimental results show that our H-FL framework achieves the state-of-art performance on different datasets for the real-world image recognition tasks.

----

## [67] Dominant Resource Fairness with Meta-Types

**Authors**: *Steven Yin, Shatian Wang, Lingyi Zhang, Christian Kroer*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/68](https://doi.org/10.24963/ijcai.2021/68)

**Abstract**:

Inspired by the recent COVID-19 pandemic, we study a generalization of the multi-resource allocation problem with heterogeneous demands and Leontief utilities. Unlike existing settings, we allow each agent to specify requirements to only accept allocations from a subset of the total supply for each resource. These requirements can take form in location constraints (e.g. A hospital can only accept volunteers who live nearby due to commute limitations). This can also model a type of substitution effect where some agents need 1 unit of resource A \emph{or} B, both belonging to the same meta-type. But some agents specifically want A, and others specifically want B. We propose a new mechanism called Dominant Resource Fairness with Meta Types which determines the allocations by solving a small number of linear programs. The proposed method  satisfies Pareto optimality, envy-freeness, strategy-proofness, and a notion of sharing incentive for our setting. To the best of our knowledge, we are the first to study this problem formulation, which improved upon existing work by capturing more constraints that often arise in real life situations. Finally, we show numerically that our method scales better to large problems than alternative approaches.

----

## [68] Altruism Design in Networked Public Goods Games

**Authors**: *Sixie Yu, David Kempe, Yevgeniy Vorobeychik*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/69](https://doi.org/10.24963/ijcai.2021/69)

**Abstract**:

Many collective decision-making settings feature a strategic tension
between agents acting out of individual self-interest and promoting a common good.
These include wearing face masks during a pandemic, voting, and vaccination.
Networked public goods games 
capture this tension, with networks encoding strategic interdependence among agents.
Conventional models of public goods games posit solely individual self-interest as a motivation, even though altruistic
motivations have long been known to play a significant role in agents' decisions.
We introduce a novel extension of public goods games to account for
altruistic motivations by adding a term in the utility function that
incorporates the perceived benefits an agent obtains from the welfare
of others, mediated by an altruism graph.
Most importantly, we view altruism not as immutable, but rather as a lever for promoting the common good.
Our central algorithmic question then revolves around the
computational complexity of modifying the altruism network to achieve desired public goods game investment profiles.
We first show that the problem can be solved using linear programming
when a principal can fractionally modify the altruism network.
While the problem becomes in general intractable if the principal's
actions are all-or-nothing, we exhibit several tractable special cases.

----

## [69] MFVFD: A Multi-Agent Q-Learning Approach to Cooperative and Non-Cooperative Tasks

**Authors**: *Tianhao Zhang, Qiwei Ye, Jiang Bian, Guangming Xie, Tie-Yan Liu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/70](https://doi.org/10.24963/ijcai.2021/70)

**Abstract**:

Value function decomposition (VFD) methods under the popular paradigm of centralized training and decentralized execution (CTDE) have promoted multi-agent reinforcement learning progress. However, existing VFD methods proceed from a group's value function decomposition to only solve cooperative tasks. With the individual value function decomposition, we propose MFVFD, a novel multi-agent Q-learning approach for solving cooperative and non-cooperative tasks based on mean-field theory. Our analysis on the Hawk-Dove and Nonmonotonic Cooperation matrix games evaluate MFVFD's convergent solution. Empirical studies on the challenging mixed cooperative-competitive tasks where hundreds of agents coexist demonstrate that MFVFD significantly outperforms existing baselines.

----

## [70] Data-Efficient Reinforcement Learning for Malaria Control

**Authors**: *Lixin Zou*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/71](https://doi.org/10.24963/ijcai.2021/71)

**Abstract**:

Sequential decision-making under cost-sensitive tasks is prohibitively daunting, especially for the problem that has a significant impact on people's daily lives, such as malaria control, treatment recommendation. The main challenge faced by policymakers is to learn a policy from scratch by interacting with a complex environment in a few trials. This work introduces a practical, data-efficient policy learning method, named Variance-Bonus Monte Carlo Tree Search~(VB-MCTS), which can copy with very little data and facilitate learning from scratch in only a few trials. Specifically, the solution is a model-based reinforcement learning method. To avoid model bias, we apply Gaussian Process~(GP) regression to estimate the transitions explicitly. With the GP world model, we propose a variance-bonus reward to measure the uncertainty about the world. Adding the reward to the planning with MCTS can result in more efficient and effective exploration. Furthermore, the derived polynomial sample complexity indicates that VB-MCTS is sample efficient. Finally, outstanding performance on a competitive world-level RL competition and extensive experimental results verify its advantage over the state-of-the-art on the challenging malaria control task.

----

## [71] Interacting with Explanations through Critiquing

**Authors**: *Diego Antognini, Claudiu Musat, Boi Faltings*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/72](https://doi.org/10.24963/ijcai.2021/72)

**Abstract**:

Using personalized explanations to support recommendations has been shown to increase trust and perceived quality. However, to actually obtain better recommendations, there needs to be a means for users to modify the recommendation criteria by interacting with the explanation. We present a novel technique using aspect markers that learns to generate personalized explanations of recommendations from review texts, and we show that human users significantly prefer these explanations over those produced by state-of-the-art techniques.

Our work's most important innovation is that it allows users to react to a recommendation by critiquing the textual explanation: removing (symmetrically adding) certain aspects they dislike or that are no longer relevant (symmetrically that are of interest). The system updates its user model and the resulting recommendations according to the critique. This is based on a novel unsupervised critiquing method for single- and multi-step critiquing with textual explanations. Empirical results show that our system achieves good performance in adapting to the preferences expressed in multi-step critiquing and generates consistent explanations.

----

## [72] On Smoother Attributions using Neural Stochastic Differential Equations

**Authors**: *Sumit Kumar Jha, Rickard Ewetz, Alvaro Velasquez, Susmit Jha*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/73](https://doi.org/10.24963/ijcai.2021/73)

**Abstract**:

Several methods have recently been developed for computing attributions of a neural network's prediction over the input features. However, these existing approaches for computing attributions are noisy and not robust to small perturbations of the input. This paper uses the recently identified connection between dynamical systems and residual neural networks to show that the attributions computed over neural stochastic differential equations (SDEs) are less noisy, visually sharper, and quantitatively more robust. Using dynamical systems theory, we theoretically analyze the robustness of these attributions. We also experimentally demonstrate the efficacy of our approach in providing smoother, visually sharper and quantitatively robust attributions by computing attributions for ImageNet images using ResNet-50, WideResNet-101 models and ResNeXt-101 models.

----

## [73] Location Predicts You: Location Prediction via Bi-direction Speculation and Dual-level Association

**Authors**: *Xixi Li, Ruimin Hu, Zheng Wang, Toshihiko Yamasaki*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/74](https://doi.org/10.24963/ijcai.2021/74)

**Abstract**:

Location prediction is of great importance in location-based applications for the construction of the smart city. To our knowledge, existing models for location prediction focus on the users' preference on POIs from the perspective of the human side. However, modeling users' interests from the historical trajectory is still limited by the data sparsity. Additionally, most of existing methods predict the next location according to the individual data independently. But the data sparsity makes it difficult to mine explicit mobility patterns or capture the casual behavior for each user. To address the issues above, we propose a novel Bi-direction Speculation and Dual-level Association method (BSDA), which considers both users' interests in POIs and POIs' appeal to users. Furthermore, we develop the cross-user and cross-POI association to alleviate the data sparsity by similar users and POIs to enrich the candidates. Experimental results on two public datasets demonstrate that BSDA achieves significant improvements over state-of-the-art methods.

----

## [74] Addressing the Long-term Impact of ML Decisions via Policy Regret

**Authors**: *David Lindner, Hoda Heidari, Andreas Krause*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/75](https://doi.org/10.24963/ijcai.2021/75)

**Abstract**:

Machine Learning (ML) increasingly informs the allocation of opportunities to individuals and communities in areas such as lending, education, employment, and beyond. Such decisions often impact their subjects' future characteristics and capabilities in an a priori unknown fashion. The decision-maker, therefore, faces exploration-exploitation dilemmas akin to those in multi-armed bandits.
Following prior work, we model communities as arms. To capture the long-term effects of ML-based allocation decisions, we study a setting in which the reward from each arm evolves every time the decision-maker pulls that arm. We focus on reward functions that are initially increasing in the number of pulls but may become (and remain) decreasing after a certain point. We argue that an acceptable sequential allocation of opportunities must take an arm's potential for growth into account. We capture these considerations through the notion of policy regret, a much stronger notion than the often-studied external regret, and present an algorithm with provably sub-linear policy regret for sufficiently long time horizons. We empirically compare our algorithm with several baselines and find that it consistently outperforms them, in particular for long time horizons.

----

## [75] Multi-Objective Reinforcement Learning for Designing Ethical Environments

**Authors**: *Manel Rodriguez-Soto, Maite López-Sánchez, Juan A. Rodríguez-Aguilar*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/76](https://doi.org/10.24963/ijcai.2021/76)

**Abstract**:

AI research is being challenged with ensuring that autonomous agents learn to behave ethically, namely in alignment with moral values. A common approach, founded on the exploitation of Reinforcement Learning techniques, is to design environments that incentivise agents to behave ethically. However, to the best of our knowledge, current approaches do not theoretically guarantee that an agent will learn to behave ethically.  Here, we make headway along this direction by proposing a novel way of designing environments wherein it is formally guaranteed that an agent learns to behave ethically while pursuing its individual objectives.  Our theoretical results develop within the formal framework of Multi-Objective Reinforcement Learning to ease the handling of an agent's individual and ethical objectives. As a further contribution, we leverage on our theoretical results to introduce an algorithm that automates the design of ethical environments.

----

## [76] Bias Silhouette Analysis: Towards Assessing the Quality of Bias Metrics for Word Embedding Models

**Authors**: *Maximilian Spliethöver, Henning Wachsmuth*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/77](https://doi.org/10.24963/ijcai.2021/77)

**Abstract**:

Word embedding models reflect bias towards genders, ethnicities, and other social groups present in the underlying training data. Metrics such as ECT, RNSB, and WEAT quantify bias in these models based on predefined word lists representing social groups and bias-conveying concepts. How suitable these lists actually are to reveal bias - let alone the bias metrics in general - remains unclear, though. In this paper, we study how to assess the quality of bias metrics for word embedding models. In particular, we present a generic method, Bias Silhouette Analysis (BSA), that quantifies the accuracy and robustness of such a metric and of the word lists used. Given a biased and an unbiased reference embedding model, BSA applies the metric systematically for several subsets of the lists to the models. The variance and rate of convergence of the bias values of each model then entail the robustness of the word lists, whereas the distance between the models' values gives indications of the general accuracy of the metric with the word lists. We demonstrate the behavior of BSA on two standard embedding models for the three mentioned metrics with several word lists from existing research.

----

## [77] Decision Making with Differential Privacy under a Fairness Lens

**Authors**: *Cuong Tran, Ferdinando Fioretto, Pascal Van Hentenryck, Zhiyan Yao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/78](https://doi.org/10.24963/ijcai.2021/78)

**Abstract**:

Many agencies release datasets and statistics about groups of individuals that are used as input to a number of critical decision processes. To conform with privacy and confidentiality requirements, these agencies are often required to release privacy-preserving versions of the data. This paper studies the release of differentially private datasets and analyzes their impact on some critical resource allocation tasks under a fairness perspective.  The paper shows that, when the decisions take as input differentially private data, the noise added to achieve privacy disproportionately impacts some groups over others. The paper analyzes the reasons for these disproportionate impacts and proposes guidelines to mitigate these effects. The proposed approaches are evaluated on critical decision problems that use differentially private census data.

----

## [78] An Examination of Fairness of AI Models for Deepfake Detection

**Authors**: *Loc Trinh, Yan Liu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/79](https://doi.org/10.24963/ijcai.2021/79)

**Abstract**:

Recent studies have demonstrated that deep learning models can discriminate based on protected classes like race and gender. In this work, we evaluate bias present in deepfake datasets and detection models across protected subgroups. Using facial datasets balanced by race and gender, we examine three popular deepfake detectors and find large disparities in predictive performances across races, with up to 10.7% difference in error rate between subgroups. A closer look reveals that the widely used FaceForensics++ dataset is overwhelmingly composed of Caucasian subjects, with the majority being female Caucasians. Our investigation of the racial distribution of deepfakes reveals that the methods used to create deepfakes as positive training signals tend to produce ``irregular" faces - when a personâ€™s face is swapped onto another person of a different race or gender. This causes detectors to learn spurious correlations between the foreground faces and fakeness. Moreover, when detectors are trained with the Blended Image (BI) dataset from Face X-Rays, we find that those detectors develop systematic discrimination towards certain racial subgroups, primarily female Asians.

----

## [79] Characteristic Examples: High-Robustness, Low-Transferability Fingerprinting of Neural Networks

**Authors**: *Siyue Wang, Xiao Wang, Pin-Yu Chen, Pu Zhao, Xue Lin*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/80](https://doi.org/10.24963/ijcai.2021/80)

**Abstract**:

This paper proposes Characteristic Examples for effectively fingerprinting deep neural networks, featuring high-robustness to the base model against model pruning as well as low-transferability to unassociated models. This is the first work taking both robustness and transferability into consideration for generating realistic fingerprints, whereas current methods lack practical assumptions and may incur large false positive rates. To achieve better trade-off between robustness and transferability, we propose three kinds of characteristic examples: vanilla C-examples, RC-examples, and LTRC-example, to derive fingerprints from the original base model. To fairly characterize the trade-off between robustness and transferability, we propose Uniqueness Score, a comprehensive metric that measures the difference between robustness and transferability, which also serves as an indicator to the false alarm problem. Extensive experiments demonstrate that the proposed characteristic examples can achieve superior performance when compared with existing fingerprinting methods. In particular, for VGG ImageNet models, using LTRC-examples gives 4X higher uniqueness score than the baseline method and does not incur any false positives.

----

## [80] GASP: Gated Attention for Saliency Prediction

**Authors**: *Fares Abawi, Tom Weber, Stefan Wermter*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/81](https://doi.org/10.24963/ijcai.2021/81)

**Abstract**:

Saliency prediction refers to the computational task of modeling overt attention. Social cues greatly influence our attention, consequently altering our eye movements and behavior. 
To emphasize the efficacy of such features, we present a neural model for integrating social cues and weighting their influences. Our model consists of two stages. During the first stage, we detect two social cues by following gaze, estimating gaze direction, and recognizing affect. These features are then transformed into spatiotemporal maps through image processing operations. The transformed representations are propagated to the second stage (GASP) where we explore various techniques of late fusion for integrating social cues and introduce two sub-networks for directing attention to relevant stimuli. Our experiments indicate that fusion approaches achieve better results for static integration methods, whereas non-fusion approaches for which the influence of each modality is unknown, result in better outcomes when coupled with recurrent models for dynamic saliency prediction. We show that gaze direction and affective representations contribute a prediction to ground-truth correspondence improvement of at least 5% compared to dynamic saliency models without social cues. Furthermore, affective representations improve GASP, supporting the necessity of considering affect-biased attention in predicting saliency.

----

## [81] Explaining Self-Supervised Image Representations with Visual Probing

**Authors**: *Dominika Basaj, Witold Oleszkiewicz, Igor Sieradzki, Michal Górszczak, Barbara Rychalska, Tomasz Trzcinski, Bartosz Zielinski*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/82](https://doi.org/10.24963/ijcai.2021/82)

**Abstract**:

Recently introduced self-supervised methods for image representation learning provide on par or superior results to their fully supervised competitors, yet the corresponding efforts to explain the self-supervised approaches lag behind. Motivated by this observation, we introduce a novel visual probing framework for explaining the self-supervised models by leveraging probing tasks employed previously in natural language processing. The probing tasks require knowledge about semantic relationships between image parts. Hence, we propose a systematic approach to obtain analogs of natural language in vision, such as visual words, context, and taxonomy. We show the effectiveness and applicability of those analogs in the context of explaining self-supervised representations. Our key findings emphasize that relations between language and vision can serve as an effective yet intuitive tool for discovering how machine learning models work, independently of data modality. Our work opens a plethora of research pathways towards more explainable and transparent AI.

----

## [82] Themis: A Fair Evaluation Platform for Computer Vision Competitions

**Authors**: *Zinuo Cai, Jianyong Yuan, Yang Hua, Tao Song, Hao Wang, Zhengui Xue, Ningxin Hu, Jonathan Ding, Ruhui Ma, Mohammad Reza Haghighat, Haibing Guan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/83](https://doi.org/10.24963/ijcai.2021/83)

**Abstract**:

It has become increasingly thorny for computer vision competitions to preserve fairness when participants intentionally fine-tune their models against the test datasets to improve their performance. To mitigate such unfairness, competition organizers restrict the training and evaluation process of participants' models. However, such restrictions introduce massive computation overheads for organizers and potential intellectual property leakage for participants. Thus, we propose Themis, a framework that trains a noise generator jointly with organizers and participants to prevent intentional fine-tuning by protecting test datasets from surreptitious manual labeling. Specifically, with the carefully designed noise generator, Themis adds noise to perturb test sets without twisting the performance ranking of participants' models. We evaluate the validity of Themis with a wide spectrum of real-world models and datasets. Our experimental results show that Themis effectively enforces competition fairness by precluding manual labeling of test sets and preserving the performance ranking of participants' models.

----

## [83] Novelty Detection via Contrastive Learning with Negative Data Augmentation

**Authors**: *Chengwei Chen, Yuan Xie, Shaohui Lin, Ruizhi Qiao, Jian Zhou, Xin Tan, Yi Zhang, Lizhuang Ma*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/84](https://doi.org/10.24963/ijcai.2021/84)

**Abstract**:

Novelty detection is the process of determining whether a query example differs from the learned training distribution. Previous generative adversarial networks based methods and self-supervised approaches suffer from instability training, mode dropping, and low discriminative ability. We overcome such problems by introducing a novel decoder-encoder framework. Firstly,  a generative network (decoder) learns the representation by mapping the initialized latent vector to an image. In particular, this vector is initialized by considering the entire distribution of training data to avoid the problem of mode-dropping. Secondly, a contrastive network (encoder) aims to ``learn to compare'' through mutual information estimation, which directly helps the generative network to obtain a more discriminative representation by using a negative data augmentation strategy. Extensive experiments show that our model has significant superiority over cutting-edge novelty detectors and achieves new state-of-the-art results on various novelty detection benchmarks, e.g. CIFAR10 and DCASE. Moreover, our model is more stable for training in a non-adversarial manner, compared to other adversarial based novelty detection methods.

----

## [84] Zero-Shot Chinese Character Recognition with Stroke-Level Decomposition

**Authors**: *Jingye Chen, Bin Li, Xiangyang Xue*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/85](https://doi.org/10.24963/ijcai.2021/85)

**Abstract**:

Chinese character recognition has attracted much research interest due to its wide applications. Although it has been studied for many years, some issues in this field have not been completely resolved yet, \textit{e.g.} the zero-shot problem. Previous character-based and radical-based methods have not fundamentally addressed the zero-shot problem since some characters or radicals in test sets may not appear in training sets under a data-hungry condition. Inspired by the fact that humans can generalize to know how to write characters unseen before if they have learned stroke orders of some characters, we propose a stroke-based method by decomposing each character into a sequence of strokes, which are the most basic units of Chinese characters. However, we observe that there is a one-to-many relationship between stroke sequences and Chinese characters. To tackle this challenge, we employ a matching-based strategy to transform the predicted stroke sequence to a specific character. We evaluate the proposed method on handwritten characters, printed artistic characters, and scene characters. The experimental results validate that the proposed method outperforms existing methods on both character zero-shot and radical zero-shot tasks. Moreover, the proposed method can be easily generalized to other languages whose characters can be decomposed into strokes.

----

## [85] Leveraging Human Attention in Novel Object Captioning

**Authors**: *Xianyu Chen, Ming Jiang, Qi Zhao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/86](https://doi.org/10.24963/ijcai.2021/86)

**Abstract**:

Image captioning models depend on training with paired image-text corpora, which poses various challenges in describing images containing novel objects absent from the training data. While previous novel object captioning methods rely on external image taggers or object detectors to describe novel objects, we present the Attention-based Novel Object Captioner (ANOC) that complements novel object captioners with human attention features that characterize generally important information independent of tasks. It introduces a gating mechanism that adaptively incorporates human attention with self-learned machine attention, with a Constrained Self-Critical Sequence Training method to address the exposure bias while maintaining constraints of novel object descriptions. Extensive experiments conducted on the nocaps and Held-Out COCO datasets demonstrate that our method considerably outperforms the state-of-the-art novel object captioners. 
Our source code is available at https://github.com/chenxy99/ANOC.

----

## [86] Boundary Knowledge Translation based Reference Semantic Segmentation

**Authors**: *Lechao Cheng, Zunlei Feng, Xinchao Wang, Ya Jie Liu, Jie Lei, Mingli Song*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/87](https://doi.org/10.24963/ijcai.2021/87)

**Abstract**:

Given a reference object of an unknown type in an image, human observers can effortlessly find the objects of the same category  in another image and precisely tell their visual boundaries. Such visual cognition capability of humans seems absent from the current research spectrum of computer vision. Existing segmentation networks, for example, rely on a humongous amount of labeled data, which is laborious and costly to collect and annotate; besides, the performance of segmentation networks tend to downgrade as the number of the category increases. In this paper, we introduce a novel Reference semantic segmentation Network (Ref-Net) to conduct visual boundary knowledge translation. Ref-Net contains a Reference Segmentation Module (RSM) and a Boundary Knowledge Translation Module (BKTM). Inspired by the human recognition mechanism, RSM is devised only to segment the same category objects based on the features of the reference objects. BKTM, on the other hand, introduces two boundary discriminator branches to conduct inner and outer boundary segmentation of the target object in an adversarial manner, and translate the annotated boundary knowledge of open-source datasets into the segmentation network. Exhaustive experiments demonstrate that, with tens of finely-grained annotated samples as guidance, Ref-Net achieves results on par with fully supervised methods on six datasets. Our code can be found in the supplementary material.

----

## [87] Hierarchical Object-oriented Spatio-Temporal Reasoning for Video Question Answering

**Authors**: *Long Hoang Dang, Thao Minh Le, Vuong Le, Truyen Tran*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/88](https://doi.org/10.24963/ijcai.2021/88)

**Abstract**:

Video Question Answering (Video QA) is a powerful testbed to develop new AI capabilities. This task necessitates learning to reason about objects, relations, and events across visual and linguistic domains in space-time. High-level reasoning demands lifting from associative visual pattern recognition to symbol like manipulation over objects, their behavior and interactions. Toward reaching this goal we propose an object-oriented reasoning approach in that video is abstracted as a dynamic stream of interacting objects. At each stage of the video event flow, these objects interact with each other, and their interactions are reasoned about with respect to the query and under the overall context of a video. This mechanism is materialized into a family of general-purpose neural units and their multi-level architecture called Hierarchical Object-oriented Spatio-Temporal Reasoning (HOSTR) networks. This neural model maintains the objects' consistent lifelines in the form of a hierarchically nested spatio-temporal graph. Within this graph, the dynamic interactive object-oriented representations are built up along the video sequence, hierarchically abstracted in a bottom-up manner, and converge toward the key information for the correct answer. The method is evaluated on multiple major Video QA datasets and establishes new state-of-the-arts in these tasks. Analysis into the model's behavior indicates that object-oriented reasoning is a reliable, interpretable and efficient approach to Video QA.

----

## [88] Phonovisual Biases in Language: is the Lexicon Tied to the Visual World?

**Authors**: *Andrea Gregor de Varda, Carlo Strapparava*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/89](https://doi.org/10.24963/ijcai.2021/89)

**Abstract**:

The present paper addresses the study of cross-linguistic and cross-modal iconicity within a deep learning framework. An LSTM-based Recurrent Neural Network is trained to associate the phonetic representation of a concrete word, encoded as a sequence of feature vectors, to the visual representation of its referent, expressed as an HCNN-transformed image. The processing network is then tested, without further training, in a language that does not appear in the training set and belongs to a different language family. The performance of the model is evaluated through a comparison with a randomized baseline; we show that such an imaginative network is capable of extracting language-independent generalizations in the mapping from linguistic sounds to visual features, providing empirical support for the hypothesis of a universal sound-symbolic substrate underlying all languages.

----

## [89] Direction-aware Feature-level Frequency Decomposition for Single Image Deraining

**Authors**: *Sen Deng, Yidan Feng, Mingqiang Wei, Haoran Xie, Yiping Chen, Jonathan Li, Xiao-Ping Zhang, Jing Qin*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/90](https://doi.org/10.24963/ijcai.2021/90)

**Abstract**:

We present a novel direction-aware feature-level frequency decomposition network for single image deraining. Compared with existing solutions, the proposed network has three compelling characteristics. First, unlike previous algorithms, we propose to perform frequency decomposition at feature-level instead of image-level, allowing both low-frequency maps containing structures and high-frequency maps containing details to be continuously refined during the training procedure. Second, we further establish communication channels between low-frequency maps and high-frequency maps to interactively capture structures from high-frequency maps and add them back to low-frequency maps and, simultaneously, extract details from low-frequency maps and send them back to high-frequency maps, thereby removing rain streaks while preserving more delicate features in the input image. Third, different from existing algorithms using convolutional filters consistent in all directions, we propose a direction-aware filter to capture the direction of rain streaks in order to more effectively and thoroughly purge the input images of rain streaks. We extensively evaluate the proposed approach in three representative datasets and experimental results corroborate our approach consistently outperforms state-of-the-art deraining algorithms.

----

## [90] TCIC: Theme Concepts Learning Cross Language and Vision for Image Captioning

**Authors**: *Zhihao Fan, Zhongyu Wei, Siyuan Wang, Ruize Wang, Zejun Li, Haijun Shan, Xuanjing Huang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/91](https://doi.org/10.24963/ijcai.2021/91)

**Abstract**:

Existing research for image captioning usually represents an image using a scene graph with low-level facts (objects and relations) and fails to capture the high-level semantics. In this paper, we propose a Theme Concepts extended Image Captioning (TCIC) framework that incorporates theme concepts to represent high-level cross-modality semantics. In practice, we model theme concepts as memory vectors and propose Transformer with Theme Nodes (TTN) to incorporate those vectors for image captioning. Considering that theme concepts can be learned from both images and captions, we propose two settings for their representations learning based on TTN. On the vision side, TTN is configured to take both scene graph based features and theme concepts as input for visual representation learning. On the language side, TTN is configured to take both captions and theme concepts as input for text representation re-construction. Both settings aim to generate target captions with the same transformer-based decoder. During the training, we further align representations of theme concepts learned from images and corresponding captions to enforce the cross-modality learning. Experimental results on MS COCO show the effectiveness of our approach compared to some state-of-the-art models.

----

## [91] Chop Chop BERT: Visual Question Answering by Chopping VisualBERT's Heads

**Authors**: *Chenyu Gao, Qi Zhu, Peng Wang, Qi Wu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/92](https://doi.org/10.24963/ijcai.2021/92)

**Abstract**:

Vision-and-Language (VL) pre-training has shown great potential on many related downstream tasks, such as Visual Question Answering (VQA), one of the most popular problems in the VL field. All of these pre-trained models (such as VisualBERT, ViLBERT, LXMERT and UNITER) are built with Transformer, which extends the classical attention mechanism to multiple layers and heads. To investigate why and how these models work on VQA so well, in this paper we explore the roles of individual heads and layers in Transformer models when handling 12 different types of questions. Specifically, we manually remove (chop) heads (or layers) from a pre-trained VisualBERT model at a time, and test it on different levels of questions to record its performance. As shown in the interesting echelon shape of the result matrices, experiments reveal different heads and layers are responsible for different question types, with higher-level layers activated by higher-level visual reasoning questions. Based on this observation, we design a dynamic chopping module that can automatically remove heads and layers of the VisualBERT at an instance level when dealing with different questions. Our dynamic chopping module can effectively reduce the parameters of the original model by 50%, while only damaging the accuracy by less than 1% on the VQA task.

----

## [92] Feature Space Targeted Attacks by Statistic Alignment

**Authors**: *Lianli Gao, Yaya Cheng, Qilong Zhang, Xing Xu, Jingkuan Song*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/93](https://doi.org/10.24963/ijcai.2021/93)

**Abstract**:

By adding human-imperceptible perturbations to images, DNNs can be easily fooled. As one of the mainstream methods, feature space targeted attacks perturb images by modulating their intermediate feature maps, for the discrepancy between the intermediate source and target features is minimized. However, the current choice of pixel-wise Euclidean Distance to measure the discrepancy is questionable because it unreasonably imposes a spatial-consistency constraint on the source and target features.
Intuitively, an image can be categorized as "cat'' no matter the cat is on the left or right of the image. To address this issue, we propose to measure this discrepancy using statistic alignment. Specifically, we design two novel approaches called Pair-wise Alignment Attack and Global-wise Alignment Attack, which attempt to measure similarities between feature maps by high-order statistics with translation invariance. Furthermore, we systematically analyze the layer-wise transferability with varied difficulties to obtain highly reliable attacks. Extensive experiments verify the effectiveness of our proposed method, and it outperforms the state-of-the-art algorithms by a large margin. Our code is publicly available at https://github.com/yaya-cheng/PAA-GAA.

----

## [93] Multi-view Feature Augmentation with Adaptive Class Activation Mapping

**Authors**: *Xiang Gao, Yingjie Tian, Zhiquan Qi*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/94](https://doi.org/10.24963/ijcai.2021/94)

**Abstract**:

We propose an end-to-end-trainable feature augmentation module built for image classification that extracts and exploits multi-view local features to boost model performance. Different from using global average pooling (GAP) to extract vectorized features from only the global view, we propose to sample and ensemble diverse multi-view local features to improve model robustness. To sample class-representative local features, we incorporate a simple auxiliary classifier head (comprising only one 1x1 convolutional layer) which efficiently and adaptively attends to class-discriminative local regions of feature maps via our proposed AdaCAM (Adaptive Class Activation Mapping). Extensive experiments demonstrate consistent and noticeable performance gains achieved by our multi-view feature augmentation module.

----

## [94] Learning Spectral Dictionary for Local Representation of Mesh

**Authors**: *Zhongpai Gao, Junchi Yan, Guangtao Zhai, Xiaokang Yang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/95](https://doi.org/10.24963/ijcai.2021/95)

**Abstract**:

For meshes, sharing the topology of a template is a common and practical setting in face-, hand-, and body-related applications. Meshes are irregular since each vertex's neighbors are unordered and their orientations are inconsistent with other vertices. Previous methods use isotropic filters or predefined local coordinate systems or learning weighting matrices for each vertex of the template to overcome the irregularity. Learning weighting matrices for each vertex to soft-permute the vertex's neighbors into an implicit canonical order is an effective way to capture the local structure of each vertex. However, learning weighting matrices for each vertex increases the parameter size linearly with the number of vertices and large amounts of parameters are required for high-resolution 3D shapes. In this paper, we learn spectral dictionary (i.e., bases) for the weighting matrices such that the parameter size is independent of the resolution of 3D shapes. The coefficients of the weighting matrix bases for each vertex are learned from the spectral features of the template's vertex and its neighbors in a weight-sharing manner. Comprehensive experiments demonstrate that our model produces state-of-the-art results with a much smaller model size.

----

## [95] Self-Supervised Video Action Localization with Adversarial Temporal Transforms

**Authors**: *Guoqiang Gong, Liangfeng Zheng, Wenhao Jiang, Yadong Mu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/96](https://doi.org/10.24963/ijcai.2021/96)

**Abstract**:

Weakly-supervised temporal action localization aims to locate intervals of action instances with only video-level action labels for training. However, the localization results generated from video classification networks are often not accurate due to the lack of temporal boundary annotation of actions. Our motivating insight is that the temporal boundary of action should be stably predicted under various temporal transforms. This inspires a self-supervised equivariant transform consistency constraint. We design a set of temporal transform operations, including naive temporal down-sampling to learnable attention-piloted time warping. In our model, a localization network aims to perform well under all transforms, and another policy network is designed to choose a temporal transform at each iteration that adversarially brings localization result inconsistent with the localization network's. Additionally, we devise a self-refine module to enhance the completeness of action intervals harnessing temporal and semantic contexts. Experimental results on THUMOS14 and ActivityNet demonstrate that our model consistently outperforms the state-of-the-art weakly-supervised temporal action localization methods.

----

## [96] EventDrop: Data Augmentation for Event-based Learning

**Authors**: *Fuqiang Gu, Weicong Sng, Xuke Hu, Fangwen Yu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/97](https://doi.org/10.24963/ijcai.2021/97)

**Abstract**:

The advantages of event-sensing over conventional sensors (e.g., higher dynamic range, lower time latency, and lower power consumption) have spurred research into machine learning for event data. Unsurprisingly, deep learning has emerged as a competitive methodology for learning with event sensors; in typical setups, discrete and asynchronous events are first converted into frame-like tensors on which standard deep networks can be applied. However, over-fitting remains a challenge, particularly since event datasets remain small relative to conventional datasets (e.g., ImageNet). In this paper, we introduce EventDrop, a new method for augmenting asynchronous event data to improve the generalization of deep models. By dropping events selected with various strategies, we are able to increase the diversity of training data (e.g., to simulate various levels of occlusion). From a practical perspective, EventDrop is simple to implement and computationally low-cost. Experiments on two event datasets (N-Caltech101 and N-Cars) demonstrate that EventDrop can significantly improve the generalization performance across a variety of deep networks.

----

## [97] AdaVQA: Overcoming Language Priors with Adapted Margin Cosine Loss

**Authors**: *Yangyang Guo, Liqiang Nie, Zhiyong Cheng, Feng Ji, Ji Zhang, Alberto Del Bimbo*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/98](https://doi.org/10.24963/ijcai.2021/98)

**Abstract**:

A number of studies point out that current Visual Question Answering (VQA) models are severely affected by the language prior problem, which refers to blindly making predictions based on the language shortcut. Some efforts have been devoted to overcoming this issue with delicate models. However, there is no research to address it from the view of the answer feature space learning, despite the fact that existing VQA methods all cast VQA as a classification task. Inspired by this, in this work, we attempt to tackle the language prior problem from the viewpoint of the feature space learning. An adapted margin cosine loss is designed to discriminate the frequent and the sparse answer feature space under each question type properly. In this way, the limited patterns within the language modality can be largely reduced to eliminate the language priors. We apply this loss function to several baseline models and evaluate its effectiveness on two VQA-CP benchmarks. Experimental results demonstrate that our proposed adapted margin cosine loss can enhance the baseline models with an absolute performance gain of 15\% on average, strongly verifying the potential of tackling the language prior problem in VQA from the angle of the answer feature space learning.

----

## [98] Disentangled Face Attribute Editing via Instance-Aware Latent Space Search

**Authors**: *Yuxuan Han, Jiaolong Yang, Ying Fu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/99](https://doi.org/10.24963/ijcai.2021/99)

**Abstract**:

Recent works have shown that a rich set of semantic directions exist in the latent space of Generative Adversarial Networks (GANs), which enables various facial attribute editing applications. However, existing methods may suffer poor attribute variation disentanglement, leading to unwanted change of other attributes when altering the desired one. The semantic directions used by existing methods are at attribute level, which are difficult to model complex attribute correlations, especially in the presence of attribute distribution bias in GAN's training set. In this paper, we propose a novel framework (IALS) that performs Instance-Aware Latent-Space Search to find semantic directions for disentangled attribute editing. The instance information is injected by leveraging the supervision from a set of attribute classifiers evaluated on the input images. We further propose a Disentanglement-Transformation (DT) metric to quantify the attribute transformation and disentanglement efficacy and find the optimal control factor between attribute-level and instance-specific directions based on it. Experimental results on both GAN-generated and real-world images collectively show that our method outperforms state-of-the-art methods proposed recently by a wide margin. Code is available at https://github.com/yxuhan/IALS.

----

## [99] DeepME: Deep Mixture Experts for Large-scale Image Classification

**Authors**: *Ming He, Guangyi Lv, Weidong He, Jianping Fan, Guihua Zeng*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/100](https://doi.org/10.24963/ijcai.2021/100)

**Abstract**:

Although deep learning has demonstrated its outstanding performance on image classification, most well-known deep networks make efforts to optimize both their structures and their node weights for recognizing fewer (e.g., no more than 1000) object classes. Therefore, it is attractive to extend or mixture such well-known deep networks to support large-scale image classification. According to our best knowledge, how to adaptively and effectively fuse multiple CNNs for large-scale image classification is still under-explored. On this basis, a deep mixture algorithm is developed to support large-scale image classification in this paper. First, a soft spectral clustering method is developed to construct a two-layer ontology (group layer and category layer) by assigning large numbers of image categories into a set of groups according to their inter-category semantic correlations, where the semantically-related image categories under the neighbouring group nodes may share similar learning complexities. Then, such two-layer ontology is further used to generate the task groups, in which each task group contains partial image categories with similar learning complexities and one particular base deep network is learned. Finally, a gate network is learned to combine all base deep networks with fewer diverse outputs to generate a mixture network with larger outputs. Our experimental results on ImageNet10K have demonstrated that our proposed deep mixture algorithm can achieve very competitive results (top 1 accuracy: 32.13%) on large-scale image classification tasks.

----

## [100] Multi-Scale Selective Feedback Network with Dual Loss for Real Image Denoising

**Authors**: *Xiaowan Hu, Yuanhao Cai, Zhihong Liu, Haoqian Wang, Yulun Zhang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/101](https://doi.org/10.24963/ijcai.2021/101)

**Abstract**:

The feedback mechanism in the human visual system extracts high-level semantics from noisy scenes. It then guides low-level noise removal, which has not been fully explored in image denoising networks based on deep learning. The commonly used fully-supervised network optimizes parameters through paired training data. However, unpaired images without noise-free labels are ubiquitous in the real world. Therefore, we proposed a multi-scale selective feedback network (MSFN) with the dual loss. We allow shallow layers to access valuable contextual information from the following deep layers selectively between two adjacent time steps. Iterative refinement mechanism can remove complex noise from coarse to fine. The dual regression is designed to reconstruct noisy images to establish closed-loop supervision that is training-friendly for unpaired data. We use the dual loss to optimize the primary clean-to-noisy task and the dual noisy-to-clean task simultaneously. Extensive experiments prove that our method achieves state-of-the-art results and shows better adaptability on real-world images than the existing methods.

----

## [101] Dynamic Inconsistency-aware DeepFake Video Detection

**Authors**: *Ziheng Hu, Hongtao Xie, Yuxin Wang, Jiahong Li, Zhongyuan Wang, Yongdong Zhang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/102](https://doi.org/10.24963/ijcai.2021/102)

**Abstract**:

The spread of DeepFake videos causes a serious threat to information security, calling for effective detection methods to distinguish them. However, the performance of recent frame-based detection methods become limited due to their ignorance of the inter-frame inconsistency of fake videos. In this paper, we propose a novel Dynamic Inconsistency-aware Network to handle the inconsistent problem, which uses a Cross-Reference module (CRM) to capture both the global and local inter-frame inconsistencies. The CRM contains two parallel branches. The first branch takes faces from adjacent frames as input, and calculates a structure similarity map for a global inconsistency representation. The second branch only focuses on the inter-frame variation of independent critical regions, which captures the local inconsistency. To the best of our knowledge, this is the first work to totally use the inter-frame inconsistency information from the global and local perspectives. Compared with existing methods, our model provides a more accurate and robust detection on FaceForensics++, DFDC-preview and Celeb-DFv2 datasets.

----

## [102] AgeFlow: Conditional Age Progression and Regression with Normalizing Flows

**Authors**: *Zhizhong Huang, Shouzhen Chen, Junping Zhang, Hongming Shan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/103](https://doi.org/10.24963/ijcai.2021/103)

**Abstract**:

Age progression and regression aim to synthesize photorealistic appearance of a given face image with aging and rejuvenation effects, respectively. Existing generative adversarial networks (GANs) based methods suffer from the following three major issues: 1) unstable training introducing strong ghost artifacts in the generated faces, 2) unpaired training leading to unexpected changes in facial attributes such as genders and races, and 3) non-bijective age mappings increasing the uncertainty in the face transformation. To overcome these issues, this paper proposes a novel framework, termed AgeFlow, to integrate the advantages of both flow-based models and GANs. The proposed AgeFlow contains three parts: an encoder that maps a given face to a latent space through an invertible neural network, a novel invertible conditional translation module (ICTM) that translates the source latent vector to target one, and a decoder that reconstructs the generated face from the target latent vector using the same encoder network; all parts are invertible achieving bijective age mappings. The novelties of ICTM are two-fold. First, we propose an attribute-aware knowledge distillation to learn the manipulation direction of age progression while keeping other unrelated attributes unchanged, alleviating unexpected changes in facial attributes. Second,  we propose to use GANs in the latent space to ensure the learned latent vector indistinguishable from the real ones, which is much easier than traditional use of GANs in the image domain. Experimental results demonstrate superior performance over existing GANs-based methods on two benchmarked datasets. The source code is available at https://github.com/Hzzone/AgeFlow.

----

## [103] Self-Supervised Video Representation Learning with Constrained Spatiotemporal Jigsaw

**Authors**: *Yuqi Huo, Mingyu Ding, Haoyu Lu, Ziyuan Huang, Mingqian Tang, Zhiwu Lu, Tao Xiang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/104](https://doi.org/10.24963/ijcai.2021/104)

**Abstract**:

This paper proposes a novel pretext task for self-supervised video representation learning by exploiting spatiotemporal continuity in videos. It is motivated by the fact that videos are spatiotemporal by nature and a representation learned by detecting spatiotemporal continuity/discontinuity is thus beneficial for downstream video content analysis tasks. A natural choice of such a pretext task is to construct spatiotemporal (3D) jigsaw puzzles and learn to solve them. However, as we demonstrate in the experiments, this task turns out to be intractable. We thus propose Constrained Spatiotemporal Jigsaw (CSJ) whereby the 3D jigsaws are formed in a constrained manner to ensure that large continuous spatiotemporal cuboids exist. This provides sufficient cues for the model to reason about the continuity. Instead of solving them directly, which could still be extremely hard, we carefully design four surrogate tasks that are more solvable. The four tasks aim to learn representations sensitive to spatiotemporal continuity at both the local and global levels. Extensive experiments show that our CSJ achieves state-of-the-art on various benchmarks.

----

## [104] Perturb, Predict & Paraphrase: Semi-Supervised Learning using Noisy Student for Image Captioning

**Authors**: *Arjit Jain, Pranay Reddy Samala, Preethi Jyothi, Deepak Mittal, Maneesh Kumar Singh*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/105](https://doi.org/10.24963/ijcai.2021/105)

**Abstract**:

Recent semi-supervised learning (SSL) methods are predominantly focused on multi-class classification tasks. Classification tasks allow for easy mixing of class labels during augmentation which does not trivially extend to structured outputs such as word sequences that appear in tasks like image captioning. Noisy Student Training is a recent SSL paradigm proposed for image classification that is an extension of self-training and teacher-student learning. In this work, we provide an in-depth analysis of the noisy student SSL framework for the task of image captioning and derive state-of-the-art results. The original algorithm relies on computationally expensive data augmentation steps that involve perturbing the raw images and computing features for each perturbed image. We show that, even in the absence of raw image augmentation, the use of simple model and feature perturbations to the input images for the student model are beneficial to SSL training. We also show how a paraphrase generator could be effectively used for label augmentation to improve the quality of pseudo labels and significantly improve performance. Our final results in the limited labeled data setting (1% of the MS-COCO labeled data) outperform previous state-of-the-art approaches by 2.5 on BLEU4 and 11.5 on CIDEr scores.

----

## [105] Step-Wise Hierarchical Alignment Network for Image-Text Matching

**Authors**: *Zhong Ji, Kexin Chen, Haoran Wang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/106](https://doi.org/10.24963/ijcai.2021/106)

**Abstract**:

Image-text matching plays a central role in bridging the semantic gap between vision and language. The key point to achieve precise visual-semantic alignment lies in capturing the fine-grained cross-modal correspondence between image and text. Most previous methods rely on single-step reasoning to discover the visual-semantic interactions, which lacks the ability of exploiting the multi-level information to locate the hierarchical fine-grained relevance. Different from them, in this work, we propose a step-wise hierarchical alignment network (SHAN) that decomposes image-text matching into multi-step cross-modal reasoning process. Specifically, we first achieve local-to-local alignment at fragment level, following by performing global-to-local and global-to-global alignment at context level sequentially. This progressive alignment strategy supplies our model with more complementary and sufficient semantic clues to understand the hierarchical correlations between image and text. The experimental results on two benchmark datasets demonstrate the superiority of our proposed method.

----

## [106] Planning with Learned Dynamic Model for Unsupervised Point Cloud Registration

**Authors**: *Haobo Jiang, Jianjun Qian, Jin Xie, Jian Yang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/107](https://doi.org/10.24963/ijcai.2021/107)

**Abstract**:

Point cloud registration is a fundamental problem in 3D computer vision. In this paper, we cast point cloud registration into a planning problem in reinforcement learning, which can seek the transformation between the source and target point clouds through trial and error. By modeling the point cloud registration process as a Markov decision process (MDP), we develop a latent dynamic model of point clouds, consisting of a transformation network and evaluation network. The transformation network aims to predict the new transformed feature of the point cloud after performing a rigid transformation (i.e., action) on it while the evaluation network aims to predict the alignment precision between the transformed source point cloud and target point cloud as the reward signal. Once the dynamic model of the point cloud is trained, we employ the cross-entropy method (CEM) to iteratively update the planning policy by maximizing the rewards in the point cloud registration process. Thus, the optimal policy, i.e., the transformation between the source and target point clouds, can be obtained via gradually narrowing the search space of the transformation. Experimental results on ModelNet40 and 7Scene benchmark datasets demonstrate that our method can yield good registration performance in an unsupervised manner.

----

## [107] Information Bottleneck Approach to Spatial Attention Learning

**Authors**: *Qiuxia Lai, Yu Li, Ailing Zeng, Minhao Liu, Hanqiu Sun, Qiang Xu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/108](https://doi.org/10.24963/ijcai.2021/108)

**Abstract**:

The selective visual attention mechanism in the human visual system (HVS) restricts the amount of information to reach visual awareness for perceiving natural scenes, allowing near real-time information processing with limited computational capacity. This kind of selectivity acts as an ‘Information Bottleneck (IB)’, which seeks a trade-off between information compression and predictive accuracy. However, such information constraints are rarely explored in the attention mechanism for deep neural networks (DNNs). In this paper, we propose an IB-inspired spatial attention module for DNN structures built for visual recognition. The module takes as input an intermediate representation of the input image, and outputs a variational 2D attention map that minimizes the mutual information (MI) between the attention-modulated representation and the input, while maximizing the MI between the attention-modulated representation and the task label. To further restrict the information bypassed by the attention map, we quantize the continuous attention scores to a set of learnable anchor values during training. Extensive experiments show that the proposed IB-inspired spatial attention mechanism can yield attention maps that neatly highlight the regions of interest while suppressing backgrounds, and bootstrap standard DNN structures for visual recognition tasks (e.g., image classification, fine-grained recognition, cross-domain classification). The attention maps are interpretable for the decision making of the DNNs as verified in the experiments. Our code is available at this https URL.

----

## [108] Noise Doesn't Lie: Towards Universal Detection of Deep Inpainting

**Authors**: *Ang Li, Qiuhong Ke, Xingjun Ma, Haiqin Weng, Zhiyuan Zong, Feng Xue, Rui Zhang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/109](https://doi.org/10.24963/ijcai.2021/109)

**Abstract**:

Deep image inpainting aims to restore damaged or missing regions in an image with realistic contents. While having a wide range of applications such as object removal and image recovery, deep inpainting techniques also have the risk of being manipulated for image forgery. A promising countermeasure against such forgeries is deep inpainting detection, which aims to locate the inpainted regions in an image. In this paper, we make the first attempt towards universal detection of deep inpainting, where the detection network can generalize well when detecting different deep inpainting methods. To this end, we first propose a novel data generation approach to generate a universal training dataset, which imitates the noise discrepancies exist in real versus inpainted image contents to train universal detectors. We then design a Noise-Image Cross-fusion Network (NIX-Net) to effectively exploit the discriminative information contained in both the images and their noise patterns. We empirically show, on multiple benchmark datasets, that our approach outperforms existing detection methods by a large margin and generalize well to unseen deep inpainting techniques. Our universal training dataset can also significantly boost the generalizability of existing detection methods.

----

## [109] IMENet: Joint 3D Semantic Scene Completion and 2D Semantic Segmentation through Iterative Mutual Enhancement

**Authors**: *Jie Li, Laiyan Ding, Rui Huang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/110](https://doi.org/10.24963/ijcai.2021/110)

**Abstract**:

3D semantic scene completion and 2D semantic segmentation are two tightly correlated tasks that are both essential for indoor scene understanding, because they predict the same semantic classes, using positively correlated high-level features. Current methods use 2D features extracted from early-fused RGB-D images for 2D segmentation to improve 3D scene completion. We argue that this sequential scheme does not ensure these two tasks fully benefit each other, and present an Iterative Mutual Enhancement Network (IMENet) to solve them jointly, which interactively refines the two tasks at the late prediction stage. Specifically, two refinement modules are developed under a unified framework for the two tasks. The first is a 2D Deformable Context Pyramid (DCP) module, which receives the projection from the current 3D predictions to refine the 2D predictions. In turn, a 3D Deformable Depth Attention (DDA) module is proposed to leverage the reprojected results from 2D predictions to update the coarse 3D predictions. This iterative fusion happens to the stable high-level features of both tasks at a late stage. Extensive experiments on NYU and NYUCAD datasets verify the effectiveness of the proposed iterative late fusion scheme, and our approach outperforms the state of the art on both 3D semantic scene completion and 2D semantic segmentation.

----

## [110] Deep Automatic Natural Image Matting

**Authors**: *Jizhizi Li, Jing Zhang, Dacheng Tao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/111](https://doi.org/10.24963/ijcai.2021/111)

**Abstract**:

Automatic image matting (AIM) refers to estimating the soft foreground from an arbitrary natural image without any auxiliary input like trimap, which is useful for image editing. Prior methods try to learn semantic features to aid the matting process while being limited to images with salient opaque foregrounds such as humans and animals. In this paper, we investigate the difficulties when extending them to natural images with salient transparent/meticulous foregrounds or non-salient foregrounds. To address the problem, a novel end-to-end matting network is proposed, which can predict a generalized trimap for any image of the above types as a unified semantic representation. Simultaneously, the learned semantic features guide the matting network to focus on the transition areas via an attention mechanism. We also construct a test set AIM-500 that contains 500 diverse natural images covering all types along with manually labeled alpha mattes, making it feasible to benchmark the generalization ability of AIM models. Results of the experiments demonstrate that our network trained on available composite matting datasets outperforms existing methods both objectively and subjectively. The source code and dataset are available at https://github.com/JizhiziLi/AIM.

----

## [111] Medical Image Segmentation using Squeeze-and-Expansion Transformers

**Authors**: *Shaohua Li, Xiuchao Sui, Xiangde Luo, Xinxing Xu, Yong Liu, Rick Siow Mong Goh*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/112](https://doi.org/10.24963/ijcai.2021/112)

**Abstract**:

Medical image segmentation is important for computer-aided diagnosis. Good segmentation demands the model to see the big picture and fine details simultaneously, i.e., to learn image features that incorporate large context while keep high spatial resolutions. To approach this goal, the most widely used methods -- U-Net and variants, extract and fuse multi-scale features. However, the fused features still have small "effective receptive fields" with a focus on local image cues, limiting their performance. In this work, we propose Segtran, an alternative segmentation framework based on transformers, which have unlimited "effective receptive fields" even at high feature resolutions. The core of Segtran is a novel Squeeze-and-Expansion transformer: a squeezed attention block regularizes the self attention of transformers, and an expansion block learns diversified representations. Additionally, we propose a new positional encoding scheme for transformers, imposing a continuity inductive bias for images. Experiments were performed on 2D and 3D medical image segmentation tasks: optic disc/cup segmentation in fundus images (REFUGE'20 challenge), polyp segmentation in colonoscopy images, and brain tumor segmentation in MRI scans (BraTS'19 challenge). Compared with representative existing methods, Segtran consistently achieved the highest segmentation accuracy, and exhibited good cross-domain generalization capabilities.

----

## [112] PIANO: A Parametric Hand Bone Model from Magnetic Resonance Imaging

**Authors**: *Yuwei Li, Minye Wu, Yuyao Zhang, Lan Xu, Jingyi Yu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/113](https://doi.org/10.24963/ijcai.2021/113)

**Abstract**:

Hand modeling is critical for immersive VR/AR, action understanding, or human healthcare. Existing parametric models account only for hand shape, pose, or texture, without modeling the anatomical attributes like bone, which is essential for realistic hand biomechanics analysis. In this paper, we present PIANO, the first parametric bone model of human hands from MRI data. Our PIANO model is biologically correct, simple to animate, and differentiable, achieving more anatomically precise modeling of the inner hand kinematic structure in a data-driven manner than the traditional hand models based on the outer surface only. Furthermore, our PIANO model can be applied in neural network layers to enable training with a fine-grained semantic loss, which opens up the new task of data-driven fine-grained hand bone anatomic and semantic understanding from MRI or even RGB images. We make our model publicly available.

----

## [113] Instance-Aware Coherent Video Style Transfer for Chinese Ink Wash Painting

**Authors**: *Hao Liang, Shuai Yang, Wenjing Wang, Jiaying Liu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/114](https://doi.org/10.24963/ijcai.2021/114)

**Abstract**:

Recent researches have made remarkable achievements in fast video style transfer based on western paintings. However, due to the inherent different drawing techniques and aesthetic expressions of Chinese ink wash painting, existing methods either achieve poor temporal consistency or fail to transfer the key freehand brushstroke characteristics of Chinese ink wash painting. In this paper, we present a novel video style transfer framework for Chinese ink wash paintings. The two key ideas are a multi-frame fusion for temporal coherence and an instance-aware style transfer. The frame reordering and stylization based on reference frame fusion are proposed to improve temporal consistency. Meanwhile, the proposed method is able to adaptively leave the white spaces in the background and to select proper scales to extract features and depict the foreground subject by leveraging instance segmentation. Experimental results demonstrate the superiority of the proposed method over state-of-the-art style transfer methods in terms of both temporal coherence and visual quality. Our project website is available at https://oblivioussy.github.io/InkVideo/.

----

## [114] Noise2Grad: Extract Image Noise to Denoise

**Authors**: *Huangxing Lin, Yihong Zhuang, Yue Huang, Xinghao Ding, Xiaoqing Liu, Yizhou Yu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/115](https://doi.org/10.24963/ijcai.2021/115)

**Abstract**:

In many image denoising tasks, the difficulty of collecting noisy/clean image pairs limits the application of supervised CNNs. We consider such a case in which paired data and noise statistics are not accessible, but unpaired noisy and clean images are easy to collect. To form the necessary supervision, our strategy is to extract the noise from the noisy image to synthesize new data. To ease the interference of the image background, we use a noise removal module to aid noise extraction. The noise removal module first roughly removes noise from the noisy image, which is equivalent to excluding much background information. A noise approximation module can therefore easily extract a new noise map from the removed noise to match the gradient of the noisy input. This noise map is added to a random clean image to synthesize a new data pair, which is then fed back to the noise removal module to correct the noise removal process. These two modules cooperate to extract noise finely. After convergence, the noise removal module can remove noise without damaging other background details, so we use it as our final denoising network. Experiments show that the denoising performance of the proposed method is competitive with other supervised CNNs.

----

## [115] Direct Measure Matching for Crowd Counting

**Authors**: *Hui Lin, Xiaopeng Hong, Zhiheng Ma, Xing Wei, Yunfeng Qiu, Yaowei Wang, Yihong Gong*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/116](https://doi.org/10.24963/ijcai.2021/116)

**Abstract**:

Traditional crowd counting approaches usually use Gaussian assumption to generate pseudo density ground truth, which suffers from problems like inaccurate estimation of the Gaussian kernel sizes. In this paper, we propose a new measure-based counting approach to regress the predicted density maps to the scattered point-annotated ground truth directly. First, crowd counting is formulated as a measure matching problem. Second, we derive a semi-balanced form of Sinkhorn divergence, based on which a Sinkhorn counting loss is designed for measure matching. Third, we propose a self-supervised mechanism by devising a Sinkhorn scale consistency loss to resist scale changes. Finally, an efficient optimization method is provided to minimize the overall loss function. Extensive experiments on four challenging crowd counting datasets namely ShanghaiTech, UCF-QNRF, JHU++ and NWPU have validated the proposed method.

----

## [116] A Multi-Constraint Similarity Learning with Adaptive Weighting for Visible-Thermal Person Re-Identification

**Authors**: *Yongguo Ling, Zhiming Luo, Yaojin Lin, Shaozi Li*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/117](https://doi.org/10.24963/ijcai.2021/117)

**Abstract**:

The challenges of visible-thermal person re-identification (VT-ReID) lies in the inter-modality discrepancy and the intra-modality variations. An appropriate metric learning plays a crucial role in optimizing the feature similarity between the two modalities. However,  most existing metric learning-based methods mainly constrain the similarity between individual instances or class centers, which are inadequate to explore the rich data relationships in the cross-modality data. Besides, most of these methods fail to consider the importance of different pairs, incurring an inefficiency and ineffectiveness of optimization. To address these issues, we propose a Multi-Constraint (MC) similarity learning method that jointly considers the cross-modality relationships from three different aspects, i.e., Instance-to-Instance (I2I), Center-to-Instance (C2I), and Center-to-Center (C2C). Moreover, we devise an Adaptive Weighting Loss (AWL) function to implement the MC efficiently. In the AWL, we first use an adaptive margin pair mining to select informative pairs and then adaptively adjust weights of mined pairs based on their similarity. Finally, the mined and weighted pairs are used for the metric learning. Extensive experiments on two benchmark datasets demonstrate the superior performance of the proposed over the state-of-the-art methods.

----

## [117] Learning 3-D Human Pose Estimation from Catadioptric Videos

**Authors**: *Chenchen Liu, Yongzhi Li, Kangqi Ma, Duo Zhang, Peijun Bao, Yadong Mu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/118](https://doi.org/10.24963/ijcai.2021/118)

**Abstract**:

3-D human pose estimation is a crucial step for understanding human actions. However, reliably capturing precise 3-D position of human joints is non-trivial and tedious. Current models often suffer from the scarcity of high-quality 3-D annotated training data. In this work, we explore a novel way of obtaining gigantic 3-D human pose data without manual annotations. In catedioptric videos (\emph{e.g.}, people dance before a mirror), the camera records both the original and mirrored human poses, which provides cues for estimating 3-D positions of human joints. Following this idea, we crawl a large-scale Dance-before-Mirror (DBM) video dataset, which is about 24 times larger than existing Human3.6M benchmark. Our technical insight is that, by jointly harnessing the epipolar geometry and human skeleton priors, 3-D joint estimation can boil down to an optimization problem over two sets of 2-D estimations. To our best knowledge, this represents the first work that collects high-quality 3-D human data via catadioptric systems. We have conducted comprehensive experiments on cross-scenario pose estimation and visualization analysis. The results strongly demonstrate the usefulness of our proposed DBM human poses.

----

## [118] Bipartite Matching for Crowd Counting with Point Supervision

**Authors**: *Hao Liu, Qiang Zhao, Yike Ma, Feng Dai*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/119](https://doi.org/10.24963/ijcai.2021/119)

**Abstract**:

For crowd counting task, it has been demonstrated that imposing Gaussians to point annotations hurts generalization performance. Several methods attempt to utilize point annotations as supervision directly. And they have made significant improvement compared with density-map based methods. However, these point based methods ignore the inevitable annotation noises and still suffer from low robustness to noisy annotations. To address the problem, we propose a bipartite matching based method for crowd counting with only point supervision (BM-Count). In BM-Count, we select a subset of most similar pixels from the predicted density map to match annotated pixels via bipartite matching. Then loss functions can be defined based on the matching pairs to alleviate the bad effect caused by those annotated dots with incorrect positions. Under the noisy annotations, our method reduces MAE and RMSE by 9% and 11.2% respectively. Moreover, we propose a novel ranking distribution learning framework to address the imbalanced distribution problem of head counts, which encodes the head counts as classification distribution in the ranking domain and refines the estimated count map in the continuous domain. Extensive experiments on four datasets show that our method achieves state-of-the-art performance and performs better crowd localization.

----

## [119] Dual Reweighting Domain Generalization for Face Presentation Attack Detection

**Authors**: *Shubao Liu, Ke-Yue Zhang, Taiping Yao, Kekai Sheng, Shouhong Ding, Ying Tai, Jilin Li, Yuan Xie, Lizhuang Ma*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/120](https://doi.org/10.24963/ijcai.2021/120)

**Abstract**:

Face anti-spoofing approaches based on domain generalization (DG) have drawn growing attention due to their robustness for unseen scenarios. Previous methods treat each sample from multiple domains indiscriminately during the training process, and endeavor to extract a common feature space to improve the generalization. However, due to complex and biased data distribution, directly treating them equally will corrupt the generalization ability. To settle the issue, we propose a novel Dual Reweighting Domain Generalization (DRDG) framework which iteratively reweights the relative importance between samples to further improve the generalization.  Concretely, Sample Reweighting Module is first proposed to identify samples with relatively large domain bias, and reduce their impact on the overall optimization. Afterwards, Feature Reweighting Module is introduced to focus on these samples and extract more domain-irrelevant features via a self-distilling mechanism. Combined with the domain discriminator, the iteration of the two modules promotes the extraction of generalized features. Extensive experiments and visualizations are presented to demonstrate the effectiveness and interpretability of our method against the state-of-the-art competitors.

----

## [120] Graph Consistency Based Mean-Teaching for Unsupervised Domain Adaptive Person Re-Identification

**Authors**: *Xiaobin Liu, Shiliang Zhang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/121](https://doi.org/10.24963/ijcai.2021/121)

**Abstract**:

Recent works show that mean-teaching is an effective framework for unsupervised domain adaptive person re-identification. However, existing methods perform contrastive learning on selected samples between teacher and student networks, which is sensitive to noises in pseudo labels and neglects the relationship among most samples. Moreover, these methods are not effective in cooperation of different teacher networks. To handle these issues, this paper proposes a Graph Consistency based Mean-Teaching (GCMT) method with constructing the Graph Consistency Constraint (GCC) between teacher and student networks. Specifically, given unlabeled training images, we apply teacher networks to extract corresponding features and further construct a teacher graph for each teacher network to describe the similarity relationships among training images. To boost the representation learning, different teacher graphs are fused to provide the supervise signal for optimizing student networks. GCMT fuses similarity relationships predicted by different teacher networks as supervision and effectively optimizes student networks with more sample relationships involved. Experiments on three datasets, i.e., Market-1501, DukeMTMCreID, and MSMT17, show that proposed GCMT outperforms state-of-the-art methods by clear margin. Specially, GCMT even outperforms the previous method that uses a deeper backbone. Experimental results also show that GCMT can effectively boost the performance with multiple teacher and student networks. Our code is available at https://github.com/liu-xb/GCMT .

----

## [121] Domain Generalization under Conditional and Label Shifts via Variational Bayesian Inference

**Authors**: *Xiaofeng Liu, Bo Hu, Linghao Jin, Xu Han, Fangxu Xing, Jinsong Ouyang, Jun Lu, Georges El Fakhri, Jonghye Woo*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/122](https://doi.org/10.24963/ijcai.2021/122)

**Abstract**:

In this work, we propose a domain generalization (DG) approach to learn on several labeled source domains and transfer knowledge to a target domain that is inaccessible in training. Considering the inherent conditional and label shifts, we would expect the alignment of p(x|y) and p(y). However, the widely used domain invariant feature learning (IFL) methods relies on aligning the marginal concept shift w.r.t. p(x), which rests on an unrealistic assumption that p(y) is invariant across domains. We thereby propose a novel variational Bayesian inference framework to enforce the conditional distribution alignment w.r.t. p(x|y) via the prior distribution matching in a latent space, which also takes the marginal label shift w.r.t. p(y) into consideration with the posterior alignment. Extensive experiments on various benchmarks demonstrate that our framework is robust to the label shift and the cross-domain accuracy is significantly improved, thereby achieving superior performance over the conventional IFL counterparts.

----

## [122] Learn from Concepts: Towards the Purified Memory for Few-shot Learning

**Authors**: *Xuncheng Liu, Xudong Tian, Shaohui Lin, Yanyun Qu, Lizhuang Ma, Wang Yuan, Zhizhong Zhang, Yuan Xie*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/123](https://doi.org/10.24963/ijcai.2021/123)

**Abstract**:

Human beings have a great generalization ability to recognize a novel category by only seeing a few number of samples. This is because humans possess the ability to learn from the concepts that already exist in our minds. However, many existing few-shot approaches fail in addressing such a fundamental problem, {\it i.e.,} how to utilize the knowledge learned in the past to improve the prediction for the new task. In this paper, we present a novel purified memory mechanism that simulates the recognition process of human beings. This new memory updating scheme enables the model to purify the information from semantic labels and progressively learn consistent, stable, and expressive concepts when episodes are trained one by one. On its basis, a Graph Augmentation Module (GAM) is introduced to aggregate these concepts and knowledge learned from new tasks via a graph neural network, making the prediction more accurate. Generally, our approach is model-agnostic and computing efficient with negligible memory cost. Extensive experiments performed on several benchmarks demonstrate the proposed method can consistently outperform a vast number of state-of-the-art few-shot learning methods.

----

## [123] One-Shot Affordance Detection

**Authors**: *Hongchen Luo, Wei Zhai, Jing Zhang, Yang Cao, Dacheng Tao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/124](https://doi.org/10.24963/ijcai.2021/124)

**Abstract**:

Affordance detection refers to identifying the potential action possibilities of objects in an image, which is an important ability for robot perception and manipulation. To empower robots with this ability in unseen scenarios, we consider the challenging one-shot affordance detection problem in this paper, i.e., given a support image that depicts the action purpose, all objects in a scene with the common affordance should be detected. To this end, we devise a One-Shot Affordance Detection (OS-AD) network that firstly estimates the purpose and then transfers it to help detect the common affordance from all candidate images. Through collaboration learning, OS-AD can capture the common characteristics between objects having the same underlying affordance and learn a good adaptation capability for perceiving unseen affordances. Besides, we build a Purpose-driven Affordance Dataset (PAD) by collecting and labeling 4k images from 31 affordance and 72 object categories. Experimental results demonstrate the superiority of our model over previous representative ones in terms of both objective metrics and visual quality. The benchmark suite is at  ProjectPage.

----

## [124] CIMON: Towards High-quality Hash Codes

**Authors**: *Xiao Luo, Daqing Wu, Zeyu Ma, Chong Chen, Minghua Deng, Jinwen Ma, Zhongming Jin, Jianqiang Huang, Xian-Sheng Hua*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/125](https://doi.org/10.24963/ijcai.2021/125)

**Abstract**:

Recently, hashing is widely used in approximate nearest neighbor search for its storage and computational efficiency. Most of the unsupervised hashing methods learn to map images into semantic similarity-preserving hash codes by constructing local semantic similarity structure from the pre-trained model as the guiding information, i.e., treating each point pair similar if their distance is small in feature space. However, due to the inefficient representation ability of the pre-trained model, many false positives and negatives in local semantic similarity will be introduced and lead to error propagation during the hash code learning. Moreover, few of the methods consider the robustness of models, which will cause instability of hash codes to disturbance. In this paper, we propose a new method named  Comprehensive sImilarity Mining and cOnsistency learNing (CIMON). First, we use global refinement and similarity statistical distribution to obtain reliable and smooth guidance. Second, both semantic and contrastive consistency learning are introduced to derive both disturb-invariant and discriminative hash codes. Extensive experiments on several benchmark datasets show that the proposed method outperforms a wide range of state-of-the-art methods in both retrieval performance and robustness.

----

## [125] Point-based Acoustic Scattering for Interactive Sound Propagation via Surface Encoding

**Authors**: *Hsien-Yu Meng, Zhenyu Tang, Dinesh Manocha*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/126](https://doi.org/10.24963/ijcai.2021/126)

**Abstract**:

We present a novel geometric deep learning method to compute the acoustic scattering properties of geometric objects. Our learning algorithm uses a point cloud representation of objects to compute the scattering properties and integrates them with ray tracing for interactive sound propagation in dynamic scenes. We use discrete Laplacian-based surface encoders and approximate the neighborhood of each point using a shared multi-layer perceptron. We show that our formulation is permutation invariant and present a neural network that computes the scattering function using spherical harmonics. Our approach can handle objects with arbitrary topologies and deforming models, and takes less than 1ms per object on a commodity GPU. We have analyzed the accuracy and perform validation on thousands of unseen 3D objects and highlight the benefits over other point-based geometric deep learning methods. To the best of our knowledge, this is the first real-time learning algorithm that can approximate the acoustic scattering properties of arbitrary objects with high accuracy.

----

## [126] Modality-aware Style Adaptation for RGB-Infrared Person Re-Identification

**Authors**: *Ziling Miao, Hong Liu, Wei Shi, Wanlu Xu, Hanrong Ye*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/127](https://doi.org/10.24963/ijcai.2021/127)

**Abstract**:

RGB-infrared (IR) person re-identification is a challenging task due to the large modality gap between RGB and IR images. Many existing methods bridge the modality gap by style conversion, requiring high-similarity images exchanged by complex CNN structures, like GAN. In this paper, we propose a highly compact modality-aware style adaptation (MSA) framework, which aims to explore more potential relations between RGB and IR modalities by introducing new related modalities. Therefore, the attention is shifted from bridging to filling the modality gap with no requirement on high-quality generated images. To this end, we firstly propose a concise feature-free image generation structure to adapt the original modalities to two new styles that are compatible with both inputs by patch-based pixel redistribution. Secondly, we devise two image style quantification metrics to discriminate styles in image space using luminance and contrast. Thirdly, we design two image-level losses based on the quantified results to guide the style adaptation during an end-to-end four-modality collaborative learning process. Experimental results on two datasets SYSU-MM01 and RegDB show that MSA achieves significant improvements with little extra computation cost and outperforms the state-of-the-art methods.

----

## [127] Look Wide and Interpret Twice: Improving Performance on Interactive Instruction-following Tasks

**Authors**: *Van-Quang Nguyen, Masanori Suganuma, Takayuki Okatani*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/128](https://doi.org/10.24963/ijcai.2021/128)

**Abstract**:

There is a growing interest in the community in making an embodied AI agent perform a complicated task while interacting with an environment following natural language directives. Recent studies have tackled the problem using ALFRED, a well-designed dataset for the task, but achieved only very low accuracy. This paper proposes a new method, which outperforms the previous methods by a large margin. It is based on a combination of several new ideas. One is a two-stage interpretation of the provided instructions. The method first selects and interprets an instruction without using visual information, yielding a tentative action sequence prediction. It then integrates the prediction with the visual information etc., yielding the final prediction of an action and an object. As the object's class to interact is identified in the first stage, it can accurately select the correct object from the input image. Moreover, our method considers multiple egocentric views of the environment and extracts essential information by applying hierarchical attention conditioned on the current instruction. This contributes to the accurate prediction of actions for navigation. A preliminary version of the method won the ALFRED Challenge 2020. The current version achieves the unseen environment's success rate of 4.45% with a single view, which is further improved to 8.37% with multiple views.

----

## [128] Attention-based Pyramid Dilated Lattice Network for Blind Image Denoising

**Authors**: *Mohammad Nikzad, Yongsheng Gao, Jun Zhou*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/129](https://doi.org/10.24963/ijcai.2021/129)

**Abstract**:

Though convolutional neural networks (CNNs) with residual and dense aggregations have obtained much attention in image denoising, they are incapable of exploiting different levels of contextual information at every convolutional unit in order to infer different levels of noise components with a single model. In this paper, to overcome this shortcoming we present a novel attention-based pyramid dilated lattice (APDL) architecture and investigate its capability for blind image denoising. The proposed framework can effectively harness the advantages of residual and dense aggregations to achieve a great trade-off between performance, parameter efficiency, and test time. It also employs a novel pyramid dilated convolution strategy to effectively capture contextual information corresponding to different noise levels through the training of a single model. Our extensive experimental investigation verifies the effectiveness and efficiency of the APDL architecture for image denoising as well as JPEG artifacts suppression tasks.

----

## [129] Few-shot Neural Human Performance Rendering from Sparse RGBD Videos

**Authors**: *Anqi Pang, Xin Chen, Haimin Luo, Minye Wu, Jingyi Yu, Lan Xu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/130](https://doi.org/10.24963/ijcai.2021/130)

**Abstract**:

Recent neural rendering approaches for human activities achieve remarkable view synthesis results, but still rely on dense input views or dense training with all the capture frames, leading to deployment difficulty and inefficient training overload. However, existing advances will be ill-posed if the input is both spatially and temporally sparse. To fill this gap, in this paper we propose a few-shot neural human rendering approach (FNHR) from only sparse RGBD inputs, which exploits the temporal and spatial redundancy to generate photo-realistic free-view output of human activities. Our FNHR is trained only on the key-frames which expand the motion manifold in the input sequences. We introduce a two-branch neural blending to combine the neural point render and classical graphics texturing pipeline, which integrates reliable observations over sparse key-frames. Furthermore, we adopt a patch-based adversarial training process to make use of the local redundancy and avoids over-fitting to the key-frames, which generates fine-detailed rendering results. Extensive experiments demonstrate the effectiveness of our approach to generate high-quality free view-point results for challenging human performances under the sparse setting.

----

## [130] Self-boosting for Feature Distillation

**Authors**: *Yulong Pei, Yanyun Qu, Junping Zhang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/131](https://doi.org/10.24963/ijcai.2021/131)

**Abstract**:

Knowledge distillation is a simple but effective method for model compression, which obtains a better-performing small network (Student) by learning from a well-trained large network (Teacher). However, when the difference in the model sizes of Student and Teacher is large, the gap in capacity leads to poor performance of Student. Existing methods focus on seeking simplified or more effective knowledge from Teacher to narrow the Teacher-Student gap, while we address this problem by Student's self-boosting. Specifically, we propose a novel distillation method named Self-boosting Feature Distillation (SFD), which eases the Teacher-Student gap by feature integration and self-distillation of Student. Three different modules are designed for feature integration to enhance the discriminability of Student's feature, which leads to improving the order of convergence in theory. Moreover, an easy-to-operate self-distillation strategy is put forward to stabilize the training process and promote the performance of Student, without additional forward propagation or memory consumption. Extensive experiments on multiple benchmarks and networks show that our method is significantly superior to existing methods.

----

## [131] SiamRCR: Reciprocal Classification and Regression for Visual Object Tracking

**Authors**: *Jinlong Peng, Zhengkai Jiang, Yueyang Gu, Yang Wu, Yabiao Wang, Ying Tai, Chengjie Wang, Weiyao Lin*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/132](https://doi.org/10.24963/ijcai.2021/132)

**Abstract**:

Recently, most siamese network based trackers locate targets via object classification and bounding-box regression. Generally, they select the bounding-box with maximum classification confidence as the final prediction. This strategy may miss the right result due to the accuracy misalignment between classification and regression. In this paper, we propose a novel siamese tracking algorithm called SiamRCR, addressing this problem with a simple, light and effective solution. It builds reciprocal links between classification and regression branches, which can dynamically re-weight their losses for each positive sample. In addition, we add a localization branch to predict the localization accuracy, so that it can work as the replacement of the regression assistance link during inference. This branch makes the training and inference more consistent. Extensive experimental results demonstrate the effectiveness of SiamRCR and its superiority over the state-of-the-art competitors on GOT-10k, LaSOT, TrackingNet, OTB-2015, VOT-2018 and VOT-2019. Moreover, our SiamRCR runs at 65 FPS, far above the real-time requirement.

----

## [132] Unsupervised Hashing with Contrastive Information Bottleneck

**Authors**: *Zexuan Qiu, Qinliang Su, Zijing Ou, Jianxing Yu, Changyou Chen*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/133](https://doi.org/10.24963/ijcai.2021/133)

**Abstract**:

Many unsupervised hashing methods are implicitly established on the idea of reconstructing the input data, which basically encourages the hashing codes to retain as much information of original data as possible. However, this requirement may force the models spending lots of their effort on reconstructing the unuseful background information, while ignoring to preserve the discriminative semantic information that is more important for the hashing task. To tackle this problem, inspired by the recent success of contrastive learning in learning continuous representations, we propose to adapt this framework to learn binary hashing codes. Specifically, we first propose to modify the objective function to meet the specific requirement of hashing and then introduce a probabilistic binary representation layer into the model to facilitate end-to-end training of the entire model. We further prove the strong connection between the proposed contrastive-learning-based hashing method and the mutual information, and show that the proposed model can be considered under the broader framework of the information bottleneck (IB). Under this perspective, a more general hashing model is naturally obtained. Extensive experimental results on three benchmark image datasets demonstrate that the proposed hashing method significantly outperforms existing baselines.

----

## [133] Adaptive Edge Attention for Graph Matching with Outliers

**Authors**: *Jingwei Qu, Haibin Ling, Chenrui Zhang, Xiaoqing Lyu, Zhi Tang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/134](https://doi.org/10.24963/ijcai.2021/134)

**Abstract**:

Graph matching aims at establishing correspondence between node sets of given graphs while keeping the consistency between their edge sets. However, outliers in practical scenarios and equivalent learning of edge representations in deep learning methods are still challenging. To address these issues, we present an Edge Attention-adaptive Graph Matching (EAGM) network and a novel description of edge features. EAGM transforms the matching relation between two graphs into a node and edge classification problem over their assignment graph. To explore the potential of edges, EAGM learns edge attention on the assignment graph to 1) reveal the impact of each edge on graph matching, as well as 2) adjust the learning of edge representations adaptively. To alleviate issues caused by the outliers, we describe an edge by aggregating the semantic information over the space spanned by the edge. Such rich information provides clear distinctions between different edges (e.g., inlier-inlier edges vs. inlier-outlier edges), which further distinguishes outliers in the view of their associated edges. Extensive experiments demonstrate that EAGM achieves promising matching quality compared with state-of-the-arts, on cases both with and without outliers. Our source code along with the experiments is available at https://github.com/bestwei/EAGM.

----

## [134] Multi-Level Graph Encoding with Structural-Collaborative Relation Learning for Skeleton-Based Person Re-Identification

**Authors**: *Haocong Rao, Shihao Xu, Xiping Hu, Jun Cheng, Bin Hu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/135](https://doi.org/10.24963/ijcai.2021/135)

**Abstract**:

Skeleton-based person re-identification (Re-ID) is an emerging open topic providing great value for safety-critical applications. Existing methods typically extract hand-crafted features or model skeleton dynamics from the trajectory of body joints, while they rarely explore valuable relation information contained in body structure or motion. To fully explore body relations, we construct graphs to model human skeletons from different levels, and for the first time propose a Multi-level Graph encoding approach with Structural-Collaborative Relation learning (MG-SCR) to encode discriminative graph features for person Re-ID. Specifically, considering that structurally-connected body components are highly correlated in a skeleton, we first propose a multi-head structural relation layer to learn different relations of neighbor body-component nodes in graphs, which helps aggregate key correlative features for effective node representations. Second, inspired by the fact that body-component collaboration in walking usually carries recognizable patterns, we propose a cross-level collaborative relation layer to infer collaboration between different level components, so as to capture more discriminative skeleton graph features. Finally, to enhance graph dynamics encoding, we propose a novel self-supervised sparse sequential prediction task for model pre-training, which facilitates encoding high-level graph semantics for person Re-ID. MG-SCR outperforms state-of-the-art skeleton-based methods, and it achieves superior performance to many multi-modal methods that utilize extra RGB or depth features. Our codes are available at https://github.com/Kali-Hac/MG-SCR.

----

## [135] Learning Visual Words for Weakly-Supervised Semantic Segmentation

**Authors**: *Lixiang Ru, Bo Du, Chen Wu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/136](https://doi.org/10.24963/ijcai.2021/136)

**Abstract**:

Current weakly-supervised semantic segmentation (WSSS) methods with image-level labels mainly adopt class activation maps (CAM) to generate the initial pseudo labels. However, CAM usually only identifies the most discriminative object extents, which is attributed to the fact that the network doesn't need to discover the integral object to recognize image-level labels. In this work, to tackle this problem, we proposed to simultaneously learn the image-level labels and local visual word labels. Specifically, in each forward propagation, the feature maps of the input image will be encoded to visual words with a learnable codebook. By enforcing the network to classify the encoded fine-grained visual words, the generated CAM could cover more semantic regions. Besides, we also proposed a hybrid spatial pyramid pooling module that could preserve local maximum and global average values of feature maps, so that more object details and less background were considered. Based on the proposed methods, we conducted experiments on the PASCAL VOC 2012 dataset. Our proposed method achieved 67.2% mIoU on the val set and 67.3% mIoU on the test set, which outperformed recent state-of-the-art methods.

----

## [136] Learning with Selective Forgetting

**Authors**: *Takashi Shibata, Go Irie, Daiki Ikami, Yu Mitsuzumi*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/137](https://doi.org/10.24963/ijcai.2021/137)

**Abstract**:

Lifelong learning aims to train a highly expressive model for a new task while retaining all knowledge for previous tasks. However, many practical scenarios do not always require the system to remember all of the past knowledge. Instead, ethical considerations call for selective and proactive forgetting of undesirable knowledge in order to prevent privacy issues and data leakage. In this paper, we propose a new framework for lifelong learning, called Learning with Selective Forgetting, which is to update a model for the new task with forgetting only the selected classes of the previous tasks while maintaining the rest. The key is to introduce a class-specific synthetic signal called mnemonic code. The codes are "watermarked" on all the training samples of the corresponding classes when the model is updated for a new task. This enables us to forget arbitrary classes later by only using the mnemonic codes without using the original data. Experiments on common benchmark datasets demonstrate the remarkable superiority of the proposed method over several existing methods.

----

## [137] Structure Guided Lane Detection

**Authors**: *Jinming Su, Chao Chen, Ke Zhang, Junfeng Luo, Xiaoming Wei, Xiaolin Wei*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/138](https://doi.org/10.24963/ijcai.2021/138)

**Abstract**:

Recently, lane detection has made great progress with the rapid development of deep neural networks and autonomous driving. However, there exist three mainly problems including characterizing lanes, modeling the structural relationship between scenes and lanes, and supporting more attributes (e.g., instance and type) of lanes. In this paper, we propose a novel structure guided framework to solve these problems simultaneously. In the framework, we first introduce a new lane representation to characterize each instance. Then a top-down vanishing point guided anchoring mechanism is proposed to produce intensive anchors, which efficiently capture various lanes. Next, multi-level structural constraints are used to improve the perception of lanes. In the process, pixel-level perception with binary segmentation is introduced to promote features around anchors and restore lane details from bottom up, a lane-level relation is put forward to model structures (i.e., parallel) around lanes, and an image-level attention is used to adaptively attend different regions of the image from the perspective of scenes. With the help of structural guidance, anchors are effectively classified and regressed to obtain precise locations and shapes. Extensive experiments on public benchmark datasets show that the proposed approach outperforms state-of-the-art methods with 117 FPS on a single GPU.

----

## [138] Towards Unsupervised Deformable-Instances Image-to-Image Translation

**Authors**: *Sitong Su, Jingkuan Song, Lianli Gao, Junchen Zhu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/139](https://doi.org/10.24963/ijcai.2021/139)

**Abstract**:

Replacing objects in images is a practical functionality of Photoshop, e.g., clothes changing. This task is defined as Unsupervised Deformable-Instances Image-to-Image Translation (UDIT), which maps multiple foreground instances of a source domain to a target domain, involving significant changes in shape. In this paper, we propose an effective pipeline named Mask-Guided Deformable-instances GAN (MGD-GAN) which first generates target masks in batch and then utilizes them to synthesize corresponding instances on the background image, with all instances efficiently translated and background well preserved. To promote the quality of synthesized images and stabilize the training, we design an elegant training procedure which transforms the unsupervised mask-to-instance process into a supervised way by creating paired examples. To objectively evaluate the performance of UDIT task, we design new evaluation metrics which are based on the object detection. Extensive experiments on four datasets demonstrate the significant advantages of our MGD-GAN over existing methods both quantitatively and qualitatively. Furthermore, our training time consumption is hugely reduced compared to the state-of-the-art. The code could be available at https://github.com/sitongsu/MGD_GAN.

----

## [139] Enhance Image as You Like with Unpaired Learning

**Authors**: *Xiaopeng Sun, Muxingzi Li, Tianyu He, Lubin Fan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/140](https://doi.org/10.24963/ijcai.2021/140)

**Abstract**:

Low-light image enhancement exhibits an ill-posed nature, as a given image may have many enhanced versions, yet recent studies focus on building a deterministic mapping from input to an enhanced version. In contrast, we propose a lightweight one-path conditional generative adversarial network (cGAN) to learn a one-to-many relation from low-light to normal-light image space, given only sets of low- and normal-light training images without any correspondence. By formulating this ill-posed problem as a modulation code learning task, our network learns to generate a collection of enhanced images from a given input conditioned on various reference images. Therefore our inference model easily adapts to various user preferences, provided with a few favorable photos from each user. Our model achieves competitive visual and quantitative results on par with fully supervised methods on both noisy and clean datasets, while being 6 to 10 times lighter than state-of-the-art generative adversarial networks (GANs) approaches.

----

## [140] Speech2Talking-Face: Inferring and Driving a Face with Synchronized Audio-Visual Representation

**Authors**: *Yasheng Sun, Hang Zhou, Ziwei Liu, Hideki Koike*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/141](https://doi.org/10.24963/ijcai.2021/141)

**Abstract**:

What can we picture solely from a clip of speech? Previous research has shown the possibility of directly inferring the appearance of a person's face by listening to a voice. However, within human speech lies not only the biometric identity signal but also the identity-irrelevant information such as the talking content. Our goal is to extract as much information from a clip of speech as possible. In particular, we aim at not only inferring the face of a person but also animating it. Our key insight is to synchronize audio and visual representations from two perspectives in a style-based generative framework. Specifically, contrastive learning is leveraged to map both the identity and speech content information within the speech to visual representation spaces. Furthermore, the identity space is strengthened with class centroids. Through curriculum learning, the style-based generator is capable of automatically balancing the information from the two latent spaces. Extensive experiments show that our approach encourages better speech-identity correlation learning while generating vivid faces whose identities are consistent with given speech samples. Moreover, by leveraging the same model, these inferred faces can be driven to talk by the audio.

----

## [141] Context-aware Cross-level Fusion Network for Camouflaged Object Detection

**Authors**: *Yujia Sun, Geng Chen, Tao Zhou, Yi Zhang, Nian Liu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/142](https://doi.org/10.24963/ijcai.2021/142)

**Abstract**:

Camouflaged object detection (COD) is a challenging task due to the low boundary contrast between the object and its surroundings. In addition, the appearance of camouflaged objects varies significantly, e.g., object size and shape, aggravating the difficulties of accurate COD. In this paper, we propose a novel Context-aware Crosslevel Fusion Network (C2F-Net) to address the challenging COD task. Specifically, we propose an Attention-induced Cross-level Fusion Module (ACFM) to integrate the multi-level features with
informative attention coefficients. The fused features are then fed to the proposed Dual-branch Global Context Module (DGCM), which yields multi-scale feature representations for exploiting rich global context information. In C2F-Net, the two modules are conducted on high-level features using a cascaded manner. Extensive experiments on three widely used benchmark datasets demonstrate that our C2F-Net is an effective COD model and outperforms state-of-the-art models remarkably. Our code is publicly available at:
https://github.com/thograce/C2FNet.

----

## [142] Proposal-free One-stage Referring Expression via Grid-Word Cross-Attention

**Authors**: *Wei Suo, Mengyang Sun, Peng Wang, Qi Wu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/143](https://doi.org/10.24963/ijcai.2021/143)

**Abstract**:

Referring Expression Comprehension (REC) has become one of the most important tasks in visual reasoning, since it is an essential step for many vision-and-language tasks such as visual question answering. However, it has not been widely used in many downstream tasks because it suffers 1) two-stage methods exist heavy computation cost and inevitable error accumulation, and 2) one-stage methods have to depend on lots of hyper-parameters (such as anchors) to generate bounding box. In this paper, we present a proposal-free one-stage (PFOS) model that is able to regress the region-of-interest from the image, based on a textual query, in an end-to-end manner. Instead of using the dominant anchor proposal fashion, we directly take the dense-grid of image as input for a cross-attention transformer that learns grid-word correspondences. The final bounding box is predicted directly from the image without the time-consuming anchor selection process that previous methods suffer. Our model achieves the state-of-the-art performance on four referring expression datasets with higher efficiency, comparing to previous best one-stage and two-stage methods.

----

## [143] MatchVIE: Exploiting Match Relevancy between Entities for Visual Information Extraction

**Authors**: *Guozhi Tang, Lele Xie, Lianwen Jin, Jiapeng Wang, Jingdong Chen, Zhen Xu, Qianying Wang, Yaqiang Wu, Hui Li*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/144](https://doi.org/10.24963/ijcai.2021/144)

**Abstract**:

Visual Information Extraction (VIE) task aims to extract key information from multifarious document images (e.g., invoices and purchase receipts). Most previous methods treat the VIE task simply as a sequence labeling problem or classification problem, which requires models to carefully identify each kind of semantics by introducing multimodal features, such as font, color, layout. But simply introducing multimodal features can't work well when faced with numeric semantic categories or some ambiguous texts. To address this issue, in this paper we propose a novel key-value matching model based on a graph neural network for VIE (MatchVIE). Through key-value matching based on relevancy evaluation, the proposed MatchVIE can bypass the recognitions to various semantics, and simply focuses on the strong relevancy between entities. Besides, we introduce a simple but effective operation, Num2Vec, to tackle the instability of encoded values, which helps model converge more smoothly. Comprehensive experiments demonstrate that the proposed MatchVIE can significantly outperform previous methods. Notably, to the best of our knowledge, MatchVIE may be the first attempt to tackle the VIE task by modeling the relevancy between keys and values and it is a good complement to the existing methods.

----

## [144] AVA: Adversarial Vignetting Attack against Visual Recognition

**Authors**: *Binyu Tian, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Xiaohong Li, Yang Liu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/145](https://doi.org/10.24963/ijcai.2021/145)

**Abstract**:

Vignetting is an inherent imaging phenomenon within almost all optical systems, showing as a radial intensity darkening toward the corners of an image. Since it is a common effect for photography and usually appears as a slight intensity variation, people usually regard it as a part of a photo and would not even want to post-process it. Due to this natural advantage, in this work, we study the vignetting from a new viewpoint, i.e., adversarial vignetting attack (AVA), which aims to embed intentionally misleading information into the vignetting and produce a natural adversarial example without noise patterns. This example can fool the state-of-the-art deep convolutional neural networks (CNNs) but is imperceptible to human. To this end, we first propose the radial-isotropic adversarial vignetting attack (RI-AVA) based on the physical model of vignetting, where the physical parameters (e.g., illumination factor and focal length) are tuned through the guidance of target CNN models. To achieve higher transferability across different CNNs, we further propose radial-anisotropic adversarial vignetting attack (RA-AVA) by allowing the effective regions of vignetting to be radial-anisotropic and shape-free. Moreover, we propose the geometry-aware level-set optimization method to solve the adversarial vignetting regions and physical parameters jointly. We validate the proposed methods on three popular datasets, i.e., DEV, CIFAR10, and Tiny ImageNet, by attacking four CNNs, e.g., ResNet50, EfficientNet-B0, DenseNet121, and MobileNet-V2, demonstrating the advantages of our methods over baseline methods on both transferability and image quality.

----

## [145] Towards Cross-View Consistency in Semantic Segmentation While Varying View Direction

**Authors**: *Xin Tong, Xianghua Ying, Yongjie Shi, He Zhao, Ruibin Wang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/146](https://doi.org/10.24963/ijcai.2021/146)

**Abstract**:

Several images are taken for the same scene with many view directions. Given a pixel in any one image of them, its correspondences may appear in the other images. However, by using existing semantic segmentation methods, we find that the pixel and its correspondences do not always have the same inferred label as expected. Fortunately, from the knowledge of multiple view geometry, if we keep the position of a camera unchanged, and only vary its orientation, there is a homography transformation to describe the relationship of corresponding pixels in such images. Based on this fact, we propose to generate images which are the same as real images of the scene taken in certain novel view directions for training and evaluation. We also introduce gradient guided deformable convolution to alleviate the inconsistency, by learning dynamic proper receptive field from feature gradients. Furthermore, a novel consistency loss is presented to enforce feature consistency. Compared with previous approaches, the proposed method gets significant improvement in both cross-view consistency and semantic segmentation performance on images with abundant view directions, while keeping comparable or better performance on the existing datasets.

----

## [146] Learning Interpretable Concept Groups in CNNs

**Authors**: *Saurabh Varshneya, Antoine Ledent, Robert A. Vandermeulen, Yunwen Lei, Matthias Enders, Damian Borth, Marius Kloft*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/147](https://doi.org/10.24963/ijcai.2021/147)

**Abstract**:

We propose a novel training methodology---Concept Group Learning (CGL)---that encourages training of interpretable CNN filters by partitioning filters in each layer into \emph{concept groups}, each of which is trained to learn a single visual concept. We achieve this through a novel regularization strategy that forces filters in the same group to be active in similar image regions for a given layer. We additionally use a regularizer to encourage a sparse weighting of the concept groups in each layer so that a few concept groups can have greater importance than others. We quantitatively evaluate CGL's model interpretability using standard interpretability evaluation techniques and find that our method increases interpretability scores in most cases. Qualitatively we compare the image regions which are most active under filters learned using CGL versus filters learned without CGL and find that CGL activation regions more strongly concentrate around semantically relevant features.

----

## [147] Text-based Person Search via Multi-Granularity Embedding Learning

**Authors**: *Chengji Wang, Zhiming Luo, Yaojin Lin, Shaozi Li*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/148](https://doi.org/10.24963/ijcai.2021/148)

**Abstract**:

Most existing text-based person search methods highly depend on exploring the corresponding relations between the regions of the image and the words in the sentence. However, these methods correlated image regions and words in the same semantic granularity. It 1) results in irrelevant corresponding relations between image and text, 2) causes an ambiguity embedding problem.  In this study, we propose a novel multi-granularity embedding learning model for text-based person search. It generates multi-granularity embeddings of partial person bodies in a coarse-to-fine manner by revisiting the person image at different spatial scales. Specifically, we distill the partial knowledge from image scrips to guide the model to select the semantically relevant words from the text description. It can learn discriminative and modality-invariant visual-textual embeddings. In addition, we integrate the partial embeddings at each granularity and perform multi-granularity image-text matching. Extensive experiments validate the effectiveness of our method, which can achieve new state-of-the-art performance by the learned discriminative partial embeddings.

----

## [148] Cross-Domain Few-Shot Classification via Adversarial Task Augmentation

**Authors**: *Haoqing Wang, Zhi-Hong Deng*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/149](https://doi.org/10.24963/ijcai.2021/149)

**Abstract**:

Few-shot classification aims to recognize unseen classes with few labeled samples from each class. Many meta-learning models for few-shot classification elaborately design various task-shared inductive bias (meta-knowledge) to solve such tasks, and achieve impressive performance. However, when there exists the domain shift between the training tasks and the test tasks, the obtained inductive bias fails to generalize across domains, which degrades the performance of the meta-learning models. In this work, we aim to improve the robustness of the inductive bias through task augmentation. Concretely, we consider the worst-case problem around the source task distribution, and propose the adversarial task augmentation method which can generate the inductive bias-adaptive 'challenging' tasks. Our method can be used as a simple plug-and-play module for various meta-learning models, and improve their cross-domain generalization capability. We conduct extensive experiments under the cross-domain setting, using nine few-shot classification datasets: mini-ImageNet, CUB, Cars, Places, Plantae, CropDiseases, EuroSAT, ISIC and ChestX. Experimental results show that our method can effectively improve the few-shot classification performance of the meta-learning models under domain shift, and outperforms the existing works. Our code is available at https://github.com/Haoqing-Wang/CDFSL-ATA.

----

## [149] Tag, Copy or Predict: A Unified Weakly-Supervised Learning Framework for Visual Information Extraction using Sequences

**Authors**: *Jiapeng Wang, Tianwei Wang, Guozhi Tang, Lianwen Jin, Weihong Ma, Kai Ding, Yichao Huang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/150](https://doi.org/10.24963/ijcai.2021/150)

**Abstract**:

Visual information extraction (VIE) has attracted increasing attention in recent years. The existing methods usually first organized optical character recognition (OCR) results in plain texts and then utilized token-level category annotations as supervision to train a sequence tagging model. However, it expends great annotation costs and may be exposed to label confusion, the OCR errors will also significantly affect the final performance. In this paper, we propose a unified weakly-supervised learning framework called TCPNet (Tag, Copy or Predict Network), which introduces 1) an efficient encoder to simultaneously model the semantic and layout information in 2D OCR results, 2) a weakly-supervised training method that utilizes only sequence-level supervision; and 3) a flexible and switchable decoder which contains two inference modes: one (Copy or Predict Mode) is to output key information sequences of different categories by copying a token from the input or predicting one in each time step, and the other (Tag Mode) is to directly tag the input sequence in a single forward pass. Our method shows new state-of-the-art performance on several public benchmarks, which fully proves its effectiveness.

----

## [150] Spline Positional Encoding for Learning 3D Implicit Signed Distance Fields

**Authors**: *Peng-Shuai Wang, Yang Liu, Yu-Qi Yang, Xin Tong*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/151](https://doi.org/10.24963/ijcai.2021/151)

**Abstract**:

Multilayer perceptrons (MLPs) have been successfully used to represent 3D
shapes implicitly and compactly, by mapping 3D coordinates to the
corresponding signed distance values or occupancy values. In this paper, we
propose a novel positional encoding scheme, called Spline Positional
Encoding, to map the input coordinates to a high dimensional space before
passing them to MLPs, which help recover 3D signed distance fields with
fine-scale geometric details from unorganized 3D point clouds.  We verified
the superiority of our approach over other positional encoding schemes on
tasks of 3D shape reconstruction and 3D shape space learning from input
point clouds. The efficacy of our approach extended to image reconstruction
is also demonstrated and evaluated.

----

## [151] Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion

**Authors**: *Suzhen Wang, Lincheng Li, Yu Ding, Changjie Fan, Xin Yu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/152](https://doi.org/10.24963/ijcai.2021/152)

**Abstract**:

We propose an audio-driven talking-head method to generate photo-realistic talking-head videos from a single reference image. In this work, we tackle two key challenges: (i) producing natural head motions that match speech prosody, and (ii)} maintaining the appearance of a speaker in a large head motion while stabilizing the non-face regions. We first design a head pose predictor by modeling rigid 6D head movements with a motion-aware recurrent neural network (RNN). In this way, the predicted head poses act as the low-frequency holistic movements of a talking head, thus allowing our latter network to focus on detailed facial movement generation. To depict the entire image motions arising from audio, we exploit a keypoint based dense motion field representation. Then, we develop a motion field generator to produce the dense motion fields from input audio, head poses, and a reference image. As this keypoint based representation models the motions of facial regions, head, and backgrounds integrally, our method can better constrain the spatial and temporal consistency of the generated videos. Finally, an image generation network is employed to render photo-realistic talking-head videos from the estimated keypoint based motion fields and the input reference image. Extensive experiments demonstrate that our method produces videos with plausible head motions, synchronized facial expressions, and stable backgrounds and outperforms the state-of-the-art.

----

## [152] Norm-guided Adaptive Visual Embedding for Zero-Shot Sketch-Based Image Retrieval

**Authors**: *Wenjie Wang, Yufeng Shi, Shiming Chen, Qinmu Peng, Feng Zheng, Xinge You*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/153](https://doi.org/10.24963/ijcai.2021/153)

**Abstract**:

Zero-shot sketch-based image retrieval (ZS-SBIR), which aims to retrieve photos with sketches under the zero-shot scenario, has shown extraordinary talents in real-world applications. Most existing methods leverage language models to generate class-prototypes and use them to arrange the locations of all categories in the common space for photos and sketches. Although great progress has been made, few of them consider whether such pre-defined prototypes are necessary for ZS-SBIR, where locations of unseen class samples in the embedding space are actually determined by visual appearance and a visual embedding actually performs better. To this end, we propose a novel Norm-guided Adaptive Visual Embedding (NAVE) model, for adaptively building the common space based on visual similarity instead of language-based pre-defined prototypes. To further enhance the representation quality of unseen classes for both photo and sketch modality, modality norm discrepancy and noisy label regularizer are jointly employed to measure and repair the modality bias of the learned common embedding. Experiments on two challenging datasets demonstrate the superiority of our NAVE over state-of-the-art competitors.

----

## [153] Dig into Multi-modal Cues for Video Retrieval with Hierarchical Alignment

**Authors**: *Wenzhe Wang, Mengdan Zhang, Runnan Chen, Guanyu Cai, Penghao Zhou, Pai Peng, Xiaowei Guo, Jian Wu, Xing Sun*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/154](https://doi.org/10.24963/ijcai.2021/154)

**Abstract**:

Multi-modal cues presented in videos are usually beneficial for the challenging video-text retrieval task on internet-scale datasets. Recent video retrieval methods take advantage of multi-modal cues by aggregating them to holistic high-level semantics for matching with text representations in a global view. In contrast to this global alignment, the local alignment of detailed semantics encoded within both multi-modal cues and distinct phrases is still not well conducted. Thus, in this paper, we leverage the hierarchical video-text alignment to fully explore the detailed diverse characteristics in multi-modal cues for fine-grained alignment with local semantics from phrases, as well as to capture a high-level semantic correspondence. Specifically, multi-step attention is learned for progressively comprehensive local alignment and a holistic transformer is utilized to summarize multi-modal cues for global alignment. With hierarchical alignment, our model outperforms state-of-the-art methods on three public video retrieval datasets.

----

## [154] Towards Compact Single Image Super-Resolution via Contrastive Self-distillation

**Authors**: *Yanbo Wang, Shaohui Lin, Yanyun Qu, Haiyan Wu, Zhizhong Zhang, Yuan Xie, Angela Yao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/155](https://doi.org/10.24963/ijcai.2021/155)

**Abstract**:

Convolutional neural networks (CNNs) are highly successful for super-resolution (SR) but often require sophisticated architectures with heavy memory cost and computational overhead significantly restricts their practical deployments on resource-limited devices. In this paper, we proposed a novel contrastive self-distillation (CSD) framework to simultaneously compress and accelerate various off-the-shelf SR models. In particular, a channel-splitting super-resolution network can first be constructed from a target teacher network as a compact student network. Then, we propose a novel contrastive loss to improve the quality of SR images and PSNR/SSIM via explicit knowledge transfer. Extensive experiments demonstrate that the proposed CSD scheme effectively compresses and accelerates several standard SR models such as EDSR, RCAN and CARN. Code is available at https://github.com/Booooooooooo/CSD.

----

## [155] Deep Unified Cross-Modality Hashing by Pairwise Data Alignment

**Authors**: *Yimu Wang, Bo Xue, Quan Cheng, Yuhui Chen, Lijun Zhang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/156](https://doi.org/10.24963/ijcai.2021/156)

**Abstract**:

With the increasing amount of multimedia data, cross-modality hashing has made great progress as it achieves sub-linear search time and low memory space. However, due to the huge discrepancy between different modalities, most existing cross-modality hashing methods cannot learn unified hash codes and functions for modalities at the same time. The gap between separated hash codes and functions further leads to bad search performance. In this paper, to address the issues above, we propose a novel end-to-end Deep Unified Cross-Modality Hashing method named DUCMH, which is able to jointly learn unified hash codes and unified hash functions by alternate learning and data alignment. Specifically, to reduce the discrepancy between image and text modalities, DUCMH utilizes data alignment to learn an auxiliary image to text mapping under the supervision of image-text pairs. For text data, hash codes can be obtained by unified hash functions, while for image data, DUCMH first maps images to texts by the auxiliary mapping, and then uses the mapped texts to obtain hash codes. DUCMH utilizes alternate learning to update unified hash codes and functions. Extensive experiments on three representative image-text datasets demonstrate the superiority of our DUCMH over several state-of-the-art cross-modality hashing methods.

----

## [156] HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping

**Authors**: *Yuhan Wang, Xu Chen, Junwei Zhu, Wenqing Chu, Ying Tai, Chengjie Wang, Jilin Li, Yongjian Wu, Feiyue Huang, Rongrong Ji*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/157](https://doi.org/10.24963/ijcai.2021/157)

**Abstract**:

In this work, we propose a high fidelity face swapping method, called HifiFace, which can well preserve the face shape of the source face and generate photo-realistic results. Unlike other existing face swapping works that only use face recognition model to keep the identity similarity, we propose 3D shape-aware identity to control the face shape with the geometric supervision from 3DMM and 3D face reconstruction method. Meanwhile, we introduce the Semantic Facial Fusion module to optimize the combination of encoder and decoder features and make adaptive blending, which makes the results more photo-realistic. Extensive experiments on faces in the wild demonstrate that our method can preserve better identity, especially on the face shape, and can generate more photo-realistic results than previous state-of-the-art methods. Code is available at: https://johann.wang/HifiFace

----

## [157] Domain-Smoothing Network for Zero-Shot Sketch-Based Image Retrieval

**Authors**: *Zhipeng Wang, Hao Wang, Jiexi Yan, Aming Wu, Cheng Deng*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/158](https://doi.org/10.24963/ijcai.2021/158)

**Abstract**:

Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) is a novel cross-modal retrieval task, where abstract sketches are used as queries to retrieve natural images under zero-shot scenario. Most existing methods regard ZS-SBIR as a traditional classification problem and employ a cross-entropy or triplet-based loss to achieve retrieval, which neglect the problems of the domain gap between sketches and natural images and the large intra-class diversity in sketches. Toward this end, we propose a novel Domain-Smoothing Network (DSN) for ZS-SBIR. Specifically, a cross-modal contrastive method is proposed to learn generalized representations to smooth the domain gap by mining relations with additional augmented samples. Furthermore, a category-specific memory bank with sketch features is explored to reduce intra-class diversity in the sketch domain. Extensive experiments demonstrate that our approach notably outperforms the state-of-the-art methods in both Sketchy and TU-Berlin datasets.

----

## [158] Local Representation is Not Enough: Soft Point-Wise Transformer for Descriptor and Detector of Local Features

**Authors**: *Zihao Wang, Xueyi Li, Zhen Li*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/159](https://doi.org/10.24963/ijcai.2021/159)

**Abstract**:

Significant progress has been witnessed for the descriptor and detector of local features, but there still exist several challenging and intractable limitations, such as insufficient localization accuracy and non-discriminative description, especially in repetitive- or blank-texture regions, which haven't be well addressed. The coarse feature representation and limited receptive field are considered as the main issues for these limitations. To address these issues, we propose a novel Soft Point-Wise Transformer for Descriptor and Detector, simultaneously mining long-range intrinsic and cross-scale dependencies of local features. Furthermore, our model leverages the distinct transformers based on the soft point-wise attention, substantially decreasing the memory and computation complexity, especially for high-resolution feature maps. In addition, multi-level decoder is constructed to guarantee the high detection accuracy and discriminative description. Extensive experiments demonstrate that our model outperforms the existing state-of-the-art methods on the image matching and visual localization benchmarks.

----

## [159] Weakly Supervised Dense Video Captioning via Jointly Usage of Knowledge Distillation and Cross-modal Matching

**Authors**: *Bofeng Wu, Guocheng Niu, Jun Yu, Xinyan Xiao, Jian Zhang, Hua Wu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/160](https://doi.org/10.24963/ijcai.2021/160)

**Abstract**:

This paper proposes an approach to Dense Video Captioning (DVC) without pairwise event-sentence annotation. First, we adopt the knowledge distilled from relevant and well solved tasks to generate high-quality event proposals. Then we incorporate contrastive loss and cycle-consistency loss typically applied to cross-modal retrieval tasks to build semantic matching between the proposals and sentences, which are eventually used to train the caption generation module. In addition, the parameters of matching module are initialized via pre-training based on annotated images to improve the matching performance. Extensive experiments on ActivityNet-Caption dataset reveal the significance of distillation-based event proposal generation and cross-modal retrieval-based semantic matching to weakly supervised DVC, and demonstrate the superiority of our method to existing state-of-the-art methods.

----

## [160] Tracklet Proposal Network for Multi-Object Tracking on Point Clouds

**Authors**: *Hai Wu, Qing Li, Chenglu Wen, Xin Li, Xiaoliang Fan, Cheng Wang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/161](https://doi.org/10.24963/ijcai.2021/161)

**Abstract**:

This paper proposes the first tracklet proposal network, named PC-TCNN, for Multi-Object Tracking (MOT) on point clouds. Our pipeline first generates tracklet proposals,  then refines these tracklets and associates them to generate long trajectories. Specifically, object proposal generation and motion regression are first performed on a point cloud sequence to generate tracklet candidates. Then, spatial-temporal features of each tracklet are exploited and their consistency is used to refine the tracklet proposal. Finally, the refined tracklets across multiple frames are associated to perform MOT on the point cloud sequence. The PC-TCNN significantly improves the MOT performance by introducing the tracklet proposal design. On the KITTI tracking benchmark, it attains an MOTA of 91.75%, outperforming all submitted results on the online leaderboard.

----

## [161] Weakly-Supervised Spatio-Temporal Anomaly Detection in Surveillance Video

**Authors**: *Jie Wu, Wei Zhang, Guanbin Li, Wenhao Wu, Xiao Tan, Yingying Li, Errui Ding, Liang Lin*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/162](https://doi.org/10.24963/ijcai.2021/162)

**Abstract**:

In this paper, we introduce a novel task, referred to as Weakly-Supervised Spatio-Temporal Anomaly Detection (WSSTAD) in surveillance video. Specifically, given an untrimmed video, WSSTAD aims to localize a spatio-temporal tube (i.e., a sequence of bounding boxes at consecutive times) that encloses the abnormal event, with only coarse video-level annotations as supervision during training. To address this challenging task, we propose a dual-branch network which takes as input the proposals with multi-granularities in both spatial-temporal domains. Each branch employs a relationship reasoning module to capture the correlation between tubes/videolets, which can provide rich contextual information and complex entity relationships for the concept learning of abnormal behaviors. Mutually-guided Progressive Refinement framework is set up to employ dual-path mutual guidance in a recurrent manner, iteratively sharing auxiliary supervision information across branches. It impels the learned concepts of each branch to serve as a guide for its counterpart, which progressively refines the corresponding branch and the whole framework. Furthermore, we contribute two datasets, i.e., ST-UCF-Crime and STRA, consisting of videos containing spatio-temporal abnormal annotations to serve as the benchmarks for WSSTAD. We conduct extensive qualitative and quantitative evaluations to demonstrate the effectiveness of the proposed approach and analyze the key factors that contribute more to handle this task.

----

## [162] GM-MLIC: Graph Matching based Multi-Label Image Classification

**Authors**: *Yanan Wu, He Liu, Songhe Feng, Yi Jin, Gengyu Lyu, Zizhang Wu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/163](https://doi.org/10.24963/ijcai.2021/163)

**Abstract**:

Multi-Label Image Classification (MLIC) aims to predict a set of labels that present in an image. The key to deal with such problem is to mine the associations between image contents and labels, and further obtain the correct assignments between images and their labels. In this paper, we treat each image as a bag of instances, and reformulate the task of MLIC as a instance-label matching selection problem. To model such problem, we propose a novel deep learning framework named Graph Matching based Multi-Label Image Classification (GM-MLIC), where Graph Matching (GM) scheme is introduced owing to its excellent capability of excavating the instance and label relationship. Specifically,  we first construct an instance spatial graph and a label semantic graph respectively, and then incorporate them into a constructed assignment graph by connecting each instance to all labels. Subsequently, the graph network block is adopted to aggregate and update all nodes and edges state on the assignment graph to form structured representations for each instance and label. Our network finally derives a prediction score for each instance-label correspondence and optimizes such correspondence with a weighted cross-entropy loss. Extensive experiments conducted on various datasets demonstrate the superiority of our proposed method.

----

## [163] Micro-Expression Recognition Enhanced by Macro-Expression from Spatial-Temporal Domain

**Authors**: *Bin Xia, Shangfei Wang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/164](https://doi.org/10.24963/ijcai.2021/164)

**Abstract**:

Facial micro-expression recognition has attracted much attention due to its objectiveness to reveal the true emotion of a person. However, the limited micro-expression datasets have posed a great challenge to train a high performance micro-expression classifier. Since micro-expression and macro-expression share some similarities in both spatial and temporal facial behavior patterns, we propose a macro-to-micro transformation framework for micro-expression recognition. Specifically, we first pretrain two-stream baseline model from micro-expression data and macro-expression data respectively, named MiNet and MaNet. Then, we introduce two auxiliary tasks to align the spatial and temporal features learned from micro-expression data and macro-expression data. In spatial domain, we introduce a domain discriminator to align the features of MiNet and MaNet. In temporal domain, we introduce relation classifier to predict the correct relation for temporal features from MaNet and MiNet. Finally, we propose contrastive loss to encourage the MiNet to give closely aligned features to all entries from the same class in each instance. Experiments on three benchmark databases demonstrate the superiority of the proposed method.

----

## [164] Segmenting Transparent Objects in the Wild with Transformer

**Authors**: *Enze Xie, Wenjia Wang, Wenhai Wang, Peize Sun, Hang Xu, Ding Liang, Ping Luo*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/165](https://doi.org/10.24963/ijcai.2021/165)

**Abstract**:

This work presents a new fine-grained transparent object segmentation dataset, termed Trans10K-v2, extending Trans10K-v1, the first large-scale transparent object segmentation dataset. 
Unlike Trans10K-v1 that only has two limited categories, our new dataset has several appealing benefits. (1) It has 11 fine-grained categories of transparent objects, commonly occurring in the human domestic environment, making it more practical for real-world application. 
(2) Trans10K-v2 brings more challenges for the current advanced segmentation methods than its former version.

Furthermore, a novel Transformer-based segmentation pipeline termed Trans2Seg is proposed.

Firstly, the Transformer encoder of Trans2Seg provides the global receptive field in contrast to CNN's local receptive field, which shows excellent advantages over pure CNN architectures.

Secondly, by formulating semantic segmentation as a problem of dictionary look-up, we design a set of learnable prototypes as the query of Trans2Seg's Transformer decoder, where each prototype learns the statistics of one category in the whole dataset.

We benchmark more than 20 recent semantic segmentation methods, demonstrating that Trans2Seg significantly outperforms all the CNN-based methods, showing the proposed algorithm's potential ability to solve transparent object segmentation.Code is available in https://github.com/xieenze/Trans2Seg.

----

## [165] Adversarial Feature Disentanglement for Long-Term Person Re-identification

**Authors**: *Wanlu Xu, Hong Liu, Wei Shi, Ziling Miao, Zhisheng Lu, Feihu Chen*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/166](https://doi.org/10.24963/ijcai.2021/166)

**Abstract**:

Most existing person re-identification methods are effective in short-term scenarios because of their appearance dependencies. However, these methods may fail in long-term scenarios where people might change their clothes. To this end, we propose an adversarial feature disentanglement network (AFD-Net) which contains intra-class reconstruction and inter-class adversary to disentangle the identity-related and identity-unrelated (clothing) features. For intra-class reconstruction, the person images with the same identity are represented and disentangled into identity and clothing features by two separate encoders, and further reconstructed into original images to reduce intra-class feature variations. For inter-class adversary, the disentangled features across different identities are exchanged and recombined to generate adversarial clothes-changing images for training, which makes the identity and clothing features more independent. Especially, to supervise these new generated clothes-changing images, a re-feeding strategy is designed to re-disentangle and reconstruct these new images for image-level self-supervision in the original image space and feature-level soft-supervision in the disentangled feature space. Moreover, we collect a challenging Market-Clothes dataset and a real-world PKU-Market-Reid dataset for evaluation. The results on one large-scale short-term dataset (Market-1501) and five long-term datasets (three public and two we proposed) confirm the superiority of our method against other state-of-the-art methods.

----

## [166] Tool- and Domain-Agnostic Parameterization of Style Transfer Effects Leveraging Pretrained Perceptual Metrics

**Authors**: *Hiromu Yakura, Yuki Koyama, Masataka Goto*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/167](https://doi.org/10.24963/ijcai.2021/167)

**Abstract**:

Current deep learning techniques for style transfer would not be optimal for design support since their "one-shot" transfer does not fit exploratory design processes. To overcome this gap, we propose parametric transcription, which transcribes an end-to-end style transfer effect into parameter values of specific transformations available in an existing content editing tool. With this approach, users can imitate the style of a reference sample in the tool that they are familiar with and thus can easily continue further exploration by manipulating the parameters. To enable this, we introduce a framework that utilizes an existing pretrained model for style transfer to calculate a perceptual style distance to the reference sample and uses black-box optimization to find the parameters that minimize this distance. Our experiments with various third-party tools, such as Instagram and Blender, show that our framework can effectively leverage deep learning techniques for computational design support.

----

## [167] Hierarchical Self-supervised Augmented Knowledge Distillation

**Authors**: *Chuanguang Yang, Zhulin An, Linhang Cai, Yongjun Xu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/168](https://doi.org/10.24963/ijcai.2021/168)

**Abstract**:

Knowledge distillation often involves how to define and transfer knowledge from teacher to student effectively. Although recent self-supervised contrastive knowledge achieves the best performance, forcing the network to learn such knowledge may damage the representation learning of the original class recognition task. We therefore adopt an alternative self-supervised augmented task to guide the network to learn the joint distribution of the original recognition task and self-supervised auxiliary task. It is demonstrated as a richer knowledge to improve the representation power without losing the normal classification capability. Moreover, it is incomplete that previous methods only transfer the probabilistic knowledge between the final layers. We propose to append several auxiliary classifiers to hierarchical intermediate feature maps to generate diverse self-supervised knowledge and perform the one-to-one transfer to teach the student network thoroughly. Our method significantly surpasses the previous SOTA SSKD with an average improvement of 2.56% on CIFAR-100 and an improvement of 0.77% on ImageNet across widely used network pairs. Codes are available at https://github.com/winycg/HSAKD.

----

## [168] RR-Net: Injecting Interactive Semantics in Human-Object Interaction Detection

**Authors**: *Dongming Yang, Yuexian Zou, Can Zhang, Meng Cao, Jie Chen*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/169](https://doi.org/10.24963/ijcai.2021/169)

**Abstract**:

Human-Object Interaction (HOI) detection devotes to learn how humans interact with surrounding objects. Latest end-to-end HOI detectors are short of relation reasoning, which leads to inability to learn HOI-specific interactive semantics for predictions. In this paper, we therefore propose novel relation reasoning for HOI detection. We first present a progressive Relation-aware Frame, which brings a new structure and parameter sharing pattern for interaction inference. Upon the frame, an Interaction Intensifier Module and a Correlation Parsing Module are carefully designed, where: a) interactive semantics from humans can be exploited and passed to objects to intensify interactions, b) interactive correlations among humans, objects and interactions are integrated to promote predictions. Based on modules above, we construct an end-to-end trainable framework named Relation Reasoning Network (abbr. RR-Net). Extensive experiments show that our proposed RR-Net sets a new state-of-the-art on both V-COCO and HICO-DET benchmarks and improves the baseline about 5.5% and 9.8% relatively, validating that this first effort in exploring relation reasoning and integrating interactive semantics has brought obvious improvement for end-to-end HOI detection.

----

## [169] Non-contact Pain Recognition from Video Sequences with Remote Physiological Measurements Prediction

**Authors**: *Ruijing Yang, Ziyu Guan, Zitong Yu, Xiaoyi Feng, Jinye Peng, Guoying Zhao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/170](https://doi.org/10.24963/ijcai.2021/170)

**Abstract**:

Automatic pain recognition is paramount for medical diagnosis and treatment. The existing works fall into three categories: assessing facial appearance changes, exploiting physiological cues, or fusing them in a multi-modal manner. However, (1) appearance changes are easily affected by subjective factors which impedes objective pain recognition. Besides, the appearance-based approaches ignore long-range spatial-temporal dependencies that are important for modeling expressions over time; (2) the physiological cues are obtained by attaching sensors on human body, which is inconvenient and uncomfortable. In this paper, we present a novel multi-task learning framework which encodes both appearance changes and physiological cues in a non-contact manner for pain recognition. The framework is able to capture both local and long-range dependencies via the proposed attention mechanism for the learned appearance representations, which are further enriched by temporally attended physiological cues (remote photoplethysmography, rPPG) that are recovered from videos in the auxiliary task. This framework is dubbed rPPG-enriched Spatio-Temporal Attention Network (rSTAN) and allows us to establish the state-of-the-art performance of non-contact pain recognition on publicly available pain databases. It demonstrates that rPPG predictions can be used as an auxiliary task to facilitate non-contact automatic pain recognition.

----

## [170] Coupling Intent and Action for Pedestrian Crossing Behavior Prediction

**Authors**: *Yu Yao, Ella M. Atkins, Matthew Johnson-Roberson, Ram Vasudevan, Xiaoxiao Du*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/171](https://doi.org/10.24963/ijcai.2021/171)

**Abstract**:

Accurate prediction of pedestrian crossing behaviors by autonomous vehicles can significantly improve traffic safety. Existing approaches often model pedestrian behaviors using trajectories or poses but do not offer a deeper semantic interpretation of a person's actions or how actions influence a pedestrian's intention to cross in the future. In this work, we follow the neuroscience and psychological literature to define pedestrian crossing behavior as a combination of an unobserved inner will (a probabilistic representation of binary intent of crossing vs. not crossing) and a set of multi-class actions (e.g., walking, standing, etc.). Intent generates actions, and the future actions in turn reflect the intent. We present a novel multi-task network that predicts future pedestrian actions and uses predicted future action as a prior to detect the present intent and action of the pedestrian. We also designed an attention relation network to incorporate external environmental contexts thus further improve intent and action detection performance. We evaluated our approach on two naturalistic driving datasets, PIE and JAAD, and extensive experiments show significantly improved and more explainable results for both intent detection and  action prediction over state-of-the-art approaches. Our code is available at: https://github.com/umautobots/pedestrian_intent_action_detection

----

## [171] Object Detection in Densely Packed Scenes via Semi-Supervised Learning with Dual Consistency

**Authors**: *Chao Ye, Huaidong Zhang, Xuemiao Xu, Weiwei Cai, Jing Qin, Kup-Sze Choi*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/172](https://doi.org/10.24963/ijcai.2021/172)

**Abstract**:

Deep neural networks have been shown to be very powerful tools for object detection in various scenes. Their remarkable performance, however, heavily depends on the availability of a large number of high quality labeled data, which are time-consuming and costly to acquire for scenes with densely packed objects.  We present a novel semi-supervised approach to addressing this problem, which is designed based on a common teacher-student model, integrated with a novel intersection-over-union (IoU) aware consistency loss and a new proposal consistency loss. The IoU-aware consistency loss evaluates the IoU over the prediction pairs of the teacher model and the student model, which enforces the prediction of the student model to approach closely to that of the teacher model. The IoU-aware consistency loss also reweights the importance of different prediction pairs to suppress the low-confident pairs. The proposal consistency loss ensures proposal consistency between the two models, making it possible to involve the region proposal network in the training process with unlabeled data. We also construct a new dataset, namely RebarDSC, containing 2,125 rebar images annotated with 350,348 bounding boxes in total (164.9 annotations per image average), to evaluate the proposed method. Extensive experiments are conducted over both the RebarDSC dataset and the famous large public dataset SKU-110K. Experimental results corroborate that the proposed method is able to improve the object detection performance in densely packed scenes, consistently outperforming state-of-the-art approaches. Dataset is available in https://github.com/Armin1337/RebarDSC.

----

## [172] Adv-Makeup: A New Imperceptible and Transferable Attack on Face Recognition

**Authors**: *Bangjie Yin, Wenxuan Wang, Taiping Yao, Junfeng Guo, Zelun Kong, Shouhong Ding, Jilin Li, Cong Liu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/173](https://doi.org/10.24963/ijcai.2021/173)

**Abstract**:

Deep neural networks, particularly face recognition models, have been shown to be vulnerable to both digital and physical adversarial examples. However, existing adversarial examples against face recognition systems either lack transferability to black-box models, or fail to be implemented in practice. In this paper, we propose a unified adversarial face generation method - Adv-Makeup, which can realize imperceptible and transferable attack under the black-box setting. Adv-Makeup develops a task-driven makeup generation method with the blending module to synthesize imperceptible eye shadow over the orbital region on faces. And to achieve transferability, Adv-Makeup implements a fine-grained meta-learning based adversarial attack strategy to learn more vulnerable or sensitive features from various models. Compared to existing techniques, sufficient visualization results demonstrate that Adv-Makeup is capable to generate much more imperceptible attacks under both digital and physical scenarios. Meanwhile, extensive quantitative experiments show that Adv-Makeup can significantly improve the attack success rate under black-box setting, even attacking commercial systems.

----

## [173] Multimodal Transformer Networks for Pedestrian Trajectory Prediction

**Authors**: *Ziyi Yin, Ruijin Liu, Zhiliang Xiong, Zejian Yuan*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/174](https://doi.org/10.24963/ijcai.2021/174)

**Abstract**:

We consider the problem of forecasting the future locations of pedestrians in an ego-centric view of a moving vehicle. Current CNNs or RNNs are flawed in capturing the high dynamics of motion between pedestrians and the ego-vehicle, and suffer from the massive parameter usages due to the inefficiency of learning long-term temporal dependencies. To address these issues, we propose an efficient multimodal transformer network that aggregates the trajectory and ego-vehicle speed variations at a coarse granularity and interacts with the optical flow in a fine-grained level to fill the vacancy of highly dynamic motion. Specifically, a coarse-grained fusion stage fuses the information between trajectory and ego-vehicle speed modalities to capture the general temporal consistency. Meanwhile, a fine-grained fusion stage merges the optical flow in the center area and pedestrian area, which compensates the highly dynamic motion of ego-vehicle and target pedestrian. Besides, the whole network is only attention-based that can efficiently model long-term sequences for better capturing the temporal variations. Our multimodal transformer is validated on the PIE and JAAD datasets and achieves state-of-the-art performance with the most light-weight model size. The codes are available at https://github.com/ericyinyzy/MTN_trajectory.

----

## [174] EmbedMask: Embedding Coupling for Instance Segmentation

**Authors**: *Hui Ying, Zhaojin Huang, Shu Liu, Tianjia Shao, Kun Zhou*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/175](https://doi.org/10.24963/ijcai.2021/175)

**Abstract**:

Current instance segmentation methods can be categorized into segmentation-based methods and proposal-based methods. The former performs segmentation first and then does clustering, while the latter detects objects first and then predicts the mask for each object proposal. In this work, we propose a single-stage method, named EmbedMask, that unifies both methods by taking their advantages, so it can achieve good performance in instance segmentation and produce high-resolution masks in a high speed. EmbedMask introduces two newly defined embeddings for mask prediction, which are pixel embedding and proposal embedding. During training, we enforce the pixel embedding to be close to its coupled proposal embedding if they belong to the same instance. During inference, pixels are assigned to the mask of the proposal if their embeddings are similar. This mechanism brings several benefits. First, the pixel-level clustering enables EmbedMask to generate high-resolution masks and avoids the complicated two-stage mask prediction. Second, the existence of proposal embedding simplifies and strengthens the clustering procedure, so our method can achieve high speed and better performance than segmentation-based methods. Without any bell or whistle, EmbedMask outperforms the state-of-the-art instance segmentation method Mask R-CNN on the challenging COCO dataset, obtaining more detailed masks at a higher speed.

----

## [175] CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation

**Authors**: *Jing Yu, Yuan Chai, Yujing Wang, Yue Hu, Qi Wu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/176](https://doi.org/10.24963/ijcai.2021/176)

**Abstract**:

Scene  graphs  are  semantic  abstraction  of  images that encourage visual understanding and reasoning. However,  the  performance  of  Scene  Graph  Generation  (SGG)  is  unsatisfactory  when  faced  with biased data in real-world scenarios.  Conventional debiasing  research  mainly  studies  from  the  view of balancing data distribution or learning unbiased models  and  representations,  ignoring  the  correlations among the biased classes. In this work, we analyze this problem from a novel cognition perspective:  automatically  building  a  hierarchical  cognitive structure from the biased predictions and navigating  that  hierarchy  to  locate  the  relationships, making  the  tail  relationships  receive  more  attention in a coarse-to-fine mode.  To this end, we propose a novel debiasing Cognition Tree (CogTree) loss  for  unbiased  SGG.  We  first  build  a  cognitive structure CogTree to organize the relationships based  on  the  prediction  of  a  biased  SGG  model. The CogTree distinguishes remarkably different relationships  at  first  and  then  focuses  on  a  small portion  of  easily  confused  ones.   Then,  we  propose  a  debiasing  loss  specially  for  this  cognitive structure, which supports coarse-to-fine distinction for  the  correct  relationships.   The  loss  is  model-agnostic and consistently boosting the performance of  several  state-of-the-art  models. The  code  is available at:  https://github.com/CYVincent/Scene-Graph-Transformer-CogTree.

----

## [176] Dual-Cross Central Difference Network for Face Anti-Spoofing

**Authors**: *Zitong Yu, Yunxiao Qin, Hengshuang Zhao, Xiaobai Li, Guoying Zhao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/177](https://doi.org/10.24963/ijcai.2021/177)

**Abstract**:

Face anti-spoofing (FAS) plays a vital role in securing face recognition systems. Recently, central difference convolution (CDC) has shown its excellent representation capacity for the FAS task via leveraging local gradient features. However, aggregating central difference clues from all neighbors/directions simultaneously makes the CDC redundant and sub-optimized in the training phase. In this paper, we propose two Cross Central Difference Convolutions (C-CDC), which exploit the difference of the center and surround sparse local features from the horizontal/vertical and diagonal directions, respectively. It is interesting to find that, with only five ninth parameters and less computational cost, C-CDC even outperforms the full directional CDC. Based on these two decoupled C-CDC, a powerful Dual-Cross Central Difference Network (DC-CDN) is established with Cross Feature Interaction Modules (CFIM) for mutual relation mining and local detailed representation enhancement. Furthermore, a novel Patch Exchange (PE) augmentation strategy for FAS is proposed via simply exchanging the face patches as well as their dense labels from random samples. Thus, the augmented samples contain richer live/spoof patterns and diverse domain distributions, which benefits the intrinsic and robust feature learning. Comprehensive experiments are performed on four benchmark datasets with three testing protocols to demonstrate our state-of-the-art performance.

----

## [177] Detecting Deepfake Videos with Temporal Dropout 3DCNN

**Authors**: *Daichi Zhang, Chenyu Li, Fanzhao Lin, Dan Zeng, Shiming Ge*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/178](https://doi.org/10.24963/ijcai.2021/178)

**Abstract**:

While the abuse of deepfake technology has brought about a serious impact on human society, the detection of deepfake videos is still very challenging due to their highly photorealistic synthesis on each frame. To address that, this paper aims to leverage the possible inconsistent cues among video frames and proposes a Temporal Dropout 3-Dimensional Convolutional Neural Network (TD-3DCNN) to detect deepfake videos. In the approach, the fixed-length frame volumes sampled from a video are fed into a 3-Dimensional Convolutional Neural Network (3DCNN) to extract features across different scales and identified whether they are real or fake. Especially, a temporal dropout operation is introduced to randomly sample frames in each batch. It serves as a simple yet effective data augmentation and can enhance the representation and generalization ability, avoiding model overfitting and improving detecting accuracy. In this way, the resulting video-level classifier is accurate and effective to identify deepfake videos. Extensive experiments on benchmarks including Celeb-DF(v2) and DFDC clearly demonstrate the effectiveness and generalization capacity of our approach.

----

## [178] Low Resolution Information Also Matters: Learning Multi-Resolution Representations for Person Re-Identification

**Authors**: *Guoqing Zhang, Yuhao Chen, Weisi Lin, Arun Kumar Chandran, Xuan Jing*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/179](https://doi.org/10.24963/ijcai.2021/179)

**Abstract**:

As a prevailing task in video surveillance and forensics field, person re-identification (re-ID) aims to match person images captured from non-overlapped cameras. In unconstrained scenarios, person images often suffer from the resolution mismatch problem, i.e., Cross-Resolution Person Re-ID. To overcome this problem, most existing methods restore low resolution (LR) images to high resolution (HR) by super-resolution (SR). However, they only focus on the HR feature extraction and ignore the valid information from original LR images. In this work, we explore the influence of resolutions on feature extraction and develop a novel method for cross-resolution person re-ID called Multi-Resolution Representations Joint Learning (MRJL). Our method consists of a Resolution Reconstruction Network (RRN) and a Dual Feature Fusion Network (DFFN). The RRN uses an input image to construct a HR version and a LR version with an encoder and two decoders, while the DFFN adopts a dual-branch structure to generate person representations from multi-resolution images. Comprehensive experiments on five benchmarks verify the superiority of the proposed MRJL over the relevent state-of-the-art methods.

----

## [179] Removing Foreground Occlusions in Light Field using Micro-lens Dynamic Filter

**Authors**: *Shuo Zhang, Zeqi Shen, Youfang Lin*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/180](https://doi.org/10.24963/ijcai.2021/180)

**Abstract**:

Foreground occlusion removal task aims to automatically detect and remove foreground occlusions and recover background objects. Since for Light Fields (LFs), background objects occluded in some views may be seen in other views, the foreground occlusion removal task for LFs is easy to achieve. In this paper, we propose a learning-based method combining ‘seeking’ and ‘generating’ to  recover occluded background. Specifically, the micro-lens dynamic filters are  proposed to ‘seek’ occluded background points in shifted micro-lens images and remove occlusions using angular information. The shifted images are then combined to further ‘generate’ background regions to supplement more background details using spatial information. By fully exploring the angular and spatial information in LFs, the dense and complex occlusions can be easily removed. Quantitative and qualitative experimental results show that our method outperforms other state-of-the-arts methods by a large margin.

----

## [180] Learning Implicit Temporal Alignment for Few-shot Video Classification

**Authors**: *Songyang Zhang, Jiale Zhou, Xuming He*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/181](https://doi.org/10.24963/ijcai.2021/181)

**Abstract**:

Few-shot video classification aims to learn new video categories with only a few labeled examples, alleviating the burden of costly annotation in real-world applications. However, it is particularly challenging to learn a class-invariant  spatial-temporal representation in such a setting. To address this, we propose a novel matching-based few-shot learning strategy for video sequences in this work. Our main idea is to introduce an implicit temporal alignment for a video pair, capable of estimating the similarity between them in an accurate and robust manner. Moreover, we design an effective context encoding module to incorporate spatial and feature channel context, resulting in better modeling of intra-class variations. To train our model, we develop a multi-task loss for learning video matching, leading to video features with better generalization. Extensive experimental results on two challenging benchmarks, show that our method outperforms the prior arts with a sizable margin on Something-Something-V2 and competitive results on Kinetics.

----

## [181] What If We Could Not See? Counterfactual Analysis for Egocentric Action Anticipation

**Authors**: *Tianyu Zhang, Weiqing Min, Jiahao Yang, Tao Liu, Shuqiang Jiang, Yong Rui*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/182](https://doi.org/10.24963/ijcai.2021/182)

**Abstract**:

Egocentric action anticipation aims at predicting the near future based on past observation in first-person vision. While future actions may be wrongly predicted due to the dataset bias, we present a counterfactual analysis framework for egocentric action anticipation (CA-EAA) to enhance the capacity. In the factual case, we can predict the upcoming action based on visual features and semantic labels from past observation. Imagining one counterfactual situation where no visual representation had been observed, we would obtain a counterfactual predicted action only using past semantic labels. In this way, we can reduce the side-effect caused by semantic labels via a comparison between factual and counterfactual outcomes, which moves a step towards unbiased prediction for egocentric action anticipation.  We conduct experiments on two large-scale egocentric video datasets. Qualitative and quantitative results validate the effectiveness of our proposed CA-EAA.

----

## [182] Context-Aware Image Inpainting with Learned Semantic Priors

**Authors**: *Wendong Zhang, Junwei Zhu, Ying Tai, Yunbo Wang, Wenqing Chu, Bingbing Ni, Chengjie Wang, Xiaokang Yang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/183](https://doi.org/10.24963/ijcai.2021/183)

**Abstract**:

Recent advances in image inpainting have shown impressive results for generating plausible visual details on rather simple backgrounds. However, for complex scenes, it is still challenging to restore reasonable contents as the contextual information within the missing regions tends to be ambiguous. To tackle this problem, we introduce pretext tasks that are semantically meaningful to estimating the missing contents. In particular, we perform knowledge distillation on pretext models and adapt the features to image inpainting. The learned semantic priors ought to be partially invariant between the high-level pretext task and low-level image inpainting, which not only help to understand the global context but also provide structural guidance for the restoration of local textures. Based on the semantic priors, we further propose a context-aware image inpainting model, which adaptively integrates global semantics and local features in a unified image generator. The semantic learner and the image generator are trained in an end-to-end manner. We name the model SPL to highlight its ability to learn and leverage semantic priors. It achieves the state of the art on Places2, CelebA, and Paris StreetView datasets

----

## [183] Sequential 3D Human Pose Estimation Using Adaptive Point Cloud Sampling Strategy

**Authors**: *Zihao Zhang, Lei Hu, Xiaoming Deng, Shihong Xia*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/184](https://doi.org/10.24963/ijcai.2021/184)

**Abstract**:

3D human pose estimation is a fundamental problem in artificial intelligence, and it has wide applications in AR/VR, HCI and robotics. However, human pose estimation from point clouds still suffers from noisy points and estimated jittery artifacts because of handcrafted-based point cloud sampling and single-frame-based estimation strategies. In this paper, we present a new perspective on the 3D human pose estimation method from point cloud sequences. To sample effective point clouds from input, we design a differentiable point cloud sampling method built on density-guided attention mechanism. To avoid the jitter caused by previous 3D human pose estimation problems, we adopt temporal information to obtain more stable results. Experiments on the ITOP dataset and the NTU-RGBD dataset demonstrate that all of our contributed components are effective, and our method can achieve state-of-the-art performance.

----

## [184] Rescuing Deep Hashing from Dead Bits Problem

**Authors**: *Shu Zhao, Dayan Wu, Yucan Zhou, Bo Li, Weiping Wang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/185](https://doi.org/10.24963/ijcai.2021/185)

**Abstract**:

Deep hashing methods have shown great retrieval accuracy and efficiency in large-scale image retrieval. How to optimize discrete hash bits is always the focus in deep hashing methods. A common strategy in these methods is to adopt an activation function, e.g. sigmoid() or tanh(), and minimize a quantization loss to approximate discrete values. However, this paradigm may make more and more hash bits stuck into the wrong saturated area of the activation functions and never escaped. We call this problem "Dead Bits Problem (DBP)". Besides, the existing quantization loss will aggravate DBP as well. In this paper, we propose a simple but effective gradient amplifier which acts before activation functions to alleviate DBP. Moreover, we devise an error-aware quantization loss to further alleviate DBP. It avoids the negative effect of quantization loss based on the similarity between two images. The proposed gradient amplifier and error-aware quantization loss are compatible with a variety of deep hashing methods. Experimental results on three datasets demonstrate the efficiency of the proposed gradient amplifier and the error-aware quantization loss.

----

## [185] PointLIE: Locally Invertible Embedding for Point Cloud Sampling and Recovery

**Authors**: *Weibing Zhao, Xu Yan, Jiantao Gao, Ruimao Zhang, Jiayan Zhang, Zhen Li, Song Wu, Shuguang Cui*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/186](https://doi.org/10.24963/ijcai.2021/186)

**Abstract**:

Point Cloud Sampling and Recovery (PCSR) is critical for massive real-time point cloud collection and processing since raw data usually requires large storage and computation. This paper addresses a fundamental problem in PCSR: How to downsample the dense point cloud with arbitrary scales while preserving the local topology of discarded points in a case-agnostic manner (i.e., without additional storage for point relationships)? We propose a novel Locally Invertible Embedding (PointLIE) framework to unify the point cloud sampling and upsampling into one single framework through bi-directional learning. Specifically, PointLIE decouples the local geometric relationships between discarded points from the sampled points by progressively encoding the neighboring offsets to a latent variable. Once the latent variable is forced to obey a pre-defined distribution in the forward sampling path, the recovery can be achieved effectively through inverse operations. Taking the recover-pleasing sampled points and a latent embedding randomly drawn from the specified distribution as inputs, PointLIE can theoretically guarantee the fidelity of reconstruction and outperform state-of-the-arts quantitatively and qualitatively.

----

## [186] A Sketch-Transformer Network for Face Photo-Sketch Synthesis

**Authors**: *Mingrui Zhu, Changcheng Liang, Nannan Wang, Xiaoyu Wang, Zhifeng Li, Xinbo Gao*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/187](https://doi.org/10.24963/ijcai.2021/187)

**Abstract**:

We present a face photo-sketch synthesis model, which converts a face photo into an artistic face sketch or recover a photo-realistic facial image from a sketch portrait. Recent progress has been made by convolutional neural networks (CNNs) and generative adversarial networks (GANs), so that promising results can be obtained through real-time end-to-end architectures. However, convolutional architectures tend to focus on local information and neglect long-range spatial dependency, which limits the ability of existing approaches in keeping global structural information. In this paper, we propose a Sketch-Transformer network for face photo-sketch synthesis, which consists of three closely-related modules, including a multi-scale feature and position encoder for patch-level feature and position embedding, a self-attention module for capturing long-range spatial dependency, and a multi-scale spatially-adaptive de-normalization decoder for image reconstruction. Such a design enables the model to generate reasonable detail texture while maintaining global structural information. Extensive experiments show that the proposed method achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations.

----

## [187] PoseGTAC: Graph Transformer Encoder-Decoder with Atrous Convolution for 3D Human Pose Estimation

**Authors**: *Yiran Zhu, Xing Xu, Fumin Shen, Yanli Ji, Lianli Gao, Heng Tao Shen*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/188](https://doi.org/10.24963/ijcai.2021/188)

**Abstract**:

Graph neural networks (GNNs) have been widely used in the 3D human pose estimation task, since the pose representation of a human body can be naturally modeled by the graph structure. Generally, most of the existing GNN-based models utilize the restricted receptive ﬁelds of ﬁlters and single-scale information, while neglecting the valuable multi-scale contextual information. To tackle this issue, we propose a novel Graph Transformer Encoder-Decoder with Atrous Convolution, named PoseGTAC, to effectively extract multi-scale context and long-range information. In our proposed PoseGTAC model, Graph Atrous Convolution (GAC) and Graph Transformer Layer (GTL), respectively for the extraction of local multi-scale and global long-range information, are combined and stacked in an encoder-decoder structure, where graph pooling and unpooling are adopted for the interaction of multi-scale information from local to global (e.g., part-scale and body-scale). Extensive experiments on the Human3.6M and MPI-INF-3DHP datasets demonstrate that the proposed PoseGTAC model exceeds all previous methods and achieves state-of-the-art performance.

----

## [188] Reducing SAT to Max2SAT

**Authors**: *Carlos Ansótegui, Jordi Levy*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/189](https://doi.org/10.24963/ijcai.2021/189)

**Abstract**:

In the literature, we find reductions from 3SAT to Max2SAT. These reductions are based on the usage of a gadget, i.e., a combinatorial structure that allows translating constraints of one problem to constraints of another. Unfortunately, the generation of these gadgets lacks an intuitive or efficient method. In this paper, we provide an efficient and constructive method for  Reducing  SAT  to  Max2SAT  and show empirical results of how MaxSAT solvers are more efficient than SAT solvers solving the translation of hard formulas for Resolution.

----

## [189] Improved CP-Based Lagrangian Relaxation Approach with an Application to the TSP

**Authors**: *Raphaël Boudreault, Claude-Guy Quimper*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/190](https://doi.org/10.24963/ijcai.2021/190)

**Abstract**:

CP-based Lagrangian relaxation (CP-LR) is an efficient optimization technique that combines cost-based filtering with Lagrangian relaxation in a constraint programming context. The state-of-the-art filtering algorithms for the WeightedCircuit constraint that encodes the traveling salesman problem (TSP) are based on this approach. In this paper, we propose an improved CP-LR approach that locally modifies the Lagrangian multipliers in order to increase the number of filtered values. We also introduce two new algorithms based on the latter to filter WeightedCircuit. The experimental results on TSP instances show that our algorithms allow significant gains on the resolution time and the size of the search space when compared to the state-of-the-art implementation.

----

## [190] Efficiently Explaining CSPs with Unsatisfiable Subset Optimization

**Authors**: *Emilio Gamba, Bart Bogaerts, Tias Guns*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/191](https://doi.org/10.24963/ijcai.2021/191)

**Abstract**:

We build on a recently proposed method for explaining solutions of constraint satisfaction problems. An explanation here is a sequence of simple inference steps, where the simplicity of an inference step is measured by the number and types of constraints and facts used, and where the sequence explains all logical consequences of the problem. We build on these formal foundations and tackle two emerging questions, namely how to generate explanations that are provably optimal (with respect to the given cost metric) and how to generate them efficiently. To answer these questions, we develop 1) an implicit hitting set algorithm for finding optimal unsatisfiable subsets; 2) a method to reduce multiple calls for (optimal) unsatisfiable subsets to a single call that takes constraints on the subset into account, and 3) a method for re-using relevant information over multiple calls to these algorithms. The method is also applicable to other problems that require finding cost-optimal unsatiable subsets. We specifically show that this approach can be used to effectively find sequences of optimal explanation steps for constraint satisfaction problems like logic grid puzzles.

----

## [191] Decomposition Strategies to Count Integer Solutions over Linear Constraints

**Authors**: *Cunjing Ge, Armin Biere*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/192](https://doi.org/10.24963/ijcai.2021/192)

**Abstract**:

Counting integer solutions of linear constraints has found interesting applications in various fields. It is equivalent to the problem of counting integer points inside a polytope. However, state-of-the-art algorithms for this problem become too slow for even a modest number of variables. In this paper, we propose new decomposition techniques which target both the elimination of variables as well as inequalities using structural properties of counting problems. Experiments on extensive benchmarks show that our algorithm improves the performance of state-of-the-art counting algorithms, while the overhead is usually negligible compared to the running time of integer counting.

----

## [192] Solving Graph Homomorphism and Subgraph Isomorphism Problems Faster Through Clique Neighbourhood Constraints

**Authors**: *Sonja Kraiczy, Ciaran McCreesh*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/193](https://doi.org/10.24963/ijcai.2021/193)

**Abstract**:

Graph homomorphism problems involve finding adjacency-preserving mappings between two given graphs.  Although theoretically hard, these problems can often be solved in practice using constraint programming algorithms. We show how techniques from the state-of-the-art in subgraph isomorphism solving can be applied to broader graph homomorphism problems, and introduce a new form of filtering based upon clique-finding. We demonstrate empirically that this filtering is effective for the locally injective graph homomorphism and subgraph isomorphism problems, and gives the first practical constraint programming approach to finding general graph homomorphisms.

----

## [193] Backdoor DNFs

**Authors**: *Sebastian Ordyniak, André Schidler, Stefan Szeider*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/194](https://doi.org/10.24963/ijcai.2021/194)

**Abstract**:

We introduce backdoor DNFs, as a tool to measure the theoretical hardness of CNF formulas. Like backdoor sets and backdoor trees, backdoor DNFs are defined relative to a tractable class of CNF formulas. Each conjunctive term of a backdoor DNF defines a partial assignment that moves the input CNF formula into the base class.  Backdoor DNFs are more expressive and potentially smaller than their predecessors backdoor sets and backdoor trees.  We establish the fixed-parameter tractability of the backdoor DNF detection problem.  Our results hold for the fundamental base classes Horn and 2CNF, and their combination. We complement our theoretical findings by an empirical study. Our experiments show that backdoor DNFs provide a significant improvement over their predecessors.

----

## [194] Learning Implicitly with Noisy Data in Linear Arithmetic

**Authors**: *Alexander Philipp Rader, Ionela Georgiana Mocanu, Vaishak Belle, Brendan Juba*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/195](https://doi.org/10.24963/ijcai.2021/195)

**Abstract**:

Robust learning in expressive languages with real-world data continues to be a challenging task. Numerous conventional methods appeal to heuristics without any assurances of robustness. While probably approximately correct (PAC) Semantics offers strong guarantees, learning explicit representations is not tractable, even in propositional logic. However, recent work on so-called â€œimplicit" learning has shown tremendous promise in terms of obtaining polynomial-time results for fragments of first-order logic. In this work, we extend implicit learning in PAC-Semantics to handle noisy data in the form of intervals and threshold uncertainty in the language of linear arithmetic. We prove that our extended framework keeps the existing polynomial-time complexity guarantees. Furthermore, we provide the first empirical investigation of this hitherto purely theoretical framework. Using benchmark problems, we show that our implicit approach to learning optimal linear programming objective constraints significantly outperforms an explicit approach in practice.

----

## [195] Computing Optimal Hypertree Decompositions with SAT

**Authors**: *André Schidler, Stefan Szeider*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/196](https://doi.org/10.24963/ijcai.2021/196)

**Abstract**:

Hypertree width is a prominent hypergraph invariant with many
  algorithmic applications in constraint satisfaction and
  databases. We propose a novel characterization for hypertree width
  in terms of linear elimination orderings. We utilize this
  characterization to generate a new SAT encoding that we evaluate on
  an extensive set of benchmark instances. We compare it to
  state-of-the-art exact methods for computing optimal hypertree
  width. Our results show that the encoding based on the new
  characterization is not only significantly more compact than known
  encodings but also outperforms the other methods.

----

## [196] Exploring Periodicity and Interactivity in Multi-Interest Framework for Sequential Recommendation

**Authors**: *Gaode Chen, Xinghua Zhang, Yanyan Zhao, Cong Xue, Ji Xiang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/197](https://doi.org/10.24963/ijcai.2021/197)

**Abstract**:

Sequential recommendation systems alleviate the problem of information overload, and have attracted increasing attention in the literature. Most prior works usually obtain an overall representation based on the user’s behavior sequence, which can not sufficiently reflect the multiple interests of the user. To this end, we propose a novel method called PIMI to mitigate this issue. PIMI can model the user’s multi-interest representation effectively by considering both the periodicity and interactivity in the item sequence. Specifically, we design a periodicity-aware module to utilize the time interval information between user’s behaviors. Meanwhile, an ingenious graph is proposed to enhance the interactivity between items in user’s behavior sequence, which can capture both global and local item features. Finally, a multi-interest extraction module is applied to describe user’s multiple interests based on the obtained item representation. Extensive experiments on two real-world datasets Amazon and Taobao show that PIMI outperforms state-of-the-art methods consistently.

----

## [197] Masked Contrastive Learning for Anomaly Detection

**Authors**: *Hyunsoo Cho, Jinseok Seol, Sang-goo Lee*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/198](https://doi.org/10.24963/ijcai.2021/198)

**Abstract**:

Detecting anomalies is one fundamental aspect of a safety-critical software system, however, it remains a long-standing problem. Numerous branches of works have been proposed to alleviate the complication and have shown promising results. In particular, self-supervised learning based methods are spurring interest due to their capability of learning diverse representations without additional labels. Among self-supervised learning tactics, contrastive learning is one specific framework showing pronounced results in various fields including anomaly detection. However, the primary objective of contrastive learning is to learn task-agnostic features without any labels, which is not entirely suited to discern anomalies. In this paper, we propose a task-specific variant of contrastive learning named masked contrastive learning, which is more befitted for anomaly detection. Moreover, we propose a new inference method dubbed self-ensemble inference that further boosts performance by leveraging the ability learned through auxiliary self-supervision tasks. By combining our models, we can outperform previous state-of-the-art methods by a significant margin on various benchmark datasets.

----

## [198] Multi-Channel Pooling Graph Neural Networks

**Authors**: *Jinlong Du, Senzhang Wang, Hao Miao, Jiaqiang Zhang*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/199](https://doi.org/10.24963/ijcai.2021/199)

**Abstract**:

Graph pooling is a critical operation to downsample a graph in graph neural networks. Existing coarsening pooling methods (e.g. DiffPool) mostly focus on capturing the global topology structure by assigning the nodes into several coarse clusters, while dropping pooling methods (e.g. SAGPool) try to preserve the local topology structure by selecting the top-k representative nodes. However, there lacks an effective method to integrate the two types of methods so that both the local and the global topology structure of a graph can be well captured. To address this issue, we propose a Multi-channel Graph Pooling method named MuchPool, which captures the local structure, the global structure, and node feature simultaneously in graph pooling. Specifically, we use two channels to conduct dropping pooling based on the local topology and node features respectively, and one channel to conduct coarsening pooling. Then a cross-channel convolution operation is designed to refine the graph representations of different channels. Finally, the pooling results are aggregated as the final pooled graph. Extensive experiments on six benchmark datasets present the superior performance of MuchPool. The code of this work is publicly available at Github.

----

## [199] Guided Attention Network for Concept Extraction

**Authors**: *Songtao Fang, Zhenya Huang, Ming He, Shiwei Tong, Xiaoqing Huang, Ye Liu, Jie Huang, Qi Liu*

**Conference**: *ijcai 2021*

**URL**: [https://doi.org/10.24963/ijcai.2021/200](https://doi.org/10.24963/ijcai.2021/200)

**Abstract**:

Concept extraction aims to find words or phrases describing a concept from massive texts. Recently, researchers propose many neural network-based methods to automatically extract concepts. Although these methods for this task show promising results, they ignore structured information in the raw textual data (e.g., title, topic, and clue words). In this paper, we propose a novel model, named Guided Attention Concept Extraction Network (GACEN), which uses  title, topic, and clue words as additional supervision to provide guidance directly. Specifically, GACEN comprises two attention networks, one of them is to gather the relevant title and topic information for each context word in the document. The other one aims to model the implicit connection between informative words (clue words) and concepts. Finally, we aggregate information from two networks as input to Conditional Random Field (CRF) to model dependencies in the output. We collected clue words for three well-studied datasets. Extensive experiments demonstrate that our model outperforms the baseline models with a large margin, especially when the labeled data is insufficient.

----



[Go to the next page](IJCAI-2021-list02.md)

[Go to the catalog section](README.md)